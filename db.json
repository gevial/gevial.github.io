{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/minos/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/minos/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/minos/source/js/jquery.min.js","path":"js/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/minos/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/minos/source/css/images/logo.png","path":"css/images/logo.png","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/main.css","path":"webfonts/ptserif/main.css","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/source-code-pro/main.css","path":"webfonts/source-code-pro/main.css","modified":1,"renderable":1},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/03aPdn7fFF3H6ngCgAlQzPk_vArhqVIZ0nv9q090hN8.woff2","path":"webfonts/ptserif/fonts/03aPdn7fFF3H6ngCgAlQzPk_vArhqVIZ0nv9q090hN8.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/3Nwg9VzlwLXPq3fNKwVRMCEAvth_LlrfE80CYdSH47w.woff2","path":"webfonts/ptserif/fonts/3Nwg9VzlwLXPq3fNKwVRMCEAvth_LlrfE80CYdSH47w.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/5hX15RUpPERmeybVlLQEWBTbgVql8nDJpwnrE27mub0.woff2","path":"webfonts/ptserif/fonts/5hX15RUpPERmeybVlLQEWBTbgVql8nDJpwnrE27mub0.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/CPRt--GVMETgA6YEaoGitxTbgVql8nDJpwnrE27mub0.woff2","path":"webfonts/ptserif/fonts/CPRt--GVMETgA6YEaoGitxTbgVql8nDJpwnrE27mub0.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/I-OtoJZa3TeyH6D9oli3ifesZW2xOQ-xsNqO47m55DA.woff2","path":"webfonts/ptserif/fonts/I-OtoJZa3TeyH6D9oli3ifesZW2xOQ-xsNqO47m55DA.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/O_WhD9hODL16N4KLHLX7xSEAvth_LlrfE80CYdSH47w.woff2","path":"webfonts/ptserif/fonts/O_WhD9hODL16N4KLHLX7xSEAvth_LlrfE80CYdSH47w.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpCYE0-AqJ3nfInTTiDXDjU4.woff2","path":"webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpCYE0-AqJ3nfInTTiDXDjU4.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDTOQ_MqJVwkKsUn0wKzc2I.woff2","path":"webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDTOQ_MqJVwkKsUn0wKzc2I.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDUj_cnvWIuuBMVgbX098Mw.woff2","path":"webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDUj_cnvWIuuBMVgbX098Mw.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/b31S45a_TNgaBApZhTgE6CEAvth_LlrfE80CYdSH47w.woff2","path":"webfonts/ptserif/fonts/b31S45a_TNgaBApZhTgE6CEAvth_LlrfE80CYdSH47w.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpI4P5ICox8Kq3LLUNMylGO4.woff2","path":"webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpI4P5ICox8Kq3LLUNMylGO4.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/ptserif/fonts/fU0HAfLiPHGlZhZpY6M7dBTbgVql8nDJpwnrE27mub0.woff2","path":"webfonts/ptserif/fonts/fU0HAfLiPHGlZhZpY6M7dBTbgVql8nDJpwnrE27mub0.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","path":"webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","path":"webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","modified":1,"renderable":1},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/minos/.DS_Store","hash":"8fc9ac3be259cf25d5021054769da4ee15d1fd99","modified":1480188063000},{"_id":"themes/minos/.gitignore","hash":"bbe994b5dffd47ea6ad0458525548d5650e043a7","modified":1480187059000},{"_id":"themes/minos/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1480187059000},{"_id":"themes/minos/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1480187059000},{"_id":"themes/minos/README.md","hash":"947826ffa33cc7823231c5eed91c39598a771714","modified":1480187059000},{"_id":"themes/minos/package.json","hash":"6b4e8276c212f5a617dc558548f5b3d1ae0fb1f2","modified":1480187059000},{"_id":"themes/minos/_config.yml.example","hash":"1a7bdf1240e8c9b0ff8afe2416fc61691d922f78","modified":1480187059000},{"_id":"themes/minos/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1480187059000},{"_id":"themes/minos/.git/config","hash":"86ce9cdb1395b8347f38abd45a74bbfee3334069","modified":1480187059000},{"_id":"themes/minos/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1480187054000},{"_id":"themes/minos/.git/index","hash":"b826dc8c8a8d01e67976b39d898506e09d32b9de","modified":1480187059000},{"_id":"themes/minos/.git/packed-refs","hash":"682c15a3cefabeee6adf6379ba75afb2c374b0c1","modified":1480187059000},{"_id":"themes/minos/layout/archive.ejs","hash":"4479c33517aa70f2714ee820775ff8307a0dd115","modified":1480187059000},{"_id":"themes/minos/layout/about.ejs","hash":"d80fc2c4329b2079e65312689042de6f03312d6e","modified":1480187059000},{"_id":"themes/minos/layout/categories.ejs","hash":"c40b133eb9b8612a2286a83b8d7d2ca344673507","modified":1480187059000},{"_id":"themes/minos/layout/category.ejs","hash":"cd17981f9cac718731880148cb17de60d148a75c","modified":1480187059000},{"_id":"themes/minos/layout/index.ejs","hash":"505555df272ac4dd23e5eae3acb857a457e421b4","modified":1480187059000},{"_id":"themes/minos/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1480187059000},{"_id":"themes/minos/layout/layout.ejs","hash":"03c85682322dce721f6a90aa0f0b5d2ed6622a35","modified":1480187059000},{"_id":"themes/minos/layout/tag.ejs","hash":"bcde8c7ce7e21683ca2cba7fcc21ac43c817a9a4","modified":1480187059000},{"_id":"themes/minos/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1480187059000},{"_id":"themes/minos/layout/tags.ejs","hash":"cf485e9053f96d69a1e0ce0f8a55c3aa33ebde03","modified":1480187059000},{"_id":"themes/minos/languages/en.yml","hash":"7bada5ca0cf685cb21ab64ba6ef2983314fe10c5","modified":1480187059000},{"_id":"themes/minos/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1480187059000},{"_id":"themes/minos/languages/ru.yml","hash":"c0ac1d63913b0caea5494db14e458f7e5a0937c3","modified":1480187059000},{"_id":"themes/minos/languages/zh-CN.yml","hash":"c6daf6c25bdddcfa989ff0dd62559ed2ea5f790b","modified":1480187059000},{"_id":"source/_posts/2015-06-17-centos-web2py.md","hash":"fd52e605a5ab4263bc22c289de5e3d127d131855","modified":1480187411000},{"_id":"source/_posts/2015-06-17-delete-block-device.md","hash":"5c8bb40747e3914cf0da1f5296d1d93678f0e3e9","modified":1480187411000},{"_id":"source/_posts/2015-06-17-disable-zendmm.md","hash":"f22a38ba6c265cdd3c94798e1363408aa3f2857c","modified":1480187411000},{"_id":"source/_posts/2015-06-17-dnsmasq.md","hash":"a8db398731ada6d10ee27393c61eee67387c077a","modified":1480187411000},{"_id":"source/_posts/2015-06-17-gethostbyname-ndots.md","hash":"7dd1c445a490a4ea12045cc549022ecb77f3b1c8","modified":1480187411000},{"_id":"source/_posts/2015-06-17-hw-raid-rebuild.md","hash":"dc7b7f3920ac1985133f115533181e814e2983db","modified":1480187411000},{"_id":"source/_posts/2015-06-17-mysql-query-statistics.md","hash":"f28e2b2c2a5fbbd7307c9276ec6238dd2e581c1e","modified":1480187411000},{"_id":"source/_posts/2015-06-17-mysql-start-segfault.md","hash":"3aeb7ca6de8099a65a3d37674e5dfa6a975d2a44","modified":1480187411000},{"_id":"source/_posts/2015-06-17-puppet-error-400.md","hash":"92694e774987d5689747d6f41cdcfe69ca5f829d","modified":1480187411000},{"_id":"source/_posts/2015-06-17-nscd.md","hash":"178031ac6ceb0b6d802079e1b9608c6ac579512d","modified":1480187411000},{"_id":"source/_posts/2015-06-17-python-multiprocessing-sysexit.md","hash":"3a34e47bec984dfd56ec512c7062e3bdf7f40dc7","modified":1480187411000},{"_id":"source/_posts/2015-06-17-reinstall-grub.md","hash":"a631f6c062be9aefc6375752c9708b620227af97","modified":1480187411000},{"_id":"source/_posts/2015-06-17-routes-on-vpn-connect-osx.md","hash":"2d05aa64161ffb68e43c05756988f5436aaea382","modified":1480187411000},{"_id":"source/_posts/2015-06-17-sata-host-scan.md","hash":"f6cf254338395b2f1e5c4ac70944ecc4ce749551","modified":1480187411000},{"_id":"source/_posts/2015-06-17-several-ip-assign.md","hash":"ab8603496276d401d07b752a03997af8d02a0604","modified":1480187411000},{"_id":"source/_posts/2015-06-19-debug-502-php.md","hash":"5d8802424959add593efd4e0a9e0c37892c11550","modified":1480187411000},{"_id":"source/_posts/2015-06-23-nginx-bind-error.md","hash":"96877fda588297e7b164d6f6678477ef7394a11b","modified":1480187411000},{"_id":"source/_posts/2015-07-14-local-elk-fast-start.md","hash":"0e0b1b6ec98b81fb6210cc0e52e84e07aec652c5","modified":1480187411000},{"_id":"source/_posts/2015-07-17-puppet-concat-order.md","hash":"c09404a2565452f617a437e123fed65d027d58bc","modified":1480187411000},{"_id":"source/_posts/2015-09-07-mysql-ip.md","hash":"596f9ad115c675a5770ec70cc9003cc3c22ad52e","modified":1480187411000},{"_id":"source/_posts/2015-09-24-mysql-charset-proc.md","hash":"06eee0c3364b5995262ca965179211848233db0c","modified":1480187411000},{"_id":"source/_posts/2015-10-12-puppet-cert-error-header-too-long.md","hash":"0d8868a29c3c8e102a7ce168e142ff375b4476d8","modified":1480187411000},{"_id":"source/_posts/2015-11-10-python-no-sys-exit-in-signal-handlers.md","hash":"d8e26fe6921400d3a2edc741bce955734e476ceb","modified":1480187411000},{"_id":"source/_posts/2016-01-12-tpc-h.md","hash":"869546c1c2708e8519ab9241858ee7451bd5a846","modified":1480187411000},{"_id":"source/_posts/2016-01-12-mysql-range-access-method-explained.md","hash":"c6f2d86923373e79e5f85181036d36b0eb18c747","modified":1480187411000},{"_id":"source/_posts/2016-01-15-lsi-raid-controller-cache-policies.md","hash":"74cf5101b4854df91a12e05bf83085595a8c19aa","modified":1480187411000},{"_id":"source/_posts/2016-01-21-time_wait-sockets.md","hash":"c0ce3935adc34198d5a7307588c5a89bba1f167b","modified":1480187411000},{"_id":"source/_posts/2016-02-10-change-ext-journal-device-ext4.md","hash":"e901a34269fe02dd934a5484be1c6d2db35c0d2a","modified":1480187411000},{"_id":"source/_posts/2016-06-30-fio.md","hash":"3a8f31ac0378c00921789f1035d7c11df8d5b8d3","modified":1480187411000},{"_id":"source/_posts/2016-07-01-work-env.md","hash":"e9fc92d13e19cb668cb1eaf69a90cd3683a604b1","modified":1480187411000},{"_id":"source/_posts/2016-07-03-web-operations-sla.md","hash":"09165cdc5a35d53b7862772894f436cebf143827","modified":1480187411000},{"_id":"source/_posts/2016-10-28-web-operations-data-assets.md","hash":"51a51adbffcd38afad464d0f728da5894273aeb7","modified":1480187411000},{"_id":"source/_posts/2016-09-27-web-operations-postmortem.md","hash":"1f04312d19a44104a7a09f788f8c33bae3eb6f92","modified":1480187411000},{"_id":"source/_posts/hello-world.md","hash":"8a02477044e2b77f1b262da2c48c01429e4a32e4","modified":1479055387000},{"_id":"source/_posts/2016-11-13-openapi.md","hash":"0be34782c3b58e388153023121a2da3484e4c37c","modified":1480187411000},{"_id":"source/tags/index.md","hash":"e999413d6392c34156b5c6e9273f9069f9e6d92d","modified":1480187135000},{"_id":"source/categories/index.md","hash":"55bee2cb88da438a2e8b1f29b1d7e954c07a9e60","modified":1480187127000},{"_id":"themes/minos/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1480187054000},{"_id":"themes/minos/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1480187054000},{"_id":"themes/minos/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1480187054000},{"_id":"themes/minos/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1480187054000},{"_id":"themes/minos/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1480187054000},{"_id":"themes/minos/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1480187054000},{"_id":"themes/minos/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1480187054000},{"_id":"themes/minos/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1480187054000},{"_id":"themes/minos/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1480187054000},{"_id":"themes/minos/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1480187054000},{"_id":"themes/minos/.git/logs/HEAD","hash":"38b8101f315a03cadaa6c998fb692b35ef416073","modified":1480187059000},{"_id":"themes/minos/layout/_partial/after-footer.ejs","hash":"59e91784ebde77f8d258dac6f21e29147ad36b4f","modified":1480187059000},{"_id":"themes/minos/layout/_partial/archive-post.ejs","hash":"9d687d6560e05764d3d57b2948680aa3940332cf","modified":1480187059000},{"_id":"themes/minos/layout/_partial/archive.ejs","hash":"fb0206d283ae56717eb92f92784271e79b2e208a","modified":1480187059000},{"_id":"themes/minos/layout/_partial/about-page.ejs","hash":"23a0d62ddf1964f8d48fb234a73d01cdd948928c","modified":1480187059000},{"_id":"themes/minos/layout/_partial/article.ejs","hash":"eeb275d1221fff483b2b7bb9c0fe34b1b2ee90a2","modified":1480187059000},{"_id":"themes/minos/layout/_partial/footer.ejs","hash":"9ff7842d55d8707317fbcd00b1b2fac206a21a1a","modified":1480187059000},{"_id":"themes/minos/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1480187059000},{"_id":"themes/minos/layout/_partial/head.ejs","hash":"0bd191a43bc158d1b2b01e1f5001efe5175edbec","modified":1480187059000},{"_id":"themes/minos/layout/_partial/header.ejs","hash":"3431b84ac8057be6766ad2806dd418b71f5b9787","modified":1480187059000},{"_id":"themes/minos/_source/about/index.md","hash":"f61be0b26f5ecb076f5fa820db27a558a8863a95","modified":1480187059000},{"_id":"themes/minos/_source/categories/index.md","hash":"55bee2cb88da438a2e8b1f29b1d7e954c07a9e60","modified":1480187059000},{"_id":"themes/minos/_source/tags/index.md","hash":"e999413d6392c34156b5c6e9273f9069f9e6d92d","modified":1480187059000},{"_id":"themes/minos/source/css/_extend.styl","hash":"d31b1c9980353af3c1607ee6caf84835b7322eea","modified":1480187059000},{"_id":"themes/minos/source/css/_variables.styl","hash":"5bb3cfe78ece808ee0b32078535bb3ce69d98065","modified":1480187059000},{"_id":"themes/minos/source/css/style.styl","hash":"6793062670c69b331e786cfb19d5473f82d7d51c","modified":1480187059000},{"_id":"themes/minos/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1480187059000},{"_id":"themes/minos/source/js/script.js","hash":"631cc4a69bc1f7903a24544b79b8e6ea68be9243","modified":1480187059000},{"_id":"themes/minos/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1480187059000},{"_id":"themes/minos/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1480187059000},{"_id":"themes/minos/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1480187059000},{"_id":"themes/minos/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1480187059000},{"_id":"themes/minos/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1480187059000},{"_id":"themes/minos/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1480187059000},{"_id":"themes/minos/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1480187059000},{"_id":"themes/minos/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1480187059000},{"_id":"themes/minos/source/js/jquery.min.js","hash":"a6eedf84389e1bc9f757bc2d19538f8c8d1cae9d","modified":1480187059000},{"_id":"themes/minos/.git/refs/heads/master","hash":"a9632deb36eada8a855d7f84937c791d096868b2","modified":1480187059000},{"_id":"themes/minos/.git/objects/pack/pack-8ab88af8110758671a3557a2a6d5c6dd788c5c71.idx","hash":"0f73a17f23ba649322c4f1eb227a504bb2880a20","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/category.ejs","hash":"28600328d5d2d68b547b59e7ed713cd315a138d8","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/nav.ejs","hash":"573863e2d6a9d637fff4a8e3b2a4cacb65565499","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/share_jia.ejs","hash":"924744aa3c1bce9056ba03cec02e19e095009126","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/share_addthis.ejs","hash":"0ac35bd92e58983c189ac0c35df404ebc6ee826e","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1480187059000},{"_id":"themes/minos/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/archive.styl","hash":"f75e3da863fccfebafcae2e76ea6732a927b79f4","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/comment.styl","hash":"06fc75428036bd8277a6d3dea4b636a0dac91154","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/article.styl","hash":"42ffaa45f8ee22f34f0a560164298e07aa8c24b9","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/custom-layout.styl","hash":"8d922662464bda0ac0b639c40fda2ee196bef5b5","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/fancybox.styl","hash":"46a40e2749e68db0348db2938429fe4ce0f4724e","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/footer.styl","hash":"e4e9b6da90a2620f7905b7283e52322bb83d2fdb","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/header.styl","hash":"c0efb35cee449e1721473ba535e635f8ac08b178","modified":1480187059000},{"_id":"themes/minos/source/css/_partial/highlight.styl","hash":"3fb9265868e4cebeaffa155d8825e90311eb3744","modified":1480187059000},{"_id":"themes/minos/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1480187059000},{"_id":"themes/minos/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1480187059000},{"_id":"themes/minos/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1480187059000},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1480187059000},{"_id":"themes/minos/source/css/images/logo.png","hash":"f5fd1c37a281d60440362c43216cb7f3f670a412","modified":1480188227000},{"_id":"themes/minos/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1480187059000},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1480187059000},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1480187059000},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1480187059000},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1480187059000},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1480187059000},{"_id":"themes/minos/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/main.css","hash":"ec6a269189b9a8b807fb4e1de6ffd7acc6a7fea8","modified":1480187059000},{"_id":"themes/minos/source/webfonts/source-code-pro/main.css","hash":"e6a0204ff3c501d6248d96e55aa20d0b42b45a79","modified":1480187059000},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1480187059000},{"_id":"themes/minos/.git/logs/refs/heads/master","hash":"38b8101f315a03cadaa6c998fb692b35ef416073","modified":1480187059000},{"_id":"themes/minos/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/03aPdn7fFF3H6ngCgAlQzPk_vArhqVIZ0nv9q090hN8.woff2","hash":"fa8cc541ddc3da23a5a90b08e64e4c12944c56a1","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/3Nwg9VzlwLXPq3fNKwVRMCEAvth_LlrfE80CYdSH47w.woff2","hash":"703369bb4159f050b38ecc4f52cfadb8e5760775","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/5hX15RUpPERmeybVlLQEWBTbgVql8nDJpwnrE27mub0.woff2","hash":"0c79a0581c3472e6bb29082092ea37d897370473","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/CPRt--GVMETgA6YEaoGitxTbgVql8nDJpwnrE27mub0.woff2","hash":"4da92f4f265caa786469ec415cfa6515d2997943","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/I-OtoJZa3TeyH6D9oli3ifesZW2xOQ-xsNqO47m55DA.woff2","hash":"36225cd511b12ed61f3e3fbad53773119e9dd73e","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/O_WhD9hODL16N4KLHLX7xSEAvth_LlrfE80CYdSH47w.woff2","hash":"950d5547dc10d4a1bdb837439fcfc6c68bbe1b02","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpCYE0-AqJ3nfInTTiDXDjU4.woff2","hash":"5984003d117f49ae596bde0498310ed215ac3aba","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDTOQ_MqJVwkKsUn0wKzc2I.woff2","hash":"b64d3a0d20efa14e6063070eb30fbdb594bde59c","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDUj_cnvWIuuBMVgbX098Mw.woff2","hash":"6f1e434623e2fa20ba8972a6f97dd9c800b56168","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/b31S45a_TNgaBApZhTgE6CEAvth_LlrfE80CYdSH47w.woff2","hash":"0b4aef50c2979164681fa6dfe2c1d6bd6be6bcd3","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpI4P5ICox8Kq3LLUNMylGO4.woff2","hash":"df9999766ca9ffe9428b139931352cd821526aed","modified":1480187059000},{"_id":"themes/minos/source/webfonts/ptserif/fonts/fU0HAfLiPHGlZhZpY6M7dBTbgVql8nDJpwnrE27mub0.woff2","hash":"3f425d6aee0c07774a10d82dcb742e32b067f217","modified":1480187059000},{"_id":"themes/minos/source/webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","hash":"942addaec4d3a60af33947a84a3d85f926015947","modified":1480187059000},{"_id":"themes/minos/source/webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","hash":"b0e0bb5ef78db8b15d430d0b9be9d4329289a310","modified":1480187059000},{"_id":"themes/minos/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1480187059000},{"_id":"themes/minos/.git/logs/refs/remotes/origin/HEAD","hash":"38b8101f315a03cadaa6c998fb692b35ef416073","modified":1480187059000},{"_id":"themes/minos/.git/objects/pack/pack-8ab88af8110758671a3557a2a6d5c6dd788c5c71.pack","hash":"b589f501053b32f876ec7612394f30ef15dc337e","modified":1480187059000},{"_id":"public/tags/index.html","hash":"038b2c40cf4c4ad16b2f4af7c106ae6ab51dc423","modified":1480188366756},{"_id":"public/categories/index.html","hash":"3e84bfe1335c760679d4d4b21ebfb31efe0432b7","modified":1480188366832},{"_id":"public/2016/11/26/2015-07-14-local-elk-fast-start/index.html","hash":"e84a303b4a38dafd2e5a6a98f2f4c6ca1cb10cde","modified":1480188366848},{"_id":"public/2016/11/26/2015-06-17-centos-web2py/index.html","hash":"865cd89c71e734be9f55ca3cc84d7fa1d0f69bd3","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-disable-zendmm/index.html","hash":"3b48103f372f3dbcff0c1bee668301bcb6726293","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-dnsmasq/index.html","hash":"c912e3804dcaa46b4a26dad65112d78dc02787fa","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-gethostbyname-ndots/index.html","hash":"d50ea75123934ee37a1f6123d5217f94b4f457e6","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-hw-raid-rebuild/index.html","hash":"0984078977154d136134bba03d38fb93eb572c95","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-mysql-query-statistics/index.html","hash":"76cb405af8e3e04022c8eaa625f05feecea01930","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-mysql-start-segfault/index.html","hash":"54904b4a8c163ae02ff76ad29194b6bf6e5c92b8","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-puppet-error-400/index.html","hash":"db50fdc2d34e21d969bde5f2523d27e70e977009","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-nscd/index.html","hash":"f10da2290491863df260edb5b329a3b82c8f25d8","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-python-multiprocessing-sysexit/index.html","hash":"386e3d865e7bfa0d46165cd81f393f1b4a883685","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-reinstall-grub/index.html","hash":"e33684ea5a37f17e045c7958a7cae1a5c90c11c1","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-routes-on-vpn-connect-osx/index.html","hash":"b4aa1fa77ef32105932ddb3bf5c9f5f0a6c42a3d","modified":1480188366849},{"_id":"public/2016/11/26/2015-06-17-sata-host-scan/index.html","hash":"e4cbd2b4aa0da6452c7b5e0515ff2095de162c33","modified":1480188366850},{"_id":"public/2016/11/26/2015-06-17-several-ip-assign/index.html","hash":"de14c5292fe1c16821bc1585787ecc7613d45ca5","modified":1480188366850},{"_id":"public/2016/11/26/2015-06-19-debug-502-php/index.html","hash":"ead5b4e597b2ed2c6676da10d447b7645369177a","modified":1480188366850},{"_id":"public/2016/11/26/2015-06-23-nginx-bind-error/index.html","hash":"46edc2f287310b07ffe1730e061134027b6baa9f","modified":1480188366850},{"_id":"public/2016/11/26/2015-06-17-delete-block-device/index.html","hash":"88d712495d2cc6677510e9eeb1bf0f30b4b4a605","modified":1480188366850},{"_id":"public/2016/11/26/2015-07-17-puppet-concat-order/index.html","hash":"52fc98d7b4f6808f5516153a2e3b87521c87a535","modified":1480188366850},{"_id":"public/2016/11/26/2015-09-07-mysql-ip/index.html","hash":"4f6048772165caeaa1d45cf7e3cde75972f75b49","modified":1480188366850},{"_id":"public/2016/11/26/2015-09-24-mysql-charset-proc/index.html","hash":"21a83099f0580c2626c4c9333785d905edd72b6d","modified":1480188366850},{"_id":"public/2016/11/26/2015-10-12-puppet-cert-error-header-too-long/index.html","hash":"816c1f8a83256fd611451aaa213a92c96a11597a","modified":1480188366850},{"_id":"public/2016/11/26/2015-11-10-python-no-sys-exit-in-signal-handlers/index.html","hash":"7a4c1b9be7230973a75c10dbece051292aaabff8","modified":1480188366850},{"_id":"public/2016/11/26/2016-01-12-tpc-h/index.html","hash":"db3735f429d4fcc8a1f51f415ab76962dc73f3db","modified":1480188366850},{"_id":"public/2016/11/26/2016-01-12-mysql-range-access-method-explained/index.html","hash":"ee661991b82b1fa45a5cb43e4180073bd62b6c54","modified":1480188366850},{"_id":"public/2016/11/26/2016-01-15-lsi-raid-controller-cache-policies/index.html","hash":"13efc5a8602af1a2e5df860964cee96970e6cddf","modified":1480188366850},{"_id":"public/2016/11/26/2016-01-21-time_wait-sockets/index.html","hash":"0c23ad81712a27f146a1984653a4d7a541681d86","modified":1480188366850},{"_id":"public/2016/11/26/2016-02-10-change-ext-journal-device-ext4/index.html","hash":"aebb06faa56eaf96374294fd2b2200b59d508e20","modified":1480188366850},{"_id":"public/2016/11/26/2016-06-30-fio/index.html","hash":"39f0aaf4b4e5adcfb45dbcbf3a1c1288e2a193a5","modified":1480188366850},{"_id":"public/2016/11/26/2016-07-03-web-operations-sla/index.html","hash":"b72d3ce7270fac0f0a0a05c3fe3698e05b3534a1","modified":1480188366850},{"_id":"public/2016/11/26/2016-10-28-web-operations-data-assets/index.html","hash":"30b851e53b07be9424aa4b2974c5c006365858df","modified":1480188366850},{"_id":"public/2016/11/26/2016-07-01-work-env/index.html","hash":"4c4475c7d6da96478eb25afa4e3cf58f81a947bc","modified":1480188366850},{"_id":"public/2016/11/26/2016-09-27-web-operations-postmortem/index.html","hash":"0296376a2acb15352ac2863af52ef72f4e2edbd7","modified":1480188366865},{"_id":"public/2016/11/26/2016-11-13-openapi/index.html","hash":"5844aa6a7f7c57257a9bc36232cbda18e7549957","modified":1480188366865},{"_id":"public/2016/11/13/hello-world/index.html","hash":"52dec9e7343c7ab13b1c85338a8c139b95d288d5","modified":1480188366865},{"_id":"public/tags/nginx/index.html","hash":"21f07370324321f3788dcd4dea59a7ab3f211acb","modified":1480188366865},{"_id":"public/tags/python/index.html","hash":"00c7d38c1736905a5b3583ed636ae311c76a2b8c","modified":1480188366865},{"_id":"public/tags/uwsgi/index.html","hash":"e29b61fdaf7efe977927dba3031cb9d0f24a0b96","modified":1480188366866},{"_id":"public/tags/hardware/index.html","hash":"1e730a62ac25372f7d1885a3d11e4ae2fc7ce0b1","modified":1480188366866},{"_id":"public/tags/php/index.html","hash":"49b7c4a96217581c040e609060eedabbc27e9ef3","modified":1480188366866},{"_id":"public/tags/apache/index.html","hash":"2464113299974f84c15412c7379dc8e417072527","modified":1480188366866},{"_id":"public/tags/dns/index.html","hash":"b83c7b58d005d5b625165221fb48396d83d2b3df","modified":1480188366866},{"_id":"public/tags/dhcp/index.html","hash":"1ba9cc3e9bdc47433005f1cee12ef5e2f39153b7","modified":1480188366866},{"_id":"public/tags/storage/index.html","hash":"59196a97ad304994b6976de5ed54d6dea057c4c2","modified":1480188366866},{"_id":"public/tags/mysql/index.html","hash":"83a0865a3ae3e11e772df5993b22164885d5954b","modified":1480188366866},{"_id":"public/tags/troubleshooting/index.html","hash":"abf9e385ceae00651f660ed46cc41ea7fd1de43b","modified":1480188366866},{"_id":"public/tags/puppet/index.html","hash":"daf8d1689eb8354fe50bd405fac22a14bec80b1e","modified":1480188366866},{"_id":"public/tags/vpn/index.html","hash":"5216f2a76c7fa9938bfe74e0cadcc99e5418f90d","modified":1480188366866},{"_id":"public/tags/environment/index.html","hash":"c93c73ea4cb85abda8634c739f41c9fbc78bd971","modified":1480188366866},{"_id":"public/tags/network/index.html","hash":"c473a21c4388245c2c6ee133d35f8dc0d6336ebf","modified":1480188366866},{"_id":"public/tags/logs/index.html","hash":"f60dcf1a2f1d77ad4b5d339d681bc664eca0c94b","modified":1480188366866},{"_id":"public/tags/elk/index.html","hash":"cc6770518dfe4bbeee0043e2246d5feae17c0ad9","modified":1480188366866},{"_id":"public/tags/performance/index.html","hash":"ba538e7ee5171979795641902d4d220766d07c90","modified":1480188366866},{"_id":"public/tags/tool/index.html","hash":"ec6f92f2894c93ad51fbd3f5658bcf1db4165931","modified":1480188366866},{"_id":"public/tags/book/index.html","hash":"1c8f39892c53bdbab14e0ee195d10068cf69d036","modified":1480188366866},{"_id":"public/tags/development/index.html","hash":"f38224beb57ba9460389d79bb1063087ccf3f06a","modified":1480188366866},{"_id":"public/tags/api/index.html","hash":"3558ac1698910294d710a4b1367512aa7b9cb77a","modified":1480188366866},{"_id":"public/archives/index.html","hash":"e3b89d1634287383e89df0d4cff3cbad5548de7a","modified":1480188366866},{"_id":"public/archives/page/3/index.html","hash":"693af8033d96b5c1c329414f7ec63ee0ba9fc9a9","modified":1480188366867},{"_id":"public/archives/page/4/index.html","hash":"4f9fdae84faa0951f2dee07cb3f3ef6457d2ca17","modified":1480188366867},{"_id":"public/archives/page/2/index.html","hash":"f3a1ab17cc9e82bdf04e114f375f658ed2753e9d","modified":1480188366867},{"_id":"public/archives/2016/index.html","hash":"d1bdd2fbd73b1ce952bce87f1c78dc1848f77b37","modified":1480188366867},{"_id":"public/archives/2016/page/2/index.html","hash":"f3dccbe707d0156d24a6f6fd05671265e06b3670","modified":1480188366867},{"_id":"public/archives/2016/page/3/index.html","hash":"723d43299b10b61dbb9a980083b46fac6516a822","modified":1480188366867},{"_id":"public/archives/2016/page/4/index.html","hash":"0b1328bc7c2a6ca9a96d722f83b8fac3e6054349","modified":1480188366867},{"_id":"public/archives/2016/11/index.html","hash":"b7b52632bf69aa80109f1d38373b6bcc281b6765","modified":1480188366870},{"_id":"public/archives/2016/11/page/2/index.html","hash":"52691d2cac9e6dffa022fd96dc377d45c777c0ab","modified":1480188366870},{"_id":"public/archives/2016/11/page/3/index.html","hash":"c344b2a9ea0254691649af746db927441325bdf9","modified":1480188366870},{"_id":"public/archives/2016/11/page/4/index.html","hash":"73a685bf5330d70fc9b41f632aea343042640279","modified":1480188366870},{"_id":"public/index.html","hash":"6e809fb296fc0bcb9d7dd96a48f08dc01b15f53c","modified":1480188366870},{"_id":"public/page/2/index.html","hash":"908845bb4d338009e879356822426036ab41ed14","modified":1480188366871},{"_id":"public/page/3/index.html","hash":"c6ed4ca784d7a583db20b87c724854b40085b2ce","modified":1480188366871},{"_id":"public/page/4/index.html","hash":"e500ab7a03abc95781d49b5180ca582c3d4d952e","modified":1480188366871},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1480188366871},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1480188366871},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1480188366871},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1480188366871},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1480188366871},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1480188366871},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1480188366871},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1480188366871},{"_id":"public/css/images/logo.png","hash":"f5fd1c37a281d60440362c43216cb7f3f670a412","modified":1480188366871},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1480188366871},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1480188366871},{"_id":"public/webfonts/ptserif/fonts/03aPdn7fFF3H6ngCgAlQzPk_vArhqVIZ0nv9q090hN8.woff2","hash":"fa8cc541ddc3da23a5a90b08e64e4c12944c56a1","modified":1480188366871},{"_id":"public/webfonts/ptserif/fonts/3Nwg9VzlwLXPq3fNKwVRMCEAvth_LlrfE80CYdSH47w.woff2","hash":"703369bb4159f050b38ecc4f52cfadb8e5760775","modified":1480188366871},{"_id":"public/webfonts/ptserif/fonts/5hX15RUpPERmeybVlLQEWBTbgVql8nDJpwnrE27mub0.woff2","hash":"0c79a0581c3472e6bb29082092ea37d897370473","modified":1480188366871},{"_id":"public/webfonts/ptserif/fonts/CPRt--GVMETgA6YEaoGitxTbgVql8nDJpwnrE27mub0.woff2","hash":"4da92f4f265caa786469ec415cfa6515d2997943","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/I-OtoJZa3TeyH6D9oli3ifesZW2xOQ-xsNqO47m55DA.woff2","hash":"36225cd511b12ed61f3e3fbad53773119e9dd73e","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/O_WhD9hODL16N4KLHLX7xSEAvth_LlrfE80CYdSH47w.woff2","hash":"950d5547dc10d4a1bdb837439fcfc6c68bbe1b02","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpCYE0-AqJ3nfInTTiDXDjU4.woff2","hash":"5984003d117f49ae596bde0498310ed215ac3aba","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDTOQ_MqJVwkKsUn0wKzc2I.woff2","hash":"b64d3a0d20efa14e6063070eb30fbdb594bde59c","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpDUj_cnvWIuuBMVgbX098Mw.woff2","hash":"6f1e434623e2fa20ba8972a6f97dd9c800b56168","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/b31S45a_TNgaBApZhTgE6CEAvth_LlrfE80CYdSH47w.woff2","hash":"0b4aef50c2979164681fa6dfe2c1d6bd6be6bcd3","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/QABk9IxT-LFTJ_dQzv7xpI4P5ICox8Kq3LLUNMylGO4.woff2","hash":"df9999766ca9ffe9428b139931352cd821526aed","modified":1480188366872},{"_id":"public/webfonts/ptserif/fonts/fU0HAfLiPHGlZhZpY6M7dBTbgVql8nDJpwnrE27mub0.woff2","hash":"3f425d6aee0c07774a10d82dcb742e32b067f217","modified":1480188366872},{"_id":"public/webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","hash":"942addaec4d3a60af33947a84a3d85f926015947","modified":1480188366872},{"_id":"public/webfonts/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","hash":"b0e0bb5ef78db8b15d430d0b9be9d4329289a310","modified":1480188366872},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1480188367542},{"_id":"public/js/script.js","hash":"631cc4a69bc1f7903a24544b79b8e6ea68be9243","modified":1480188367548},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1480188367549},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1480188367549},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1480188367549},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1480188367549},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1480188367549},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1480188367549},{"_id":"public/webfonts/ptserif/main.css","hash":"ec6a269189b9a8b807fb4e1de6ffd7acc6a7fea8","modified":1480188367549},{"_id":"public/webfonts/source-code-pro/main.css","hash":"e6a0204ff3c501d6248d96e55aa20d0b42b45a79","modified":1480188367549},{"_id":"public/css/style.css","hash":"37dd13e1f04dcc29d72981a4abae98a26ebbed9e","modified":1480188367549},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1480188367549},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1480188367549},{"_id":"public/js/jquery.min.js","hash":"a6eedf84389e1bc9f757bc2d19538f8c8d1cae9d","modified":1480188367549},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1480188367549}],"Category":[],"Data":[],"Page":[{"title":"Tags","layout":"tags","_content":"","source":"tags/index.md","raw":"title: \"Tags\"\nlayout: \"tags\"\n---\n","date":"2016-11-26T19:05:35.000Z","updated":"2016-11-26T19:05:35.000Z","path":"tags/index.html","comments":1,"_id":"civzlxo7t0001gkurr6ezwr61","content":"","excerpt":"","more":""},{"title":"Categories","layout":"categories","_content":"","source":"categories/index.md","raw":"title: \"Categories\"\nlayout: \"categories\"\n---\n","date":"2016-11-26T19:05:27.000Z","updated":"2016-11-26T19:05:27.000Z","path":"categories/index.html","comments":1,"_id":"civzlxobd003qgkurwa14nn06","content":"","excerpt":"","more":""}],"Post":[{"title":"Настройка стека nginx – uwsgi – web2py в CentOS","_content":"Как сообщает Википедия, WSGI – это простой и универсальный низкоуровневый интерфейс между веб-сервером и веб-приложением/фреймворком, написанном на Python’е.\n\nВ WSGI существуют понятия “server”, или “gateway”, и “application”, или “framework”. Наиболее распространённым middleware для реализации обмена через WSGI является uWSGI. Для веб-сервера uWSGI выступает в роли “application”, для приложения – в роли “server”.\nnginx имеет нативную поддержку uwsgi, что не может не радовать.\n\nВ качестве “приложения” в моём случае будет выступать фреймворк web2py – очень удобная штука, позволяет быстро разрабатывать веб-приложения. Имеет встроенный Twitter bootstrap и DAL (Database Abstraction Layer).\n\nНастройка nginx заключается в создании нового блока `server{}`, пример конфигурации для web2py:\n\n```\nserver {\n    listen          80;\n    server_name     web2py.example.com;\n\n    location ~* /(\\w+)/static/ {\n        root /var/www/web2py/applications/;\n    }\n\n    location / {\n        uwsgi_pass      127.0.0.1:9001;\n        include         uwsgi_params;\n        uwsgi_param     UWSGI_SCHEME $scheme;\n    }\n}\n```\n\nФактически, достаточно указать директиве `uwsgi_pass` сокет демона uWSGI (TCP/IP или Unix domain) и подключить директивы из файла `uwsgi_params`, входящего в стандартную поставку nginx.\n\nНастройка uWSGI заключается в настройке родительского процесса, называемого Emperor, и одного или нескольких “вассалов” – пулов обработчиков. Надо лишь не забыть помимо самого uwsgi установить к нему плагин python:\n\n```\nyum install uwsgi-plugin-python\n```\n\nДело в том, что uwsgi, как я уже говорил – middleware, бэкендом может служить не только Python, но и PHP, Perl, Ruby, Lua, Go и пр. Вообще uwsgi богат возможностями – поддерживает различные модели управления обработчиками (prefork, threaded, asynchronous/evented, green thread/coroutine), кластеризацию, мониторинг и т.д.\n\nВот пример конфигурационного файла “императора” и пула для web2py.\n\n```ini\n[uwsgi]\nuid = uwsgi\ngid = uwsgi\npidfile = /run/uwsgi/uwsgi.pid\nemperor = /etc/uwsgi.d\nstats = /run/uwsgi/stats.sock\nemperor-tyrant = true\ncap = setgid,setuid\nplugins = python\n```\n\n```xml\n<uwsgi>\n    <uid>nginx</uid>\n    <gid>nginx</gid>\n    <plugin>python</plugin>\n    <socket>127.0.0.1:9001</socket>\n    <pythonpath>/var/www/web2py/</pythonpath>\n    <module>wsgihandler</module>\n    <processes>3</processes>\n    <harakiri>60</harakiri>\n    <reload-mercy>8</reload-mercy>\n    <cpu-affinity>1</cpu-affinity>\n    <max-requests>2000</max-requests>\n    <limit-as>512</limit-as>\n    <reload-on-as>256</reload-on-as>\n    <reload-on-rss>192</reload-on-rss>\n    <no-orphans/>\n</uwsgi>\n```\n\nТеперь о подводных камнях.\n\n* Владельцем файла настроек пула `/etc/uwsgi.d/web2py.xml` должен быть пользователь, указанный в теге , иначе вы увидите ошибку “invalid permissions”.\n* Процессы uwsgi не завершаются по SIGTERM. Они лишь перечитывают конфиг. Завершаются же они по SIGQUIT. Конфигурационная опция `–die-on-term` инвертирует интерпретацию данных сигналов.\n* Для работы фреймворка web2py требуется сделать символическую ссылку из `/var/www/web2py/handlers/wsgihandler.py` в корень фреймворка.\n* Доступ к административной части web2py обязательно должен осуществляться по HTTPS.\n* Хэш пароля администратора должен храниться в файле `parameters_<port>.py` в корне фреймворка, где – тот порт, через который осуществляется доступ к веб-приложению. Т.е. если uwsgi запущен на localhost:9001, но вы ставите его за nginx и подключаетесь по HTTPS, то файл должен называться `parameters_443.py`. В любом случае, корректное имя файла можно узнать из трассировки системных вызовов обработчика uwsgi.\n\nСсылки:\n[http://uwsgi-docs.readthedocs.org http://www.web2py.com](http://uwsgi-docs.readthedocs.org http://www.web2py.com)\n","source":"_posts/2015-06-17-centos-web2py.md","raw":"---\ntitle: Настройка стека nginx – uwsgi – web2py в CentOS\ntags: [nginx, python, uwsgi]\n---\nКак сообщает Википедия, WSGI – это простой и универсальный низкоуровневый интерфейс между веб-сервером и веб-приложением/фреймворком, написанном на Python’е.\n\nВ WSGI существуют понятия “server”, или “gateway”, и “application”, или “framework”. Наиболее распространённым middleware для реализации обмена через WSGI является uWSGI. Для веб-сервера uWSGI выступает в роли “application”, для приложения – в роли “server”.\nnginx имеет нативную поддержку uwsgi, что не может не радовать.\n\nВ качестве “приложения” в моём случае будет выступать фреймворк web2py – очень удобная штука, позволяет быстро разрабатывать веб-приложения. Имеет встроенный Twitter bootstrap и DAL (Database Abstraction Layer).\n\nНастройка nginx заключается в создании нового блока `server{}`, пример конфигурации для web2py:\n\n```\nserver {\n    listen          80;\n    server_name     web2py.example.com;\n\n    location ~* /(\\w+)/static/ {\n        root /var/www/web2py/applications/;\n    }\n\n    location / {\n        uwsgi_pass      127.0.0.1:9001;\n        include         uwsgi_params;\n        uwsgi_param     UWSGI_SCHEME $scheme;\n    }\n}\n```\n\nФактически, достаточно указать директиве `uwsgi_pass` сокет демона uWSGI (TCP/IP или Unix domain) и подключить директивы из файла `uwsgi_params`, входящего в стандартную поставку nginx.\n\nНастройка uWSGI заключается в настройке родительского процесса, называемого Emperor, и одного или нескольких “вассалов” – пулов обработчиков. Надо лишь не забыть помимо самого uwsgi установить к нему плагин python:\n\n```\nyum install uwsgi-plugin-python\n```\n\nДело в том, что uwsgi, как я уже говорил – middleware, бэкендом может служить не только Python, но и PHP, Perl, Ruby, Lua, Go и пр. Вообще uwsgi богат возможностями – поддерживает различные модели управления обработчиками (prefork, threaded, asynchronous/evented, green thread/coroutine), кластеризацию, мониторинг и т.д.\n\nВот пример конфигурационного файла “императора” и пула для web2py.\n\n```ini\n[uwsgi]\nuid = uwsgi\ngid = uwsgi\npidfile = /run/uwsgi/uwsgi.pid\nemperor = /etc/uwsgi.d\nstats = /run/uwsgi/stats.sock\nemperor-tyrant = true\ncap = setgid,setuid\nplugins = python\n```\n\n```xml\n<uwsgi>\n    <uid>nginx</uid>\n    <gid>nginx</gid>\n    <plugin>python</plugin>\n    <socket>127.0.0.1:9001</socket>\n    <pythonpath>/var/www/web2py/</pythonpath>\n    <module>wsgihandler</module>\n    <processes>3</processes>\n    <harakiri>60</harakiri>\n    <reload-mercy>8</reload-mercy>\n    <cpu-affinity>1</cpu-affinity>\n    <max-requests>2000</max-requests>\n    <limit-as>512</limit-as>\n    <reload-on-as>256</reload-on-as>\n    <reload-on-rss>192</reload-on-rss>\n    <no-orphans/>\n</uwsgi>\n```\n\nТеперь о подводных камнях.\n\n* Владельцем файла настроек пула `/etc/uwsgi.d/web2py.xml` должен быть пользователь, указанный в теге , иначе вы увидите ошибку “invalid permissions”.\n* Процессы uwsgi не завершаются по SIGTERM. Они лишь перечитывают конфиг. Завершаются же они по SIGQUIT. Конфигурационная опция `–die-on-term` инвертирует интерпретацию данных сигналов.\n* Для работы фреймворка web2py требуется сделать символическую ссылку из `/var/www/web2py/handlers/wsgihandler.py` в корень фреймворка.\n* Доступ к административной части web2py обязательно должен осуществляться по HTTPS.\n* Хэш пароля администратора должен храниться в файле `parameters_<port>.py` в корне фреймворка, где – тот порт, через который осуществляется доступ к веб-приложению. Т.е. если uwsgi запущен на localhost:9001, но вы ставите его за nginx и подключаетесь по HTTPS, то файл должен называться `parameters_443.py`. В любом случае, корректное имя файла можно узнать из трассировки системных вызовов обработчика uwsgi.\n\nСсылки:\n[http://uwsgi-docs.readthedocs.org http://www.web2py.com](http://uwsgi-docs.readthedocs.org http://www.web2py.com)\n","slug":"2015-06-17-centos-web2py","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo7p0000gkurvzn52p7n","content":"<p>Как сообщает Википедия, WSGI – это простой и универсальный низкоуровневый интерфейс между веб-сервером и веб-приложением/фреймворком, написанном на Python’е.</p>\n<p>В WSGI существуют понятия “server”, или “gateway”, и “application”, или “framework”. Наиболее распространённым middleware для реализации обмена через WSGI является uWSGI. Для веб-сервера uWSGI выступает в роли “application”, для приложения – в роли “server”.<br>nginx имеет нативную поддержку uwsgi, что не может не радовать.</p>\n<p>В качестве “приложения” в моём случае будет выступать фреймворк web2py – очень удобная штука, позволяет быстро разрабатывать веб-приложения. Имеет встроенный Twitter bootstrap и DAL (Database Abstraction Layer).</p>\n<p>Настройка nginx заключается в создании нового блока <code>server{}</code>, пример конфигурации для web2py:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen          80;</div><div class=\"line\">    server_name     web2py.example.com;</div><div class=\"line\"></div><div class=\"line\">    location ~* /(\\w+)/static/ &#123;</div><div class=\"line\">        root /var/www/web2py/applications/;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    location / &#123;</div><div class=\"line\">        uwsgi_pass      127.0.0.1:9001;</div><div class=\"line\">        include         uwsgi_params;</div><div class=\"line\">        uwsgi_param     UWSGI_SCHEME $scheme;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Фактически, достаточно указать директиве <code>uwsgi_pass</code> сокет демона uWSGI (TCP/IP или Unix domain) и подключить директивы из файла <code>uwsgi_params</code>, входящего в стандартную поставку nginx.</p>\n<p>Настройка uWSGI заключается в настройке родительского процесса, называемого Emperor, и одного или нескольких “вассалов” – пулов обработчиков. Надо лишь не забыть помимо самого uwsgi установить к нему плагин python:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install uwsgi-plugin-python</div></pre></td></tr></table></figure>\n<p>Дело в том, что uwsgi, как я уже говорил – middleware, бэкендом может служить не только Python, но и PHP, Perl, Ruby, Lua, Go и пр. Вообще uwsgi богат возможностями – поддерживает различные модели управления обработчиками (prefork, threaded, asynchronous/evented, green thread/coroutine), кластеризацию, мониторинг и т.д.</p>\n<p>Вот пример конфигурационного файла “императора” и пула для web2py.</p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"section\">[uwsgi]</span></div><div class=\"line\"><span class=\"attr\">uid</span> = uwsgi</div><div class=\"line\"><span class=\"attr\">gid</span> = uwsgi</div><div class=\"line\"><span class=\"attr\">pidfile</span> = /run/uwsgi/uwsgi.pid</div><div class=\"line\"><span class=\"attr\">emperor</span> = /etc/uwsgi.d</div><div class=\"line\"><span class=\"attr\">stats</span> = /run/uwsgi/stats.sock</div><div class=\"line\"><span class=\"attr\">emperor-tyrant</span> = <span class=\"literal\">true</span></div><div class=\"line\"><span class=\"attr\">cap</span> = setgid,setuid</div><div class=\"line\"><span class=\"attr\">plugins</span> = python</div></pre></td></tr></table></figure>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">uwsgi</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">uid</span>&gt;</span>nginx<span class=\"tag\">&lt;/<span class=\"name\">uid</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">gid</span>&gt;</span>nginx<span class=\"tag\">&lt;/<span class=\"name\">gid</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span>python<span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">socket</span>&gt;</span>127.0.0.1:9001<span class=\"tag\">&lt;/<span class=\"name\">socket</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">pythonpath</span>&gt;</span>/var/www/web2py/<span class=\"tag\">&lt;/<span class=\"name\">pythonpath</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>wsgihandler<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">processes</span>&gt;</span>3<span class=\"tag\">&lt;/<span class=\"name\">processes</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">harakiri</span>&gt;</span>60<span class=\"tag\">&lt;/<span class=\"name\">harakiri</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">reload-mercy</span>&gt;</span>8<span class=\"tag\">&lt;/<span class=\"name\">reload-mercy</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">cpu-affinity</span>&gt;</span>1<span class=\"tag\">&lt;/<span class=\"name\">cpu-affinity</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">max-requests</span>&gt;</span>2000<span class=\"tag\">&lt;/<span class=\"name\">max-requests</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">limit-as</span>&gt;</span>512<span class=\"tag\">&lt;/<span class=\"name\">limit-as</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">reload-on-as</span>&gt;</span>256<span class=\"tag\">&lt;/<span class=\"name\">reload-on-as</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">reload-on-rss</span>&gt;</span>192<span class=\"tag\">&lt;/<span class=\"name\">reload-on-rss</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">no-orphans</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">uwsgi</span>&gt;</span></div></pre></td></tr></table></figure>\n<p>Теперь о подводных камнях.</p>\n<ul>\n<li>Владельцем файла настроек пула <code>/etc/uwsgi.d/web2py.xml</code> должен быть пользователь, указанный в теге , иначе вы увидите ошибку “invalid permissions”.</li>\n<li>Процессы uwsgi не завершаются по SIGTERM. Они лишь перечитывают конфиг. Завершаются же они по SIGQUIT. Конфигурационная опция <code>–die-on-term</code> инвертирует интерпретацию данных сигналов.</li>\n<li>Для работы фреймворка web2py требуется сделать символическую ссылку из <code>/var/www/web2py/handlers/wsgihandler.py</code> в корень фреймворка.</li>\n<li>Доступ к административной части web2py обязательно должен осуществляться по HTTPS.</li>\n<li>Хэш пароля администратора должен храниться в файле <code>parameters_&lt;port&gt;.py</code> в корне фреймворка, где – тот порт, через который осуществляется доступ к веб-приложению. Т.е. если uwsgi запущен на localhost:9001, но вы ставите его за nginx и подключаетесь по HTTPS, то файл должен называться <code>parameters_443.py</code>. В любом случае, корректное имя файла можно узнать из трассировки системных вызовов обработчика uwsgi.</li>\n</ul>\n<p>Ссылки:<br><a href=\"http://uwsgi-docs.readthedocs.org http://www.web2py.com\" target=\"_blank\" rel=\"external\">http://uwsgi-docs.readthedocs.org http://www.web2py.com</a></p>\n","excerpt":"","more":"<p>Как сообщает Википедия, WSGI – это простой и универсальный низкоуровневый интерфейс между веб-сервером и веб-приложением/фреймворком, написанном на Python’е.</p>\n<p>В WSGI существуют понятия “server”, или “gateway”, и “application”, или “framework”. Наиболее распространённым middleware для реализации обмена через WSGI является uWSGI. Для веб-сервера uWSGI выступает в роли “application”, для приложения – в роли “server”.<br>nginx имеет нативную поддержку uwsgi, что не может не радовать.</p>\n<p>В качестве “приложения” в моём случае будет выступать фреймворк web2py – очень удобная штука, позволяет быстро разрабатывать веб-приложения. Имеет встроенный Twitter bootstrap и DAL (Database Abstraction Layer).</p>\n<p>Настройка nginx заключается в создании нового блока <code>server{}</code>, пример конфигурации для web2py:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">server &#123;</div><div class=\"line\">    listen          80;</div><div class=\"line\">    server_name     web2py.example.com;</div><div class=\"line\"></div><div class=\"line\">    location ~* /(\\w+)/static/ &#123;</div><div class=\"line\">        root /var/www/web2py/applications/;</div><div class=\"line\">    &#125;</div><div class=\"line\"></div><div class=\"line\">    location / &#123;</div><div class=\"line\">        uwsgi_pass      127.0.0.1:9001;</div><div class=\"line\">        include         uwsgi_params;</div><div class=\"line\">        uwsgi_param     UWSGI_SCHEME $scheme;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Фактически, достаточно указать директиве <code>uwsgi_pass</code> сокет демона uWSGI (TCP/IP или Unix domain) и подключить директивы из файла <code>uwsgi_params</code>, входящего в стандартную поставку nginx.</p>\n<p>Настройка uWSGI заключается в настройке родительского процесса, называемого Emperor, и одного или нескольких “вассалов” – пулов обработчиков. Надо лишь не забыть помимо самого uwsgi установить к нему плагин python:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">yum install uwsgi-plugin-python</div></pre></td></tr></table></figure>\n<p>Дело в том, что uwsgi, как я уже говорил – middleware, бэкендом может служить не только Python, но и PHP, Perl, Ruby, Lua, Go и пр. Вообще uwsgi богат возможностями – поддерживает различные модели управления обработчиками (prefork, threaded, asynchronous/evented, green thread/coroutine), кластеризацию, мониторинг и т.д.</p>\n<p>Вот пример конфигурационного файла “императора” и пула для web2py.</p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"section\">[uwsgi]</span></div><div class=\"line\"><span class=\"attr\">uid</span> = uwsgi</div><div class=\"line\"><span class=\"attr\">gid</span> = uwsgi</div><div class=\"line\"><span class=\"attr\">pidfile</span> = /run/uwsgi/uwsgi.pid</div><div class=\"line\"><span class=\"attr\">emperor</span> = /etc/uwsgi.d</div><div class=\"line\"><span class=\"attr\">stats</span> = /run/uwsgi/stats.sock</div><div class=\"line\"><span class=\"attr\">emperor-tyrant</span> = <span class=\"literal\">true</span></div><div class=\"line\"><span class=\"attr\">cap</span> = setgid,setuid</div><div class=\"line\"><span class=\"attr\">plugins</span> = python</div></pre></td></tr></table></figure>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">uwsgi</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">uid</span>&gt;</span>nginx<span class=\"tag\">&lt;/<span class=\"name\">uid</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">gid</span>&gt;</span>nginx<span class=\"tag\">&lt;/<span class=\"name\">gid</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span>python<span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">socket</span>&gt;</span>127.0.0.1:9001<span class=\"tag\">&lt;/<span class=\"name\">socket</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">pythonpath</span>&gt;</span>/var/www/web2py/<span class=\"tag\">&lt;/<span class=\"name\">pythonpath</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>wsgihandler<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">processes</span>&gt;</span>3<span class=\"tag\">&lt;/<span class=\"name\">processes</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">harakiri</span>&gt;</span>60<span class=\"tag\">&lt;/<span class=\"name\">harakiri</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">reload-mercy</span>&gt;</span>8<span class=\"tag\">&lt;/<span class=\"name\">reload-mercy</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">cpu-affinity</span>&gt;</span>1<span class=\"tag\">&lt;/<span class=\"name\">cpu-affinity</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">max-requests</span>&gt;</span>2000<span class=\"tag\">&lt;/<span class=\"name\">max-requests</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">limit-as</span>&gt;</span>512<span class=\"tag\">&lt;/<span class=\"name\">limit-as</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">reload-on-as</span>&gt;</span>256<span class=\"tag\">&lt;/<span class=\"name\">reload-on-as</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">reload-on-rss</span>&gt;</span>192<span class=\"tag\">&lt;/<span class=\"name\">reload-on-rss</span>&gt;</span></div><div class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">no-orphans</span>/&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">uwsgi</span>&gt;</span></div></pre></td></tr></table></figure>\n<p>Теперь о подводных камнях.</p>\n<ul>\n<li>Владельцем файла настроек пула <code>/etc/uwsgi.d/web2py.xml</code> должен быть пользователь, указанный в теге , иначе вы увидите ошибку “invalid permissions”.</li>\n<li>Процессы uwsgi не завершаются по SIGTERM. Они лишь перечитывают конфиг. Завершаются же они по SIGQUIT. Конфигурационная опция <code>–die-on-term</code> инвертирует интерпретацию данных сигналов.</li>\n<li>Для работы фреймворка web2py требуется сделать символическую ссылку из <code>/var/www/web2py/handlers/wsgihandler.py</code> в корень фреймворка.</li>\n<li>Доступ к административной части web2py обязательно должен осуществляться по HTTPS.</li>\n<li>Хэш пароля администратора должен храниться в файле <code>parameters_&lt;port&gt;.py</code> в корне фреймворка, где – тот порт, через который осуществляется доступ к веб-приложению. Т.е. если uwsgi запущен на localhost:9001, но вы ставите его за nginx и подключаетесь по HTTPS, то файл должен называться <code>parameters_443.py</code>. В любом случае, корректное имя файла можно узнать из трассировки системных вызовов обработчика uwsgi.</li>\n</ul>\n<p>Ссылки:<br><a href=\"http://uwsgi-docs.readthedocs.org http://www.web2py.com\">http://uwsgi-docs.readthedocs.org http://www.web2py.com</a></p>\n"},{"title":"Удаление дисков из системы в Linux","_content":"Перед физическим извлечение дисков в Linux следует отключить их от SATA-контроллера:\n\n```\necho 1 > /sys/block/sdc/device/delete\n```\n","source":"_posts/2015-06-17-delete-block-device.md","raw":"---\ntitle: Удаление дисков из системы в Linux\ntags: [hardware]\n---\nПеред физическим извлечение дисков в Linux следует отключить их от SATA-контроллера:\n\n```\necho 1 > /sys/block/sdc/device/delete\n```\n","slug":"2015-06-17-delete-block-device","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo7v0002gkur0oprp9va","content":"<p>Перед физическим извлечение дисков в Linux следует отключить их от SATA-контроллера:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">echo 1 &gt; /sys/block/sdc/device/delete</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>Перед физическим извлечение дисков в Linux следует отключить их от SATA-контроллера:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">echo 1 &gt; /sys/block/sdc/device/delete</div></pre></td></tr></table></figure>\n"},{"title":"Отключение Zend Memory Manager","_content":"Интерпретатор PHP Zend Engine включает в себя такой компонент как Zend Memory Manager.\nТаким образом, PHP сам управляет памятью, позволяя отслеживать выделения памяти для предотвращения утечек и ограничивать потребление памяти для каждого отдельно взятого сценария.\nИногда, например, при возникновении в сценарии ошибки сегментации, бывает полезным отключить Zend Memory Manager (в таком случае интерпретатор начинает использовать стандартные средства ОС для работы с памятью). Делается это установкой переменной окружения USE_ZEND_ALLOC в 0.\n\nЕсли вы используете Apache, наиболее удобные способы установить данную переменную – добавить в init-скрипт веб-сервера строку\n\n```\nexport USE_ZEND_ALLOC=0\n```\n\nили указать в конфигурационном файле Apache директиву\n\n```\nSetEnv USE_ZEND_ALLOC 0\n```\n\nСсылки:\n[http://www.php.net/manual/en/internals2.memory.php](http://www.php.net/manual/en/internals2.memory.php)\n","source":"_posts/2015-06-17-disable-zendmm.md","raw":"---\ntitle: Отключение Zend Memory Manager\ntags: [php, apache]\n---\nИнтерпретатор PHP Zend Engine включает в себя такой компонент как Zend Memory Manager.\nТаким образом, PHP сам управляет памятью, позволяя отслеживать выделения памяти для предотвращения утечек и ограничивать потребление памяти для каждого отдельно взятого сценария.\nИногда, например, при возникновении в сценарии ошибки сегментации, бывает полезным отключить Zend Memory Manager (в таком случае интерпретатор начинает использовать стандартные средства ОС для работы с памятью). Делается это установкой переменной окружения USE_ZEND_ALLOC в 0.\n\nЕсли вы используете Apache, наиболее удобные способы установить данную переменную – добавить в init-скрипт веб-сервера строку\n\n```\nexport USE_ZEND_ALLOC=0\n```\n\nили указать в конфигурационном файле Apache директиву\n\n```\nSetEnv USE_ZEND_ALLOC 0\n```\n\nСсылки:\n[http://www.php.net/manual/en/internals2.memory.php](http://www.php.net/manual/en/internals2.memory.php)\n","slug":"2015-06-17-disable-zendmm","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo800004gkurbagjbksp","content":"<p>Интерпретатор PHP Zend Engine включает в себя такой компонент как Zend Memory Manager.<br>Таким образом, PHP сам управляет памятью, позволяя отслеживать выделения памяти для предотвращения утечек и ограничивать потребление памяти для каждого отдельно взятого сценария.<br>Иногда, например, при возникновении в сценарии ошибки сегментации, бывает полезным отключить Zend Memory Manager (в таком случае интерпретатор начинает использовать стандартные средства ОС для работы с памятью). Делается это установкой переменной окружения USE_ZEND_ALLOC в 0.</p>\n<p>Если вы используете Apache, наиболее удобные способы установить данную переменную – добавить в init-скрипт веб-сервера строку</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">export USE_ZEND_ALLOC=0</div></pre></td></tr></table></figure>\n<p>или указать в конфигурационном файле Apache директиву</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">SetEnv USE_ZEND_ALLOC 0</div></pre></td></tr></table></figure>\n<p>Ссылки:<br><a href=\"http://www.php.net/manual/en/internals2.memory.php\" target=\"_blank\" rel=\"external\">http://www.php.net/manual/en/internals2.memory.php</a></p>\n","excerpt":"","more":"<p>Интерпретатор PHP Zend Engine включает в себя такой компонент как Zend Memory Manager.<br>Таким образом, PHP сам управляет памятью, позволяя отслеживать выделения памяти для предотвращения утечек и ограничивать потребление памяти для каждого отдельно взятого сценария.<br>Иногда, например, при возникновении в сценарии ошибки сегментации, бывает полезным отключить Zend Memory Manager (в таком случае интерпретатор начинает использовать стандартные средства ОС для работы с памятью). Делается это установкой переменной окружения USE_ZEND_ALLOC в 0.</p>\n<p>Если вы используете Apache, наиболее удобные способы установить данную переменную – добавить в init-скрипт веб-сервера строку</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">export USE_ZEND_ALLOC=0</div></pre></td></tr></table></figure>\n<p>или указать в конфигурационном файле Apache директиву</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">SetEnv USE_ZEND_ALLOC 0</div></pre></td></tr></table></figure>\n<p>Ссылки:<br><a href=\"http://www.php.net/manual/en/internals2.memory.php\">http://www.php.net/manual/en/internals2.memory.php</a></p>\n"},{"title":"dnsmasq и /etc/hosts","_content":"Я использую dnsmasq в качестве ресолвера и DHCP-сервера для офиса. Демон также ресолвит имена из локального файла hosts.\nЕсли в hosts указано два имени через запятую для одного IP-адреса, то dnsmasq будет ресолвить только последнее. Чтобы избежать этой ситуации, достаточно создать две строчки для этого IP в hosts.\n","source":"_posts/2015-06-17-dnsmasq.md","raw":"---\ntitle: dnsmasq и /etc/hosts\ntags: [dns, dhcp]\n---\nЯ использую dnsmasq в качестве ресолвера и DHCP-сервера для офиса. Демон также ресолвит имена из локального файла hosts.\nЕсли в hosts указано два имени через запятую для одного IP-адреса, то dnsmasq будет ресолвить только последнее. Чтобы избежать этой ситуации, достаточно создать две строчки для этого IP в hosts.\n","slug":"2015-06-17-dnsmasq","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo850005gkurjn0m667e","content":"<p>Я использую dnsmasq в качестве ресолвера и DHCP-сервера для офиса. Демон также ресолвит имена из локального файла hosts.<br>Если в hosts указано два имени через запятую для одного IP-адреса, то dnsmasq будет ресолвить только последнее. Чтобы избежать этой ситуации, достаточно создать две строчки для этого IP в hosts.</p>\n","excerpt":"","more":"<p>Я использую dnsmasq в качестве ресолвера и DHCP-сервера для офиса. Демон также ресолвит имена из локального файла hosts.<br>Если в hosts указано два имени через запятую для одного IP-адреса, то dnsmasq будет ресолвить только последнее. Чтобы избежать этой ситуации, достаточно создать две строчки для этого IP в hosts.</p>\n"},{"title":"Разрешение коротких имён с помощью gethostbyname()","_content":"Сегодня обнаружил особенность работы функции gethostbyname() стандартной библиотеки C в Linux.\n\nПри указании в качестве аргумента короткого имени, к нему автоматически добавляется домен машины. В моём окружении данное поведение нежелательно, так как короткое имя и FQDN резолвятся в разные адреса (приватный и публичный соответственно). Ситуация легко обходится следующим образом: достаточно добавить в конце имени точку. Тогда домен добавляться не будет. Пример на Python'е:\n\n```python\n>> import socket\n>> socket.gethostbyname('hserv1')\n123.45.67.89\n>>socket.gethostbyname('hserv1.')\n192.168.0.27\n```\n\nТакое поведение настраивается. В `/etc/resolv.conf` можно указать опцию `ndots`. Если в имени меньше точек, чем `ndots`, то происходит добавление домена.\n","source":"_posts/2015-06-17-gethostbyname-ndots.md","raw":"---\ntitle: Разрешение коротких имён с помощью gethostbyname()\ntags: [dns]\n---\nСегодня обнаружил особенность работы функции gethostbyname() стандартной библиотеки C в Linux.\n\nПри указании в качестве аргумента короткого имени, к нему автоматически добавляется домен машины. В моём окружении данное поведение нежелательно, так как короткое имя и FQDN резолвятся в разные адреса (приватный и публичный соответственно). Ситуация легко обходится следующим образом: достаточно добавить в конце имени точку. Тогда домен добавляться не будет. Пример на Python'е:\n\n```python\n>> import socket\n>> socket.gethostbyname('hserv1')\n123.45.67.89\n>>socket.gethostbyname('hserv1.')\n192.168.0.27\n```\n\nТакое поведение настраивается. В `/etc/resolv.conf` можно указать опцию `ndots`. Если в имени меньше точек, чем `ndots`, то происходит добавление домена.\n","slug":"2015-06-17-gethostbyname-ndots","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8b0006gkurgxg2f7sc","content":"<p>Сегодня обнаружил особенность работы функции gethostbyname() стандартной библиотеки C в Linux.</p>\n<p>При указании в качестве аргумента короткого имени, к нему автоматически добавляется домен машины. В моём окружении данное поведение нежелательно, так как короткое имя и FQDN резолвятся в разные адреса (приватный и публичный соответственно). Ситуация легко обходится следующим образом: достаточно добавить в конце имени точку. Тогда домен добавляться не будет. Пример на Python’е:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;&gt; <span class=\"keyword\">import</span> socket</div><div class=\"line\">&gt;&gt; socket.gethostbyname(<span class=\"string\">'hserv1'</span>)</div><div class=\"line\"><span class=\"number\">123.45</span><span class=\"number\">.67</span><span class=\"number\">.89</span></div><div class=\"line\">&gt;&gt;socket.gethostbyname(<span class=\"string\">'hserv1.'</span>)</div><div class=\"line\"><span class=\"number\">192.168</span><span class=\"number\">.0</span><span class=\"number\">.27</span></div></pre></td></tr></table></figure>\n<p>Такое поведение настраивается. В <code>/etc/resolv.conf</code> можно указать опцию <code>ndots</code>. Если в имени меньше точек, чем <code>ndots</code>, то происходит добавление домена.</p>\n","excerpt":"","more":"<p>Сегодня обнаружил особенность работы функции gethostbyname() стандартной библиотеки C в Linux.</p>\n<p>При указании в качестве аргумента короткого имени, к нему автоматически добавляется домен машины. В моём окружении данное поведение нежелательно, так как короткое имя и FQDN резолвятся в разные адреса (приватный и публичный соответственно). Ситуация легко обходится следующим образом: достаточно добавить в конце имени точку. Тогда домен добавляться не будет. Пример на Python’е:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;&gt; <span class=\"keyword\">import</span> socket</div><div class=\"line\">&gt;&gt; socket.gethostbyname(<span class=\"string\">'hserv1'</span>)</div><div class=\"line\"><span class=\"number\">123.45</span><span class=\"number\">.67</span><span class=\"number\">.89</span></div><div class=\"line\">&gt;&gt;socket.gethostbyname(<span class=\"string\">'hserv1.'</span>)</div><div class=\"line\"><span class=\"number\">192.168</span><span class=\"number\">.0</span><span class=\"number\">.27</span></div></pre></td></tr></table></figure>\n<p>Такое поведение настраивается. В <code>/etc/resolv.conf</code> можно указать опцию <code>ndots</code>. Если в имени меньше точек, чем <code>ndots</code>, то происходит добавление домена.</p>\n"},{"title":"Ребилд аппаратного RAID-массива","description":"Добавляем новый диск в массив с помощью MegaCli","_content":"У физических дисков в аппаратных RAID-массивах LSI и Intel есть атрибут Firmware State – “состояние прошивки”.\n\nПри штатной работе состояние всех дисков должно быть “Online”. В случае неисправности состояние может перейти в “Failed” или “Unconfigured(bad)”.\nИногда (может, это зависит от модели контроллера и версий ПО) после замены диска на новый состояние не меняется – остаётся “Unconfigured (bad)”. В таком случае требуется добавить заменённый диск в массив вручную.\n\nВыводим информацию о физических дисках и определяем сбойный:\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PDList -aAll\nAdapter #0\nEnclosure Device ID: 252\nSlot Number: 8\nDevice Id: 8\nSequence Number: 2\nMedia Error Count: 0\nOther Error Count: 0\nPredictive Failure Count: 0\nLast Predictive Failure Event Seq Number: 0\nPD Type: SAS\nRaw Size: 140014MB [0x11177330 Sectors]\nNon Coerced Size: 139502MB [0x11077330 Sectors]\nCoerced Size: 139236MB [0x10ff2000 Sectors]\nFirmware state: Online\nSAS Address(0): 0x5000c500241370a5\nSAS Address(1): 0x0\nConnected Port Number: 1(path0)\nInquiry Data: SEAGATE ST3146356SS 00063QN4DX50\nForeign State: None\n\nEnclosure Device ID: 252\nSlot Number: 9\nDevice Id: 9\nSequence Number: 2\nMedia Error Count: 0\nOther Error Count: 0\nPredictive Failure Count: 0\nLast Predictive Failure Event Seq Number: 0\nPD Type: SAS\nRaw Size: 140014MB [0x11177330 Sectors]\nNon Coerced Size: 139502MB [0x11077330 Sectors]\nCoerced Size: 139236MB [0x10ff2000 Sectors]\nFirmware state: Unconfigured(bad)\nSAS Address(0): 0x5000c50023e46d19\nSAS Address(1): 0x0\nConnected Port Number: 2(path0)\nInquiry Data: SEAGATE ST3146356SS 00063QN4CW33\nForeign State: None\n...\n```\n\nВ данном случае сбойный диск имеет Enclosure ID 252 и Slot 9. Его идентификатор в MegaCli будет выглядеть как [252:9]. В случае, когда значение Enclosure ID равно N/A, идентификатор принимает вид [:9]. Принудительно помечаем диск как “good”:\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PDMakeGood -PhysDrv[252:9] -a0\nAdapter: 0: EnclId-252 SlotId-9 state changed to Unconfigured-Good.\n```\n\nПосле этого контроллер должен определить диск как “чужой” – “foreign”. Это значит, что контроллер нашёл на диске метаинформацию другого RAID-массива.\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Scan -a0\nThere are 1 foreign configuration(s) on controller 0. “Чужую” конфигурацию нужно очистить.\n# /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -a0\nForeign configuration 0 is cleared on controller 0.\n```\n\nОпределим положение диска в массиве. Если после заголовка Physical Disk – пустая строка, значит этот диск не является частью массива.\n\n```\n#/root/MegaRAID/MegaCli/MegaCli64 -CfgDsply -a0\n...\nDISK GROUPS: 1\nNumber of Spans: 1\nSPAN: 0           \nSpan Reference: 0x01\nNumber of PDs: 4    \nNumber of VDs: 1    \nNumber of dedicated Hotspares: 0\nVirtual Disk Information:       \nVirtual Disk: 0 (Target Id: 1)\n...\n\nPhysical Disk: 2\n\nPhysical Disk: 3\nEnclosure Device ID: 252\nSlot Number: 5          \nDevice Id: 4            \n...\n```\n\nРасположение диска в массиве идентифицируется номером массива, который соответствует Span Reference (в нашем случае 1, 0×0 следует отбросить) и номером ряда, который соответствует номеру диска (в данном случае 2). Подключим диск [252:9] в массив 1, ряд 2.\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PdReplaceMissing -PhysDrv[252:9] -array1 -row2 -a0\nAdapter: 0: Missing PD at Array 1, Row 2 is replaced\n```\n\nТеперь следует вручную запустить ребилд массива.\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PDRbld -Start -PhysDrv[252:4] -a0\nStarted rebuild progress on device(Encl-252 Slot-4)\n```\n\nCсылки: [http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS](http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS)\n","source":"_posts/2015-06-17-hw-raid-rebuild.md","raw":"---\ntitle: Ребилд аппаратного RAID-массива\ndescription: \"Добавляем новый диск в массив с помощью MegaCli\"\ntags: [hardware, storage]\n---\nУ физических дисков в аппаратных RAID-массивах LSI и Intel есть атрибут Firmware State – “состояние прошивки”.\n\nПри штатной работе состояние всех дисков должно быть “Online”. В случае неисправности состояние может перейти в “Failed” или “Unconfigured(bad)”.\nИногда (может, это зависит от модели контроллера и версий ПО) после замены диска на новый состояние не меняется – остаётся “Unconfigured (bad)”. В таком случае требуется добавить заменённый диск в массив вручную.\n\nВыводим информацию о физических дисках и определяем сбойный:\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PDList -aAll\nAdapter #0\nEnclosure Device ID: 252\nSlot Number: 8\nDevice Id: 8\nSequence Number: 2\nMedia Error Count: 0\nOther Error Count: 0\nPredictive Failure Count: 0\nLast Predictive Failure Event Seq Number: 0\nPD Type: SAS\nRaw Size: 140014MB [0x11177330 Sectors]\nNon Coerced Size: 139502MB [0x11077330 Sectors]\nCoerced Size: 139236MB [0x10ff2000 Sectors]\nFirmware state: Online\nSAS Address(0): 0x5000c500241370a5\nSAS Address(1): 0x0\nConnected Port Number: 1(path0)\nInquiry Data: SEAGATE ST3146356SS 00063QN4DX50\nForeign State: None\n\nEnclosure Device ID: 252\nSlot Number: 9\nDevice Id: 9\nSequence Number: 2\nMedia Error Count: 0\nOther Error Count: 0\nPredictive Failure Count: 0\nLast Predictive Failure Event Seq Number: 0\nPD Type: SAS\nRaw Size: 140014MB [0x11177330 Sectors]\nNon Coerced Size: 139502MB [0x11077330 Sectors]\nCoerced Size: 139236MB [0x10ff2000 Sectors]\nFirmware state: Unconfigured(bad)\nSAS Address(0): 0x5000c50023e46d19\nSAS Address(1): 0x0\nConnected Port Number: 2(path0)\nInquiry Data: SEAGATE ST3146356SS 00063QN4CW33\nForeign State: None\n...\n```\n\nВ данном случае сбойный диск имеет Enclosure ID 252 и Slot 9. Его идентификатор в MegaCli будет выглядеть как [252:9]. В случае, когда значение Enclosure ID равно N/A, идентификатор принимает вид [:9]. Принудительно помечаем диск как “good”:\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PDMakeGood -PhysDrv[252:9] -a0\nAdapter: 0: EnclId-252 SlotId-9 state changed to Unconfigured-Good.\n```\n\nПосле этого контроллер должен определить диск как “чужой” – “foreign”. Это значит, что контроллер нашёл на диске метаинформацию другого RAID-массива.\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Scan -a0\nThere are 1 foreign configuration(s) on controller 0. “Чужую” конфигурацию нужно очистить.\n# /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -a0\nForeign configuration 0 is cleared on controller 0.\n```\n\nОпределим положение диска в массиве. Если после заголовка Physical Disk – пустая строка, значит этот диск не является частью массива.\n\n```\n#/root/MegaRAID/MegaCli/MegaCli64 -CfgDsply -a0\n...\nDISK GROUPS: 1\nNumber of Spans: 1\nSPAN: 0           \nSpan Reference: 0x01\nNumber of PDs: 4    \nNumber of VDs: 1    \nNumber of dedicated Hotspares: 0\nVirtual Disk Information:       \nVirtual Disk: 0 (Target Id: 1)\n...\n\nPhysical Disk: 2\n\nPhysical Disk: 3\nEnclosure Device ID: 252\nSlot Number: 5          \nDevice Id: 4            \n...\n```\n\nРасположение диска в массиве идентифицируется номером массива, который соответствует Span Reference (в нашем случае 1, 0×0 следует отбросить) и номером ряда, который соответствует номеру диска (в данном случае 2). Подключим диск [252:9] в массив 1, ряд 2.\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PdReplaceMissing -PhysDrv[252:9] -array1 -row2 -a0\nAdapter: 0: Missing PD at Array 1, Row 2 is replaced\n```\n\nТеперь следует вручную запустить ребилд массива.\n\n```\n# /root/MegaRAID/MegaCli/MegaCli64 -PDRbld -Start -PhysDrv[252:4] -a0\nStarted rebuild progress on device(Encl-252 Slot-4)\n```\n\nCсылки: [http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS](http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS)\n","slug":"2015-06-17-hw-raid-rebuild","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8d0008gkur8s8w9vjv","content":"<p>У физических дисков в аппаратных RAID-массивах LSI и Intel есть атрибут Firmware State – “состояние прошивки”.</p>\n<p>При штатной работе состояние всех дисков должно быть “Online”. В случае неисправности состояние может перейти в “Failed” или “Unconfigured(bad)”.<br>Иногда (может, это зависит от модели контроллера и версий ПО) после замены диска на новый состояние не меняется – остаётся “Unconfigured (bad)”. В таком случае требуется добавить заменённый диск в массив вручную.</p>\n<p>Выводим информацию о физических дисках и определяем сбойный:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PDList -aAll</div><div class=\"line\">Adapter #0</div><div class=\"line\">Enclosure Device ID: 252</div><div class=\"line\">Slot Number: 8</div><div class=\"line\">Device Id: 8</div><div class=\"line\">Sequence Number: 2</div><div class=\"line\">Media Error Count: 0</div><div class=\"line\">Other Error Count: 0</div><div class=\"line\">Predictive Failure Count: 0</div><div class=\"line\">Last Predictive Failure Event Seq Number: 0</div><div class=\"line\">PD Type: SAS</div><div class=\"line\">Raw Size: 140014MB [0x11177330 Sectors]</div><div class=\"line\">Non Coerced Size: 139502MB [0x11077330 Sectors]</div><div class=\"line\">Coerced Size: 139236MB [0x10ff2000 Sectors]</div><div class=\"line\">Firmware state: Online</div><div class=\"line\">SAS Address(0): 0x5000c500241370a5</div><div class=\"line\">SAS Address(1): 0x0</div><div class=\"line\">Connected Port Number: 1(path0)</div><div class=\"line\">Inquiry Data: SEAGATE ST3146356SS 00063QN4DX50</div><div class=\"line\">Foreign State: None</div><div class=\"line\"></div><div class=\"line\">Enclosure Device ID: 252</div><div class=\"line\">Slot Number: 9</div><div class=\"line\">Device Id: 9</div><div class=\"line\">Sequence Number: 2</div><div class=\"line\">Media Error Count: 0</div><div class=\"line\">Other Error Count: 0</div><div class=\"line\">Predictive Failure Count: 0</div><div class=\"line\">Last Predictive Failure Event Seq Number: 0</div><div class=\"line\">PD Type: SAS</div><div class=\"line\">Raw Size: 140014MB [0x11177330 Sectors]</div><div class=\"line\">Non Coerced Size: 139502MB [0x11077330 Sectors]</div><div class=\"line\">Coerced Size: 139236MB [0x10ff2000 Sectors]</div><div class=\"line\">Firmware state: Unconfigured(bad)</div><div class=\"line\">SAS Address(0): 0x5000c50023e46d19</div><div class=\"line\">SAS Address(1): 0x0</div><div class=\"line\">Connected Port Number: 2(path0)</div><div class=\"line\">Inquiry Data: SEAGATE ST3146356SS 00063QN4CW33</div><div class=\"line\">Foreign State: None</div><div class=\"line\">...</div></pre></td></tr></table></figure>\n<p>В данном случае сбойный диск имеет Enclosure ID 252 и Slot 9. Его идентификатор в MegaCli будет выглядеть как [252:9]. В случае, когда значение Enclosure ID равно N/A, идентификатор принимает вид [:9]. Принудительно помечаем диск как “good”:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PDMakeGood -PhysDrv[252:9] -a0</div><div class=\"line\">Adapter: 0: EnclId-252 SlotId-9 state changed to Unconfigured-Good.</div></pre></td></tr></table></figure>\n<p>После этого контроллер должен определить диск как “чужой” – “foreign”. Это значит, что контроллер нашёл на диске метаинформацию другого RAID-массива.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Scan -a0</div><div class=\"line\">There are 1 foreign configuration(s) on controller 0. “Чужую” конфигурацию нужно очистить.</div><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -a0</div><div class=\"line\">Foreign configuration 0 is cleared on controller 0.</div></pre></td></tr></table></figure>\n<p>Определим положение диска в массиве. Если после заголовка Physical Disk – пустая строка, значит этот диск не является частью массива.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">#/root/MegaRAID/MegaCli/MegaCli64 -CfgDsply -a0</div><div class=\"line\">...</div><div class=\"line\">DISK GROUPS: 1</div><div class=\"line\">Number of Spans: 1</div><div class=\"line\">SPAN: 0           </div><div class=\"line\">Span Reference: 0x01</div><div class=\"line\">Number of PDs: 4    </div><div class=\"line\">Number of VDs: 1    </div><div class=\"line\">Number of dedicated Hotspares: 0</div><div class=\"line\">Virtual Disk Information:       </div><div class=\"line\">Virtual Disk: 0 (Target Id: 1)</div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\">Physical Disk: 2</div><div class=\"line\"></div><div class=\"line\">Physical Disk: 3</div><div class=\"line\">Enclosure Device ID: 252</div><div class=\"line\">Slot Number: 5          </div><div class=\"line\">Device Id: 4            </div><div class=\"line\">...</div></pre></td></tr></table></figure>\n<p>Расположение диска в массиве идентифицируется номером массива, который соответствует Span Reference (в нашем случае 1, 0×0 следует отбросить) и номером ряда, который соответствует номеру диска (в данном случае 2). Подключим диск [252:9] в массив 1, ряд 2.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PdReplaceMissing -PhysDrv[252:9] -array1 -row2 -a0</div><div class=\"line\">Adapter: 0: Missing PD at Array 1, Row 2 is replaced</div></pre></td></tr></table></figure>\n<p>Теперь следует вручную запустить ребилд массива.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PDRbld -Start -PhysDrv[252:4] -a0</div><div class=\"line\">Started rebuild progress on device(Encl-252 Slot-4)</div></pre></td></tr></table></figure>\n<p>Cсылки: <a href=\"http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS\" target=\"_blank\" rel=\"external\">http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS</a></p>\n","excerpt":"","more":"<p>У физических дисков в аппаратных RAID-массивах LSI и Intel есть атрибут Firmware State – “состояние прошивки”.</p>\n<p>При штатной работе состояние всех дисков должно быть “Online”. В случае неисправности состояние может перейти в “Failed” или “Unconfigured(bad)”.<br>Иногда (может, это зависит от модели контроллера и версий ПО) после замены диска на новый состояние не меняется – остаётся “Unconfigured (bad)”. В таком случае требуется добавить заменённый диск в массив вручную.</p>\n<p>Выводим информацию о физических дисках и определяем сбойный:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PDList -aAll</div><div class=\"line\">Adapter #0</div><div class=\"line\">Enclosure Device ID: 252</div><div class=\"line\">Slot Number: 8</div><div class=\"line\">Device Id: 8</div><div class=\"line\">Sequence Number: 2</div><div class=\"line\">Media Error Count: 0</div><div class=\"line\">Other Error Count: 0</div><div class=\"line\">Predictive Failure Count: 0</div><div class=\"line\">Last Predictive Failure Event Seq Number: 0</div><div class=\"line\">PD Type: SAS</div><div class=\"line\">Raw Size: 140014MB [0x11177330 Sectors]</div><div class=\"line\">Non Coerced Size: 139502MB [0x11077330 Sectors]</div><div class=\"line\">Coerced Size: 139236MB [0x10ff2000 Sectors]</div><div class=\"line\">Firmware state: Online</div><div class=\"line\">SAS Address(0): 0x5000c500241370a5</div><div class=\"line\">SAS Address(1): 0x0</div><div class=\"line\">Connected Port Number: 1(path0)</div><div class=\"line\">Inquiry Data: SEAGATE ST3146356SS 00063QN4DX50</div><div class=\"line\">Foreign State: None</div><div class=\"line\"></div><div class=\"line\">Enclosure Device ID: 252</div><div class=\"line\">Slot Number: 9</div><div class=\"line\">Device Id: 9</div><div class=\"line\">Sequence Number: 2</div><div class=\"line\">Media Error Count: 0</div><div class=\"line\">Other Error Count: 0</div><div class=\"line\">Predictive Failure Count: 0</div><div class=\"line\">Last Predictive Failure Event Seq Number: 0</div><div class=\"line\">PD Type: SAS</div><div class=\"line\">Raw Size: 140014MB [0x11177330 Sectors]</div><div class=\"line\">Non Coerced Size: 139502MB [0x11077330 Sectors]</div><div class=\"line\">Coerced Size: 139236MB [0x10ff2000 Sectors]</div><div class=\"line\">Firmware state: Unconfigured(bad)</div><div class=\"line\">SAS Address(0): 0x5000c50023e46d19</div><div class=\"line\">SAS Address(1): 0x0</div><div class=\"line\">Connected Port Number: 2(path0)</div><div class=\"line\">Inquiry Data: SEAGATE ST3146356SS 00063QN4CW33</div><div class=\"line\">Foreign State: None</div><div class=\"line\">...</div></pre></td></tr></table></figure>\n<p>В данном случае сбойный диск имеет Enclosure ID 252 и Slot 9. Его идентификатор в MegaCli будет выглядеть как [252:9]. В случае, когда значение Enclosure ID равно N/A, идентификатор принимает вид [:9]. Принудительно помечаем диск как “good”:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PDMakeGood -PhysDrv[252:9] -a0</div><div class=\"line\">Adapter: 0: EnclId-252 SlotId-9 state changed to Unconfigured-Good.</div></pre></td></tr></table></figure>\n<p>После этого контроллер должен определить диск как “чужой” – “foreign”. Это значит, что контроллер нашёл на диске метаинформацию другого RAID-массива.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Scan -a0</div><div class=\"line\">There are 1 foreign configuration(s) on controller 0. “Чужую” конфигурацию нужно очистить.</div><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -CfgForeign -Clear -a0</div><div class=\"line\">Foreign configuration 0 is cleared on controller 0.</div></pre></td></tr></table></figure>\n<p>Определим положение диска в массиве. Если после заголовка Physical Disk – пустая строка, значит этот диск не является частью массива.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">#/root/MegaRAID/MegaCli/MegaCli64 -CfgDsply -a0</div><div class=\"line\">...</div><div class=\"line\">DISK GROUPS: 1</div><div class=\"line\">Number of Spans: 1</div><div class=\"line\">SPAN: 0           </div><div class=\"line\">Span Reference: 0x01</div><div class=\"line\">Number of PDs: 4    </div><div class=\"line\">Number of VDs: 1    </div><div class=\"line\">Number of dedicated Hotspares: 0</div><div class=\"line\">Virtual Disk Information:       </div><div class=\"line\">Virtual Disk: 0 (Target Id: 1)</div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\">Physical Disk: 2</div><div class=\"line\"></div><div class=\"line\">Physical Disk: 3</div><div class=\"line\">Enclosure Device ID: 252</div><div class=\"line\">Slot Number: 5          </div><div class=\"line\">Device Id: 4            </div><div class=\"line\">...</div></pre></td></tr></table></figure>\n<p>Расположение диска в массиве идентифицируется номером массива, который соответствует Span Reference (в нашем случае 1, 0×0 следует отбросить) и номером ряда, который соответствует номеру диска (в данном случае 2). Подключим диск [252:9] в массив 1, ряд 2.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PdReplaceMissing -PhysDrv[252:9] -array1 -row2 -a0</div><div class=\"line\">Adapter: 0: Missing PD at Array 1, Row 2 is replaced</div></pre></td></tr></table></figure>\n<p>Теперь следует вручную запустить ребилд массива.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># /root/MegaRAID/MegaCli/MegaCli64 -PDRbld -Start -PhysDrv[252:4] -a0</div><div class=\"line\">Started rebuild progress on device(Encl-252 Slot-4)</div></pre></td></tr></table></figure>\n<p>Cсылки: <a href=\"http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS\">http://hwraid.le-vert.net/wiki/LSIMegaRAIDSAS</a></p>\n"},{"title":"Статистика времени выполнения запросов в MySQL","_content":"В MySQL существует возможность логирования “медленных” запросов.\n\nВ такой лог будут записаны все запросы, выполнение которых заняло более `long_query_time` секунд. Безусловно, анализ slow_log’а может помочь найти узкое место. Но, несмотря на то, что `long_query_time` можно указывать с точностью до микросекунд, бывает необходимо проанализировать общую статистику времени исполнения запросов.\n\nКомандой Percona реализована такая возможность. Посмотреть распределение можно с помощью запросов.\n\n```\nmysql> SHOW QUERY_RESPONSE_TIME;\ntime                   count   total\n0.000001               0       0.000000\n0.000010               0       0.000000\n0.000100               1       0.000072\n0.001000               0       0.000000\n0.010000               0       0.000000\n0.100000               0       0.000000\n1.000000               0       0.000000\n10.000000              8       47.268416\n100.000000             0       0.000000\n1000.000000            0       0.000000\n10000.000000           0       0.000000\n100000.000000          0       0.000000\n1000000.000000         0       0.000000\nTOO LONG QUERY         0       0.000000\n```\n\nЭти данные хранятся в таблице *INFORMATION_SCHEMA.QUERY_RESPONSE_TIME*. Например, приведённый вывод означает, что с момента запуска сервера 1 запрос был выполнен за время 0.000010 с < t < 0.000100 с, общее время выполнения запросов в данной категории – 0.000072 с. Также 8 запросов были выполнены за время 1 с < t < 10 с каждый, общее время – 47.268416 с.\nСбросить данные можно с помощью запроса\n\n```\nmysql> FLUSH QUERY_RESPONSE_TIME;\n```\n\nВообще данный функционал имеет множество различных настроек. Полная документация опубликована на сайте Percona. Разумеется, статистика недоступна в оригинальной MySQL, а лишь в Percona Server и в MariaDB.\n\nСсылки:\n[http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html](http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html)\n[https://mariadb.com/kb/en/query_response_time-plugin/](https://mariadb.com/kb/en/query_response_time-plugin/)\n[http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html](http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html)\n","source":"_posts/2015-06-17-mysql-query-statistics.md","raw":"---\ntitle: Статистика времени выполнения запросов в MySQL\ntags: [mysql]\n---\nВ MySQL существует возможность логирования “медленных” запросов.\n\nВ такой лог будут записаны все запросы, выполнение которых заняло более `long_query_time` секунд. Безусловно, анализ slow_log’а может помочь найти узкое место. Но, несмотря на то, что `long_query_time` можно указывать с точностью до микросекунд, бывает необходимо проанализировать общую статистику времени исполнения запросов.\n\nКомандой Percona реализована такая возможность. Посмотреть распределение можно с помощью запросов.\n\n```\nmysql> SHOW QUERY_RESPONSE_TIME;\ntime                   count   total\n0.000001               0       0.000000\n0.000010               0       0.000000\n0.000100               1       0.000072\n0.001000               0       0.000000\n0.010000               0       0.000000\n0.100000               0       0.000000\n1.000000               0       0.000000\n10.000000              8       47.268416\n100.000000             0       0.000000\n1000.000000            0       0.000000\n10000.000000           0       0.000000\n100000.000000          0       0.000000\n1000000.000000         0       0.000000\nTOO LONG QUERY         0       0.000000\n```\n\nЭти данные хранятся в таблице *INFORMATION_SCHEMA.QUERY_RESPONSE_TIME*. Например, приведённый вывод означает, что с момента запуска сервера 1 запрос был выполнен за время 0.000010 с < t < 0.000100 с, общее время выполнения запросов в данной категории – 0.000072 с. Также 8 запросов были выполнены за время 1 с < t < 10 с каждый, общее время – 47.268416 с.\nСбросить данные можно с помощью запроса\n\n```\nmysql> FLUSH QUERY_RESPONSE_TIME;\n```\n\nВообще данный функционал имеет множество различных настроек. Полная документация опубликована на сайте Percona. Разумеется, статистика недоступна в оригинальной MySQL, а лишь в Percona Server и в MariaDB.\n\nСсылки:\n[http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html](http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html)\n[https://mariadb.com/kb/en/query_response_time-plugin/](https://mariadb.com/kb/en/query_response_time-plugin/)\n[http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html](http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html)\n","slug":"2015-06-17-mysql-query-statistics","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8h0009gkura6k9qq5f","content":"<p>В MySQL существует возможность логирования “медленных” запросов.</p>\n<p>В такой лог будут записаны все запросы, выполнение которых заняло более <code>long_query_time</code> секунд. Безусловно, анализ slow_log’а может помочь найти узкое место. Но, несмотря на то, что <code>long_query_time</code> можно указывать с точностью до микросекунд, бывает необходимо проанализировать общую статистику времени исполнения запросов.</p>\n<p>Командой Percona реализована такая возможность. Посмотреть распределение можно с помощью запросов.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; SHOW QUERY_RESPONSE_TIME;</div><div class=\"line\">time                   count   total</div><div class=\"line\">0.000001               0       0.000000</div><div class=\"line\">0.000010               0       0.000000</div><div class=\"line\">0.000100               1       0.000072</div><div class=\"line\">0.001000               0       0.000000</div><div class=\"line\">0.010000               0       0.000000</div><div class=\"line\">0.100000               0       0.000000</div><div class=\"line\">1.000000               0       0.000000</div><div class=\"line\">10.000000              8       47.268416</div><div class=\"line\">100.000000             0       0.000000</div><div class=\"line\">1000.000000            0       0.000000</div><div class=\"line\">10000.000000           0       0.000000</div><div class=\"line\">100000.000000          0       0.000000</div><div class=\"line\">1000000.000000         0       0.000000</div><div class=\"line\">TOO LONG QUERY         0       0.000000</div></pre></td></tr></table></figure>\n<p>Эти данные хранятся в таблице <em>INFORMATION_SCHEMA.QUERY_RESPONSE_TIME</em>. Например, приведённый вывод означает, что с момента запуска сервера 1 запрос был выполнен за время 0.000010 с &lt; t &lt; 0.000100 с, общее время выполнения запросов в данной категории – 0.000072 с. Также 8 запросов были выполнены за время 1 с &lt; t &lt; 10 с каждый, общее время – 47.268416 с.<br>Сбросить данные можно с помощью запроса</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; FLUSH QUERY_RESPONSE_TIME;</div></pre></td></tr></table></figure>\n<p>Вообще данный функционал имеет множество различных настроек. Полная документация опубликована на сайте Percona. Разумеется, статистика недоступна в оригинальной MySQL, а лишь в Percona Server и в MariaDB.</p>\n<p>Ссылки:<br><a href=\"http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html\" target=\"_blank\" rel=\"external\">http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html</a><br><a href=\"https://mariadb.com/kb/en/query_response_time-plugin/\" target=\"_blank\" rel=\"external\">https://mariadb.com/kb/en/query_response_time-plugin/</a><br><a href=\"http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html\" target=\"_blank\" rel=\"external\">http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html</a></p>\n","excerpt":"","more":"<p>В MySQL существует возможность логирования “медленных” запросов.</p>\n<p>В такой лог будут записаны все запросы, выполнение которых заняло более <code>long_query_time</code> секунд. Безусловно, анализ slow_log’а может помочь найти узкое место. Но, несмотря на то, что <code>long_query_time</code> можно указывать с точностью до микросекунд, бывает необходимо проанализировать общую статистику времени исполнения запросов.</p>\n<p>Командой Percona реализована такая возможность. Посмотреть распределение можно с помощью запросов.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; SHOW QUERY_RESPONSE_TIME;</div><div class=\"line\">time                   count   total</div><div class=\"line\">0.000001               0       0.000000</div><div class=\"line\">0.000010               0       0.000000</div><div class=\"line\">0.000100               1       0.000072</div><div class=\"line\">0.001000               0       0.000000</div><div class=\"line\">0.010000               0       0.000000</div><div class=\"line\">0.100000               0       0.000000</div><div class=\"line\">1.000000               0       0.000000</div><div class=\"line\">10.000000              8       47.268416</div><div class=\"line\">100.000000             0       0.000000</div><div class=\"line\">1000.000000            0       0.000000</div><div class=\"line\">10000.000000           0       0.000000</div><div class=\"line\">100000.000000          0       0.000000</div><div class=\"line\">1000000.000000         0       0.000000</div><div class=\"line\">TOO LONG QUERY         0       0.000000</div></pre></td></tr></table></figure>\n<p>Эти данные хранятся в таблице <em>INFORMATION_SCHEMA.QUERY_RESPONSE_TIME</em>. Например, приведённый вывод означает, что с момента запуска сервера 1 запрос был выполнен за время 0.000010 с &lt; t &lt; 0.000100 с, общее время выполнения запросов в данной категории – 0.000072 с. Также 8 запросов были выполнены за время 1 с &lt; t &lt; 10 с каждый, общее время – 47.268416 с.<br>Сбросить данные можно с помощью запроса</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; FLUSH QUERY_RESPONSE_TIME;</div></pre></td></tr></table></figure>\n<p>Вообще данный функционал имеет множество различных настроек. Полная документация опубликована на сайте Percona. Разумеется, статистика недоступна в оригинальной MySQL, а лишь в Percona Server и в MariaDB.</p>\n<p>Ссылки:<br><a href=\"http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html\">http://www.percona.com/doc/percona-server/5.5/diagnostics/response_time_distribution.html</a><br><a href=\"https://mariadb.com/kb/en/query_response_time-plugin/\">https://mariadb.com/kb/en/query_response_time-plugin/</a><br><a href=\"http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html\">http://dev.mysql.com/doc/refman/5.5/en/slow-query-log.html</a></p>\n"},{"title":"Segfault в MySQL при старте демона","_content":"Перезагрузка сервера посредством нажатия кнопки “Reset” чревата последствиями.\n\nВ частности, файловые системы или отдельные файлы могут остаться в неконсистентном состоянии, так как ядро или RAID-контроллер не имеют возможности слить буферы записи или writeback-кэш.\n\nОднажды после жёсткой перезагрузки сервера демон MySQL перестал запускаться – при старте в нём возникала ошибка сегментации.\nПервый шаг любой диагностики – просмотр логов демона.\n\n```\n140101  2:04:00 [Note] Plugin 'FEDERATED' is disabled.\nInnoDB: The InnoDB memory heap is disabled\nInnoDB: Mutexes and rw_locks use GCC atomic builtins\nInnoDB: Compressed tables use zlib 1.2.3\n140101  2:04:00  InnoDB: Initializing buffer pool, size = 512.0M\n140101  2:04:00  InnoDB: Completed initialization of buffer pool\n140101  2:04:00  InnoDB: highest supported file format is Barracuda.\nInnoDB: Log scan progressed past the checkpoint lsn 9612902337\n140101  2:04:00  InnoDB: Database was not shut down normally!\nInnoDB: Starting crash recovery.\nInnoDB: Reading tablespace information from the .ibd files...\nInnoDB: Restoring possible half-written data pages from the doublewrite\nInnoDB: buffer...\nInnoDB: Doing recovery: scanned up to log sequence number 9612905565\n131231  5:33:44  InnoDB: Starting an apply batch of log records to the database...\nInnoDB: Progress in percents: 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 131231  5:33:44 -\nmysqld got signal 11 ;\nThis could be because you hit a bug. It is also possible that this binary or one of the libraries it was linked against is corrupt, improperly built, or misconfigured. This error can also be caused by malfunctioning hardware.\nWe will try our best to scrape up some info that will hopefully help diagnose the problem, but since we have already crashed, something is definitely wrong and this may fail.\n\nkey_buffer_size=16777216\nread_buffer_size=16777216\nmax_used_connections=0\nmax_threads=500\nthreads_connected=0\nIt is possible that mysqld could use up to\nkey_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 12309856 K bytes of memory\nHope that's ok; if not, decrease some variables in the equation.\n\nThread pointer: 0x0\nAttempting backtrace. You can use the following information to find out where mysqld died. If you see no messages after this, something went terribly wrong...\nstack_bottom = (nil) thread_stack 0x40000\n/usr/sbin/mysqld(my_print_stacktrace+0x24) [0x862214]\n/usr/sbin/mysqld(handle_segfault+0x34d) [0x5a391d]\n/lib/libpthread.so.0(+0xf010) [0x7fcc80a87010]\n/usr/sbin/mysqld() [0x74f1d0]\n/usr/sbin/mysqld() [0x7508ea]\n/usr/sbin/mysqld() [0x73ed6f]\n/usr/sbin/mysqld() [0x7405ab]\n/usr/sbin/mysqld() [0x7c848b]\n/usr/sbin/mysqld() [0x7f337a]\n/usr/sbin/mysqld() [0x789121]\n/lib/libpthread.so.0(+0x68c4) [0x7fcc80a7e8c4]\n/lib/libc.so.6(clone+0x6d) [0x7fcc7fc27fdd]\nThe manual page at http://dev.mysql.com/doc/mysql/en/crashing.html contains information that should help you find out what is causing the crash.\n```\n\nВидим, что ошибка сегментации возникает при воспроизведении redo-логов. В таком случае надо запустить демон с `innodb_force_recovery = 6` (включается SRV_FORCE_NO_LOG_REDO). После этого выполнить `SET GLOBAL innodb_fast_shutdown = 0` и остановить MySQL штатными средствами. Затем отключить `innodb_force_recovery`. После этого демон запустится.\n\nИ, конечно, никогда не перезагружайте сервера при помощи “Reset” ;)\n\nСсылки:\n[http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/](http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/)\n[http://www.mysqlperformanceblog.com/2011/02/03/how-innodb-handles-redo-logging/](http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/)\n[http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html](http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/)\n","source":"_posts/2015-06-17-mysql-start-segfault.md","raw":"---\ntitle: Segfault в MySQL при старте демона\ntags: [mysql, troubleshooting]\n---\nПерезагрузка сервера посредством нажатия кнопки “Reset” чревата последствиями.\n\nВ частности, файловые системы или отдельные файлы могут остаться в неконсистентном состоянии, так как ядро или RAID-контроллер не имеют возможности слить буферы записи или writeback-кэш.\n\nОднажды после жёсткой перезагрузки сервера демон MySQL перестал запускаться – при старте в нём возникала ошибка сегментации.\nПервый шаг любой диагностики – просмотр логов демона.\n\n```\n140101  2:04:00 [Note] Plugin 'FEDERATED' is disabled.\nInnoDB: The InnoDB memory heap is disabled\nInnoDB: Mutexes and rw_locks use GCC atomic builtins\nInnoDB: Compressed tables use zlib 1.2.3\n140101  2:04:00  InnoDB: Initializing buffer pool, size = 512.0M\n140101  2:04:00  InnoDB: Completed initialization of buffer pool\n140101  2:04:00  InnoDB: highest supported file format is Barracuda.\nInnoDB: Log scan progressed past the checkpoint lsn 9612902337\n140101  2:04:00  InnoDB: Database was not shut down normally!\nInnoDB: Starting crash recovery.\nInnoDB: Reading tablespace information from the .ibd files...\nInnoDB: Restoring possible half-written data pages from the doublewrite\nInnoDB: buffer...\nInnoDB: Doing recovery: scanned up to log sequence number 9612905565\n131231  5:33:44  InnoDB: Starting an apply batch of log records to the database...\nInnoDB: Progress in percents: 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 131231  5:33:44 -\nmysqld got signal 11 ;\nThis could be because you hit a bug. It is also possible that this binary or one of the libraries it was linked against is corrupt, improperly built, or misconfigured. This error can also be caused by malfunctioning hardware.\nWe will try our best to scrape up some info that will hopefully help diagnose the problem, but since we have already crashed, something is definitely wrong and this may fail.\n\nkey_buffer_size=16777216\nread_buffer_size=16777216\nmax_used_connections=0\nmax_threads=500\nthreads_connected=0\nIt is possible that mysqld could use up to\nkey_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 12309856 K bytes of memory\nHope that's ok; if not, decrease some variables in the equation.\n\nThread pointer: 0x0\nAttempting backtrace. You can use the following information to find out where mysqld died. If you see no messages after this, something went terribly wrong...\nstack_bottom = (nil) thread_stack 0x40000\n/usr/sbin/mysqld(my_print_stacktrace+0x24) [0x862214]\n/usr/sbin/mysqld(handle_segfault+0x34d) [0x5a391d]\n/lib/libpthread.so.0(+0xf010) [0x7fcc80a87010]\n/usr/sbin/mysqld() [0x74f1d0]\n/usr/sbin/mysqld() [0x7508ea]\n/usr/sbin/mysqld() [0x73ed6f]\n/usr/sbin/mysqld() [0x7405ab]\n/usr/sbin/mysqld() [0x7c848b]\n/usr/sbin/mysqld() [0x7f337a]\n/usr/sbin/mysqld() [0x789121]\n/lib/libpthread.so.0(+0x68c4) [0x7fcc80a7e8c4]\n/lib/libc.so.6(clone+0x6d) [0x7fcc7fc27fdd]\nThe manual page at http://dev.mysql.com/doc/mysql/en/crashing.html contains information that should help you find out what is causing the crash.\n```\n\nВидим, что ошибка сегментации возникает при воспроизведении redo-логов. В таком случае надо запустить демон с `innodb_force_recovery = 6` (включается SRV_FORCE_NO_LOG_REDO). После этого выполнить `SET GLOBAL innodb_fast_shutdown = 0` и остановить MySQL штатными средствами. Затем отключить `innodb_force_recovery`. После этого демон запустится.\n\nИ, конечно, никогда не перезагружайте сервера при помощи “Reset” ;)\n\nСсылки:\n[http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/](http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/)\n[http://www.mysqlperformanceblog.com/2011/02/03/how-innodb-handles-redo-logging/](http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/)\n[http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html](http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/)\n","slug":"2015-06-17-mysql-start-segfault","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8j000bgkurvmdffjkh","content":"<p>Перезагрузка сервера посредством нажатия кнопки “Reset” чревата последствиями.</p>\n<p>В частности, файловые системы или отдельные файлы могут остаться в неконсистентном состоянии, так как ядро или RAID-контроллер не имеют возможности слить буферы записи или writeback-кэш.</p>\n<p>Однажды после жёсткой перезагрузки сервера демон MySQL перестал запускаться – при старте в нём возникала ошибка сегментации.<br>Первый шаг любой диагностики – просмотр логов демона.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div></pre></td><td class=\"code\"><pre><div class=\"line\">140101  2:04:00 [Note] Plugin &apos;FEDERATED&apos; is disabled.</div><div class=\"line\">InnoDB: The InnoDB memory heap is disabled</div><div class=\"line\">InnoDB: Mutexes and rw_locks use GCC atomic builtins</div><div class=\"line\">InnoDB: Compressed tables use zlib 1.2.3</div><div class=\"line\">140101  2:04:00  InnoDB: Initializing buffer pool, size = 512.0M</div><div class=\"line\">140101  2:04:00  InnoDB: Completed initialization of buffer pool</div><div class=\"line\">140101  2:04:00  InnoDB: highest supported file format is Barracuda.</div><div class=\"line\">InnoDB: Log scan progressed past the checkpoint lsn 9612902337</div><div class=\"line\">140101  2:04:00  InnoDB: Database was not shut down normally!</div><div class=\"line\">InnoDB: Starting crash recovery.</div><div class=\"line\">InnoDB: Reading tablespace information from the .ibd files...</div><div class=\"line\">InnoDB: Restoring possible half-written data pages from the doublewrite</div><div class=\"line\">InnoDB: buffer...</div><div class=\"line\">InnoDB: Doing recovery: scanned up to log sequence number 9612905565</div><div class=\"line\">131231  5:33:44  InnoDB: Starting an apply batch of log records to the database...</div><div class=\"line\">InnoDB: Progress in percents: 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 131231  5:33:44 -</div><div class=\"line\">mysqld got signal 11 ;</div><div class=\"line\">This could be because you hit a bug. It is also possible that this binary or one of the libraries it was linked against is corrupt, improperly built, or misconfigured. This error can also be caused by malfunctioning hardware.</div><div class=\"line\">We will try our best to scrape up some info that will hopefully help diagnose the problem, but since we have already crashed, something is definitely wrong and this may fail.</div><div class=\"line\"></div><div class=\"line\">key_buffer_size=16777216</div><div class=\"line\">read_buffer_size=16777216</div><div class=\"line\">max_used_connections=0</div><div class=\"line\">max_threads=500</div><div class=\"line\">threads_connected=0</div><div class=\"line\">It is possible that mysqld could use up to</div><div class=\"line\">key_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 12309856 K bytes of memory</div><div class=\"line\">Hope that&apos;s ok; if not, decrease some variables in the equation.</div><div class=\"line\"></div><div class=\"line\">Thread pointer: 0x0</div><div class=\"line\">Attempting backtrace. You can use the following information to find out where mysqld died. If you see no messages after this, something went terribly wrong...</div><div class=\"line\">stack_bottom = (nil) thread_stack 0x40000</div><div class=\"line\">/usr/sbin/mysqld(my_print_stacktrace+0x24) [0x862214]</div><div class=\"line\">/usr/sbin/mysqld(handle_segfault+0x34d) [0x5a391d]</div><div class=\"line\">/lib/libpthread.so.0(+0xf010) [0x7fcc80a87010]</div><div class=\"line\">/usr/sbin/mysqld() [0x74f1d0]</div><div class=\"line\">/usr/sbin/mysqld() [0x7508ea]</div><div class=\"line\">/usr/sbin/mysqld() [0x73ed6f]</div><div class=\"line\">/usr/sbin/mysqld() [0x7405ab]</div><div class=\"line\">/usr/sbin/mysqld() [0x7c848b]</div><div class=\"line\">/usr/sbin/mysqld() [0x7f337a]</div><div class=\"line\">/usr/sbin/mysqld() [0x789121]</div><div class=\"line\">/lib/libpthread.so.0(+0x68c4) [0x7fcc80a7e8c4]</div><div class=\"line\">/lib/libc.so.6(clone+0x6d) [0x7fcc7fc27fdd]</div><div class=\"line\">The manual page at http://dev.mysql.com/doc/mysql/en/crashing.html contains information that should help you find out what is causing the crash.</div></pre></td></tr></table></figure>\n<p>Видим, что ошибка сегментации возникает при воспроизведении redo-логов. В таком случае надо запустить демон с <code>innodb_force_recovery = 6</code> (включается SRV_FORCE_NO_LOG_REDO). После этого выполнить <code>SET GLOBAL innodb_fast_shutdown = 0</code> и остановить MySQL штатными средствами. Затем отключить <code>innodb_force_recovery</code>. После этого демон запустится.</p>\n<p>И, конечно, никогда не перезагружайте сервера при помощи “Reset” ;)</p>\n<p>Ссылки:<br><a href=\"http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/\" target=\"_blank\" rel=\"external\">http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/</a><br><a href=\"http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/\" target=\"_blank\" rel=\"external\">http://www.mysqlperformanceblog.com/2011/02/03/how-innodb-handles-redo-logging/</a><br><a href=\"http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/\" target=\"_blank\" rel=\"external\">http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html</a></p>\n","excerpt":"","more":"<p>Перезагрузка сервера посредством нажатия кнопки “Reset” чревата последствиями.</p>\n<p>В частности, файловые системы или отдельные файлы могут остаться в неконсистентном состоянии, так как ядро или RAID-контроллер не имеют возможности слить буферы записи или writeback-кэш.</p>\n<p>Однажды после жёсткой перезагрузки сервера демон MySQL перестал запускаться – при старте в нём возникала ошибка сегментации.<br>Первый шаг любой диагностики – просмотр логов демона.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div></pre></td><td class=\"code\"><pre><div class=\"line\">140101  2:04:00 [Note] Plugin &apos;FEDERATED&apos; is disabled.</div><div class=\"line\">InnoDB: The InnoDB memory heap is disabled</div><div class=\"line\">InnoDB: Mutexes and rw_locks use GCC atomic builtins</div><div class=\"line\">InnoDB: Compressed tables use zlib 1.2.3</div><div class=\"line\">140101  2:04:00  InnoDB: Initializing buffer pool, size = 512.0M</div><div class=\"line\">140101  2:04:00  InnoDB: Completed initialization of buffer pool</div><div class=\"line\">140101  2:04:00  InnoDB: highest supported file format is Barracuda.</div><div class=\"line\">InnoDB: Log scan progressed past the checkpoint lsn 9612902337</div><div class=\"line\">140101  2:04:00  InnoDB: Database was not shut down normally!</div><div class=\"line\">InnoDB: Starting crash recovery.</div><div class=\"line\">InnoDB: Reading tablespace information from the .ibd files...</div><div class=\"line\">InnoDB: Restoring possible half-written data pages from the doublewrite</div><div class=\"line\">InnoDB: buffer...</div><div class=\"line\">InnoDB: Doing recovery: scanned up to log sequence number 9612905565</div><div class=\"line\">131231  5:33:44  InnoDB: Starting an apply batch of log records to the database...</div><div class=\"line\">InnoDB: Progress in percents: 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 131231  5:33:44 -</div><div class=\"line\">mysqld got signal 11 ;</div><div class=\"line\">This could be because you hit a bug. It is also possible that this binary or one of the libraries it was linked against is corrupt, improperly built, or misconfigured. This error can also be caused by malfunctioning hardware.</div><div class=\"line\">We will try our best to scrape up some info that will hopefully help diagnose the problem, but since we have already crashed, something is definitely wrong and this may fail.</div><div class=\"line\"></div><div class=\"line\">key_buffer_size=16777216</div><div class=\"line\">read_buffer_size=16777216</div><div class=\"line\">max_used_connections=0</div><div class=\"line\">max_threads=500</div><div class=\"line\">threads_connected=0</div><div class=\"line\">It is possible that mysqld could use up to</div><div class=\"line\">key_buffer_size + (read_buffer_size + sort_buffer_size)*max_threads = 12309856 K bytes of memory</div><div class=\"line\">Hope that&apos;s ok; if not, decrease some variables in the equation.</div><div class=\"line\"></div><div class=\"line\">Thread pointer: 0x0</div><div class=\"line\">Attempting backtrace. You can use the following information to find out where mysqld died. If you see no messages after this, something went terribly wrong...</div><div class=\"line\">stack_bottom = (nil) thread_stack 0x40000</div><div class=\"line\">/usr/sbin/mysqld(my_print_stacktrace+0x24) [0x862214]</div><div class=\"line\">/usr/sbin/mysqld(handle_segfault+0x34d) [0x5a391d]</div><div class=\"line\">/lib/libpthread.so.0(+0xf010) [0x7fcc80a87010]</div><div class=\"line\">/usr/sbin/mysqld() [0x74f1d0]</div><div class=\"line\">/usr/sbin/mysqld() [0x7508ea]</div><div class=\"line\">/usr/sbin/mysqld() [0x73ed6f]</div><div class=\"line\">/usr/sbin/mysqld() [0x7405ab]</div><div class=\"line\">/usr/sbin/mysqld() [0x7c848b]</div><div class=\"line\">/usr/sbin/mysqld() [0x7f337a]</div><div class=\"line\">/usr/sbin/mysqld() [0x789121]</div><div class=\"line\">/lib/libpthread.so.0(+0x68c4) [0x7fcc80a7e8c4]</div><div class=\"line\">/lib/libc.so.6(clone+0x6d) [0x7fcc7fc27fdd]</div><div class=\"line\">The manual page at http://dev.mysql.com/doc/mysql/en/crashing.html contains information that should help you find out what is causing the crash.</div></pre></td></tr></table></figure>\n<p>Видим, что ошибка сегментации возникает при воспроизведении redo-логов. В таком случае надо запустить демон с <code>innodb_force_recovery = 6</code> (включается SRV_FORCE_NO_LOG_REDO). После этого выполнить <code>SET GLOBAL innodb_fast_shutdown = 0</code> и остановить MySQL штатными средствами. Затем отключить <code>innodb_force_recovery</code>. После этого демон запустится.</p>\n<p>И, конечно, никогда не перезагружайте сервера при помощи “Reset” ;)</p>\n<p>Ссылки:<br><a href=\"http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/\">http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/</a><br><a href=\"http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/\">http://www.mysqlperformanceblog.com/2011/02/03/how-innodb-handles-redo-logging/</a><br><a href=\"http://www.mysqlperformanceblog.com/2006/08/04/innodb-double-write/\">http://dev.mysql.com/doc/refman/5.5/en/forcing-innodb-recovery.html</a></p>\n"},{"title":"Puppet Error 400","description":"Что делать, если Puppet не видит модуль.","_content":"Сегодня добавил в репозиторий Puppet новый модуль, прописал его в манифесте ноды. На ноде puppet agent не мог получить каталог с сервера - сервер “не видел” модуль.\n\nВ консоли это выглядело так:\n\n```\nError: Could not retrieve catalog from remote server:\nError 400 on SERVER: Puppet::Parser::AST::Resource failed with error ArgumentError:\nCould not find declared class rclocal at\n/var/git/puppet-main/production/manifests/service_nodes/redis.timeweb.net.pp:31\non node redis1.timeweb.net\nWarning: Not using cache on failed catalog\nError: Could not retrieve catalog; skipping run\n```\n\nМодуль располагался в правильной директории, ошибки не должно было быть. Оказалось, что причиной являлось отсутствие некоторых обязательных полей в `metadata.json` этого модуля. После добавления всех обязательных полей из [https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson](https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson) ошибка исчезла.\n","source":"_posts/2015-06-17-puppet-error-400.md","raw":"---\ntitle: Puppet Error 400\ndescription: \"Что делать, если Puppet не видит модуль.\"\ntags: [puppet, troubleshooting]\n---\nСегодня добавил в репозиторий Puppet новый модуль, прописал его в манифесте ноды. На ноде puppet agent не мог получить каталог с сервера - сервер “не видел” модуль.\n\nВ консоли это выглядело так:\n\n```\nError: Could not retrieve catalog from remote server:\nError 400 on SERVER: Puppet::Parser::AST::Resource failed with error ArgumentError:\nCould not find declared class rclocal at\n/var/git/puppet-main/production/manifests/service_nodes/redis.timeweb.net.pp:31\non node redis1.timeweb.net\nWarning: Not using cache on failed catalog\nError: Could not retrieve catalog; skipping run\n```\n\nМодуль располагался в правильной директории, ошибки не должно было быть. Оказалось, что причиной являлось отсутствие некоторых обязательных полей в `metadata.json` этого модуля. После добавления всех обязательных полей из [https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson](https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson) ошибка исчезла.\n","slug":"2015-06-17-puppet-error-400","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8k000cgkur8aq66jfn","content":"<p>Сегодня добавил в репозиторий Puppet новый модуль, прописал его в манифесте ноды. На ноде puppet agent не мог получить каталог с сервера - сервер “не видел” модуль.</p>\n<p>В консоли это выглядело так:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">Error: Could not retrieve catalog from remote server:</div><div class=\"line\">Error 400 on SERVER: Puppet::Parser::AST::Resource failed with error ArgumentError:</div><div class=\"line\">Could not find declared class rclocal at</div><div class=\"line\">/var/git/puppet-main/production/manifests/service_nodes/redis.timeweb.net.pp:31</div><div class=\"line\">on node redis1.timeweb.net</div><div class=\"line\">Warning: Not using cache on failed catalog</div><div class=\"line\">Error: Could not retrieve catalog; skipping run</div></pre></td></tr></table></figure>\n<p>Модуль располагался в правильной директории, ошибки не должно было быть. Оказалось, что причиной являлось отсутствие некоторых обязательных полей в <code>metadata.json</code> этого модуля. После добавления всех обязательных полей из <a href=\"https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson\" target=\"_blank\" rel=\"external\">https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson</a> ошибка исчезла.</p>\n","excerpt":"","more":"<p>Сегодня добавил в репозиторий Puppet новый модуль, прописал его в манифесте ноды. На ноде puppet agent не мог получить каталог с сервера - сервер “не видел” модуль.</p>\n<p>В консоли это выглядело так:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">Error: Could not retrieve catalog from remote server:</div><div class=\"line\">Error 400 on SERVER: Puppet::Parser::AST::Resource failed with error ArgumentError:</div><div class=\"line\">Could not find declared class rclocal at</div><div class=\"line\">/var/git/puppet-main/production/manifests/service_nodes/redis.timeweb.net.pp:31</div><div class=\"line\">on node redis1.timeweb.net</div><div class=\"line\">Warning: Not using cache on failed catalog</div><div class=\"line\">Error: Could not retrieve catalog; skipping run</div></pre></td></tr></table></figure>\n<p>Модуль располагался в правильной директории, ошибки не должно было быть. Оказалось, что причиной являлось отсутствие некоторых обязательных полей в <code>metadata.json</code> этого модуля. После добавления всех обязательных полей из <a href=\"https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson\">https://docs.puppetlabs.com/puppet/latest/reference/modules_publishing.html#fields-in-metadatajson</a> ошибка исчезла.</p>\n"},{"title":"Кэширование ответов DNS с помощью nscd","_content":"nscd - Name Services Caching Daemon.\n\nnscd кэширует ответы различных служб имён. Чаще всего его настраивают ради кэширования ответов DNS. Не стоит путать nscd с кэширующим DNS-сервером – он им не является, кэш используется локально. Для использования кэширования в файле `/etc/nsswitch.conf` строка `hosts` должна иметь следующий вид:\n\n```\n hosts: cache files dns\n```\n\nnscd является гибким инструментом, позволяет настраивать Positive и Negative TTL, persistence кэша при перезапуске демона, особое поведение при запросе имени, для которого есть запись в `/etc/hosts`. В man-страницах nscd и nscd.conf все нюансы расписаны очень подробно.\n","source":"_posts/2015-06-17-nscd.md","raw":"---\ntitle: Кэширование ответов DNS с помощью nscd\ntags: [dns]\n---\nnscd - Name Services Caching Daemon.\n\nnscd кэширует ответы различных служб имён. Чаще всего его настраивают ради кэширования ответов DNS. Не стоит путать nscd с кэширующим DNS-сервером – он им не является, кэш используется локально. Для использования кэширования в файле `/etc/nsswitch.conf` строка `hosts` должна иметь следующий вид:\n\n```\n hosts: cache files dns\n```\n\nnscd является гибким инструментом, позволяет настраивать Positive и Negative TTL, persistence кэша при перезапуске демона, особое поведение при запросе имени, для которого есть запись в `/etc/hosts`. В man-страницах nscd и nscd.conf все нюансы расписаны очень подробно.\n","slug":"2015-06-17-nscd","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8m000egkur2sthvnfl","content":"<p>nscd - Name Services Caching Daemon.</p>\n<p>nscd кэширует ответы различных служб имён. Чаще всего его настраивают ради кэширования ответов DNS. Не стоит путать nscd с кэширующим DNS-сервером – он им не является, кэш используется локально. Для использования кэширования в файле <code>/etc/nsswitch.conf</code> строка <code>hosts</code> должна иметь следующий вид:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hosts: cache files dns</div></pre></td></tr></table></figure>\n<p>nscd является гибким инструментом, позволяет настраивать Positive и Negative TTL, persistence кэша при перезапуске демона, особое поведение при запросе имени, для которого есть запись в <code>/etc/hosts</code>. В man-страницах nscd и nscd.conf все нюансы расписаны очень подробно.</p>\n","excerpt":"","more":"<p>nscd - Name Services Caching Daemon.</p>\n<p>nscd кэширует ответы различных служб имён. Чаще всего его настраивают ради кэширования ответов DNS. Не стоит путать nscd с кэширующим DNS-сервером – он им не является, кэш используется локально. Для использования кэширования в файле <code>/etc/nsswitch.conf</code> строка <code>hosts</code> должна иметь следующий вид:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">hosts: cache files dns</div></pre></td></tr></table></figure>\n<p>nscd является гибким инструментом, позволяет настраивать Positive и Negative TTL, persistence кэша при перезапуске демона, особое поведение при запросе имени, для которого есть запись в <code>/etc/hosts</code>. В man-страницах nscd и nscd.conf все нюансы расписаны очень подробно.</p>\n"},{"title":"multiprocessing.Process и sys.exit()","_content":"Мониторинг времени отклика серверов хостинга мы мониторим так.\n\nЕсть скрипт, который берёт список серверов и запрашивает с каждого веб-страничку (Wordpress с плагином Query Monitor), парсит оттуда время генерации страницы и время работы БД, по пути считает время скачивания странички со всей статикой.\nСначала опрос происходил последовательно в цикле, но это не есть путь самурая, поэтому решено было распараллелить процесс.\nСперва взгляд лёг на модуль threading. Однако я тогда ещё не ощутил на практике недостатки GIL (Global Interpreter Lock). Дело обернулось тем, что для каждого сервера время скачивания было 6-7 секунд, хотя настоящее значение лежит в пределах секунды. Так произошло как раз из-за GIL: таймеры в потоках были запущены, но фактически выполнялся лишь один поток, остальные продолжали ждать.\n\nТогда я решил поменять threading на multiprocessing, благо у них очень похожая семантика объектов.\nЯ вынес рабочий код из подкласса `threading.Thread` в функцию (не стал делать подкласс `multiprocessing.Process`, так как захотелось использовать пул подпроцессов - `multiprocessing.Pool`, а он не поддерживает создание чайлдов из кастомных классов), функция в зависимости от статуса исполнения завершалась `sys.exit(0)` или `sys.exit(1)`. Но мой код не заработал.\n\nПроблема заключалась в том, что, после обработки всех серверов, скрипт и его дочерние процесы продолжали работать. `strace` показал, что они висят в ожидании мьютекса. По всей видимости, `multiprocessing.Process` оборачивает полезный код, передаваемый в виде функции, дополнительными вызовами, в частности, отпускает мьютекс. В моей функции был вызов `sys.exit()`, поэтому этот код никогда не вызывался. Это лишь предположение, но факт оказался фактом: когда я поменял `sys.exit()` на `return`, скрипт и его подпроцессы успешно завершались.\n\nВывод: не используйте `sys.exit()` в функции, передаваемой в качестве `target` экземпляру `multiprocessing.Process`.\n","source":"_posts/2015-06-17-python-multiprocessing-sysexit.md","raw":"---\ntitle: multiprocessing.Process и sys.exit()\ntags: [python]\n---\nМониторинг времени отклика серверов хостинга мы мониторим так.\n\nЕсть скрипт, который берёт список серверов и запрашивает с каждого веб-страничку (Wordpress с плагином Query Monitor), парсит оттуда время генерации страницы и время работы БД, по пути считает время скачивания странички со всей статикой.\nСначала опрос происходил последовательно в цикле, но это не есть путь самурая, поэтому решено было распараллелить процесс.\nСперва взгляд лёг на модуль threading. Однако я тогда ещё не ощутил на практике недостатки GIL (Global Interpreter Lock). Дело обернулось тем, что для каждого сервера время скачивания было 6-7 секунд, хотя настоящее значение лежит в пределах секунды. Так произошло как раз из-за GIL: таймеры в потоках были запущены, но фактически выполнялся лишь один поток, остальные продолжали ждать.\n\nТогда я решил поменять threading на multiprocessing, благо у них очень похожая семантика объектов.\nЯ вынес рабочий код из подкласса `threading.Thread` в функцию (не стал делать подкласс `multiprocessing.Process`, так как захотелось использовать пул подпроцессов - `multiprocessing.Pool`, а он не поддерживает создание чайлдов из кастомных классов), функция в зависимости от статуса исполнения завершалась `sys.exit(0)` или `sys.exit(1)`. Но мой код не заработал.\n\nПроблема заключалась в том, что, после обработки всех серверов, скрипт и его дочерние процесы продолжали работать. `strace` показал, что они висят в ожидании мьютекса. По всей видимости, `multiprocessing.Process` оборачивает полезный код, передаваемый в виде функции, дополнительными вызовами, в частности, отпускает мьютекс. В моей функции был вызов `sys.exit()`, поэтому этот код никогда не вызывался. Это лишь предположение, но факт оказался фактом: когда я поменял `sys.exit()` на `return`, скрипт и его подпроцессы успешно завершались.\n\nВывод: не используйте `sys.exit()` в функции, передаваемой в качестве `target` экземпляру `multiprocessing.Process`.\n","slug":"2015-06-17-python-multiprocessing-sysexit","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8o000ggkurfbvmlx7n","content":"<p>Мониторинг времени отклика серверов хостинга мы мониторим так.</p>\n<p>Есть скрипт, который берёт список серверов и запрашивает с каждого веб-страничку (Wordpress с плагином Query Monitor), парсит оттуда время генерации страницы и время работы БД, по пути считает время скачивания странички со всей статикой.<br>Сначала опрос происходил последовательно в цикле, но это не есть путь самурая, поэтому решено было распараллелить процесс.<br>Сперва взгляд лёг на модуль threading. Однако я тогда ещё не ощутил на практике недостатки GIL (Global Interpreter Lock). Дело обернулось тем, что для каждого сервера время скачивания было 6-7 секунд, хотя настоящее значение лежит в пределах секунды. Так произошло как раз из-за GIL: таймеры в потоках были запущены, но фактически выполнялся лишь один поток, остальные продолжали ждать.</p>\n<p>Тогда я решил поменять threading на multiprocessing, благо у них очень похожая семантика объектов.<br>Я вынес рабочий код из подкласса <code>threading.Thread</code> в функцию (не стал делать подкласс <code>multiprocessing.Process</code>, так как захотелось использовать пул подпроцессов - <code>multiprocessing.Pool</code>, а он не поддерживает создание чайлдов из кастомных классов), функция в зависимости от статуса исполнения завершалась <code>sys.exit(0)</code> или <code>sys.exit(1)</code>. Но мой код не заработал.</p>\n<p>Проблема заключалась в том, что, после обработки всех серверов, скрипт и его дочерние процесы продолжали работать. <code>strace</code> показал, что они висят в ожидании мьютекса. По всей видимости, <code>multiprocessing.Process</code> оборачивает полезный код, передаваемый в виде функции, дополнительными вызовами, в частности, отпускает мьютекс. В моей функции был вызов <code>sys.exit()</code>, поэтому этот код никогда не вызывался. Это лишь предположение, но факт оказался фактом: когда я поменял <code>sys.exit()</code> на <code>return</code>, скрипт и его подпроцессы успешно завершались.</p>\n<p>Вывод: не используйте <code>sys.exit()</code> в функции, передаваемой в качестве <code>target</code> экземпляру <code>multiprocessing.Process</code>.</p>\n","excerpt":"","more":"<p>Мониторинг времени отклика серверов хостинга мы мониторим так.</p>\n<p>Есть скрипт, который берёт список серверов и запрашивает с каждого веб-страничку (Wordpress с плагином Query Monitor), парсит оттуда время генерации страницы и время работы БД, по пути считает время скачивания странички со всей статикой.<br>Сначала опрос происходил последовательно в цикле, но это не есть путь самурая, поэтому решено было распараллелить процесс.<br>Сперва взгляд лёг на модуль threading. Однако я тогда ещё не ощутил на практике недостатки GIL (Global Interpreter Lock). Дело обернулось тем, что для каждого сервера время скачивания было 6-7 секунд, хотя настоящее значение лежит в пределах секунды. Так произошло как раз из-за GIL: таймеры в потоках были запущены, но фактически выполнялся лишь один поток, остальные продолжали ждать.</p>\n<p>Тогда я решил поменять threading на multiprocessing, благо у них очень похожая семантика объектов.<br>Я вынес рабочий код из подкласса <code>threading.Thread</code> в функцию (не стал делать подкласс <code>multiprocessing.Process</code>, так как захотелось использовать пул подпроцессов - <code>multiprocessing.Pool</code>, а он не поддерживает создание чайлдов из кастомных классов), функция в зависимости от статуса исполнения завершалась <code>sys.exit(0)</code> или <code>sys.exit(1)</code>. Но мой код не заработал.</p>\n<p>Проблема заключалась в том, что, после обработки всех серверов, скрипт и его дочерние процесы продолжали работать. <code>strace</code> показал, что они висят в ожидании мьютекса. По всей видимости, <code>multiprocessing.Process</code> оборачивает полезный код, передаваемый в виде функции, дополнительными вызовами, в частности, отпускает мьютекс. В моей функции был вызов <code>sys.exit()</code>, поэтому этот код никогда не вызывался. Это лишь предположение, но факт оказался фактом: когда я поменял <code>sys.exit()</code> на <code>return</code>, скрипт и его подпроцессы успешно завершались.</p>\n<p>Вывод: не используйте <code>sys.exit()</code> в функции, передаваемой в качестве <code>target</code> экземпляру <code>multiprocessing.Process</code>.</p>\n"},{"title":"Сервер не загружается после замены диска","_content":"После замены неисправного диска в Linux он не всегда может быть обнаружен системой (типичное поведение для старых ядер).\n\nВ таком случае требуется перезагрузить сервер. Однако, бывает так, что после перезагрузки BIOS не может найти загрузчик – он мог быть установлен в MBR вылетевшего диска.\nВ таком случае требуется загрузить сервер с LiveCD. Я пользуюсь образами Gentoo. После загрузки в среду восстановления нужно разметить диск аналогично исправному. Если объём небольшой, и rebuild массива пройдёт быстро, то можно добавить диск в массив. После этого необходимо переустановить GRUB. Для этого надо подмонтировать массив и воспользоваться утилитой `grub-install`. Дело в том, что в LiveCD Gentoo нет утилит GRUB.\n\n```\n# mkdir /mnt/tmp\n# mount /dev/md126 /mnt/tmp\n# mount -o bind /dev /mnt/tmp/dev\n# chroot /mnt/tmp\n```\n\nВ chroot-окружении доступны все утилиты с сервера. Пытаемся установить загрузчик:\n\n```\n# grub-install /dev/sda\n/dev/md126 does not have any corresponding BIOS drive\n```\n\nНеудача. Дело в том, что загрузчик грузится с MBR диска, он не может быть загружен с MD-устройства. Впрочем, это не мешает ему распознавать программные RAID-массивы и загружать ядро. Установить GRUB в /dev/sda всё же можно вручную:\n\n```\n# grub\ngrub> root (hd0,0)        \nroot (hd0,0)\nFilesystem type is ext2fs, partition type 0xfd\ngrub> setup (hd0)\nsetup (hd0)\nChecking if \"/boot/grub/stage1\" exists... no\nChecking if \"/grub/stage1\" exists... yes\nChecking if \"/grub/stage2\" exists... yes\nChecking if \"/grub/e2fs_stage1_5\" exists... yes\nRunning \"embed /grub/e2fs_stage1_5 (hd0)\"...  16 sectors are embedded.\nsucceeded\nRunning \"install /grub/stage1 (hd0) (hd0)1+16 p (hd0,0)/grub/stage2 /grub/grub.conf\"... succeeded\nDone.\ngrub> quit\n# reboot\n```\n\nТакже не забудьте изменить имя MD-устройства, если оно изменилось (например, с md0 на md126 ) в файле `/etc/fstab`. После перезагрузки сервер должен успешно подняться.\n\nСсылки:\n[http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html](http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html)\n","source":"_posts/2015-06-17-reinstall-grub.md","raw":"---\ntitle: Сервер не загружается после замены диска\ntags: [troubleshooting]\n---\nПосле замены неисправного диска в Linux он не всегда может быть обнаружен системой (типичное поведение для старых ядер).\n\nВ таком случае требуется перезагрузить сервер. Однако, бывает так, что после перезагрузки BIOS не может найти загрузчик – он мог быть установлен в MBR вылетевшего диска.\nВ таком случае требуется загрузить сервер с LiveCD. Я пользуюсь образами Gentoo. После загрузки в среду восстановления нужно разметить диск аналогично исправному. Если объём небольшой, и rebuild массива пройдёт быстро, то можно добавить диск в массив. После этого необходимо переустановить GRUB. Для этого надо подмонтировать массив и воспользоваться утилитой `grub-install`. Дело в том, что в LiveCD Gentoo нет утилит GRUB.\n\n```\n# mkdir /mnt/tmp\n# mount /dev/md126 /mnt/tmp\n# mount -o bind /dev /mnt/tmp/dev\n# chroot /mnt/tmp\n```\n\nВ chroot-окружении доступны все утилиты с сервера. Пытаемся установить загрузчик:\n\n```\n# grub-install /dev/sda\n/dev/md126 does not have any corresponding BIOS drive\n```\n\nНеудача. Дело в том, что загрузчик грузится с MBR диска, он не может быть загружен с MD-устройства. Впрочем, это не мешает ему распознавать программные RAID-массивы и загружать ядро. Установить GRUB в /dev/sda всё же можно вручную:\n\n```\n# grub\ngrub> root (hd0,0)        \nroot (hd0,0)\nFilesystem type is ext2fs, partition type 0xfd\ngrub> setup (hd0)\nsetup (hd0)\nChecking if \"/boot/grub/stage1\" exists... no\nChecking if \"/grub/stage1\" exists... yes\nChecking if \"/grub/stage2\" exists... yes\nChecking if \"/grub/e2fs_stage1_5\" exists... yes\nRunning \"embed /grub/e2fs_stage1_5 (hd0)\"...  16 sectors are embedded.\nsucceeded\nRunning \"install /grub/stage1 (hd0) (hd0)1+16 p (hd0,0)/grub/stage2 /grub/grub.conf\"... succeeded\nDone.\ngrub> quit\n# reboot\n```\n\nТакже не забудьте изменить имя MD-устройства, если оно изменилось (например, с md0 на md126 ) в файле `/etc/fstab`. После перезагрузки сервер должен успешно подняться.\n\nСсылки:\n[http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html](http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html)\n","slug":"2015-06-17-reinstall-grub","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo8q000jgkur62kg4fls","content":"<p>После замены неисправного диска в Linux он не всегда может быть обнаружен системой (типичное поведение для старых ядер).</p>\n<p>В таком случае требуется перезагрузить сервер. Однако, бывает так, что после перезагрузки BIOS не может найти загрузчик – он мог быть установлен в MBR вылетевшего диска.<br>В таком случае требуется загрузить сервер с LiveCD. Я пользуюсь образами Gentoo. После загрузки в среду восстановления нужно разметить диск аналогично исправному. Если объём небольшой, и rebuild массива пройдёт быстро, то можно добавить диск в массив. После этого необходимо переустановить GRUB. Для этого надо подмонтировать массив и воспользоваться утилитой <code>grub-install</code>. Дело в том, что в LiveCD Gentoo нет утилит GRUB.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># mkdir /mnt/tmp</div><div class=\"line\"># mount /dev/md126 /mnt/tmp</div><div class=\"line\"># mount -o bind /dev /mnt/tmp/dev</div><div class=\"line\"># chroot /mnt/tmp</div></pre></td></tr></table></figure>\n<p>В chroot-окружении доступны все утилиты с сервера. Пытаемся установить загрузчик:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># grub-install /dev/sda</div><div class=\"line\">/dev/md126 does not have any corresponding BIOS drive</div></pre></td></tr></table></figure>\n<p>Неудача. Дело в том, что загрузчик грузится с MBR диска, он не может быть загружен с MD-устройства. Впрочем, это не мешает ему распознавать программные RAID-массивы и загружать ядро. Установить GRUB в /dev/sda всё же можно вручную:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"># grub</div><div class=\"line\">grub&gt; root (hd0,0)        </div><div class=\"line\">root (hd0,0)</div><div class=\"line\">Filesystem type is ext2fs, partition type 0xfd</div><div class=\"line\">grub&gt; setup (hd0)</div><div class=\"line\">setup (hd0)</div><div class=\"line\">Checking if &quot;/boot/grub/stage1&quot; exists... no</div><div class=\"line\">Checking if &quot;/grub/stage1&quot; exists... yes</div><div class=\"line\">Checking if &quot;/grub/stage2&quot; exists... yes</div><div class=\"line\">Checking if &quot;/grub/e2fs_stage1_5&quot; exists... yes</div><div class=\"line\">Running &quot;embed /grub/e2fs_stage1_5 (hd0)&quot;...  16 sectors are embedded.</div><div class=\"line\">succeeded</div><div class=\"line\">Running &quot;install /grub/stage1 (hd0) (hd0)1+16 p (hd0,0)/grub/stage2 /grub/grub.conf&quot;... succeeded</div><div class=\"line\">Done.</div><div class=\"line\">grub&gt; quit</div><div class=\"line\"># reboot</div></pre></td></tr></table></figure>\n<p>Также не забудьте изменить имя MD-устройства, если оно изменилось (например, с md0 на md126 ) в файле <code>/etc/fstab</code>. После перезагрузки сервер должен успешно подняться.</p>\n<p>Ссылки:<br><a href=\"http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html\" target=\"_blank\" rel=\"external\">http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html</a></p>\n","excerpt":"","more":"<p>После замены неисправного диска в Linux он не всегда может быть обнаружен системой (типичное поведение для старых ядер).</p>\n<p>В таком случае требуется перезагрузить сервер. Однако, бывает так, что после перезагрузки BIOS не может найти загрузчик – он мог быть установлен в MBR вылетевшего диска.<br>В таком случае требуется загрузить сервер с LiveCD. Я пользуюсь образами Gentoo. После загрузки в среду восстановления нужно разметить диск аналогично исправному. Если объём небольшой, и rebuild массива пройдёт быстро, то можно добавить диск в массив. После этого необходимо переустановить GRUB. Для этого надо подмонтировать массив и воспользоваться утилитой <code>grub-install</code>. Дело в том, что в LiveCD Gentoo нет утилит GRUB.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"># mkdir /mnt/tmp</div><div class=\"line\"># mount /dev/md126 /mnt/tmp</div><div class=\"line\"># mount -o bind /dev /mnt/tmp/dev</div><div class=\"line\"># chroot /mnt/tmp</div></pre></td></tr></table></figure>\n<p>В chroot-окружении доступны все утилиты с сервера. Пытаемся установить загрузчик:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\"># grub-install /dev/sda</div><div class=\"line\">/dev/md126 does not have any corresponding BIOS drive</div></pre></td></tr></table></figure>\n<p>Неудача. Дело в том, что загрузчик грузится с MBR диска, он не может быть загружен с MD-устройства. Впрочем, это не мешает ему распознавать программные RAID-массивы и загружать ядро. Установить GRUB в /dev/sda всё же можно вручную:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\"># grub</div><div class=\"line\">grub&gt; root (hd0,0)        </div><div class=\"line\">root (hd0,0)</div><div class=\"line\">Filesystem type is ext2fs, partition type 0xfd</div><div class=\"line\">grub&gt; setup (hd0)</div><div class=\"line\">setup (hd0)</div><div class=\"line\">Checking if &quot;/boot/grub/stage1&quot; exists... no</div><div class=\"line\">Checking if &quot;/grub/stage1&quot; exists... yes</div><div class=\"line\">Checking if &quot;/grub/stage2&quot; exists... yes</div><div class=\"line\">Checking if &quot;/grub/e2fs_stage1_5&quot; exists... yes</div><div class=\"line\">Running &quot;embed /grub/e2fs_stage1_5 (hd0)&quot;...  16 sectors are embedded.</div><div class=\"line\">succeeded</div><div class=\"line\">Running &quot;install /grub/stage1 (hd0) (hd0)1+16 p (hd0,0)/grub/stage2 /grub/grub.conf&quot;... succeeded</div><div class=\"line\">Done.</div><div class=\"line\">grub&gt; quit</div><div class=\"line\"># reboot</div></pre></td></tr></table></figure>\n<p>Также не забудьте изменить имя MD-устройства, если оно изменилось (например, с md0 на md126 ) в файле <code>/etc/fstab</code>. После перезагрузки сервер должен успешно подняться.</p>\n<p>Ссылки:<br><a href=\"http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html\">http://idolinux.blogspot.ru/2009/07/reinstall-grub-bootloader-on-md0.html</a></p>\n"},{"layout":"post","title":"Автосоздание маршрутов при подключении к VPN на macOS","modified":"2015-06-16T21:00:00.000Z","_content":"Не хочется весь трафик пускать через VPN.\n\nЧтобы при подключении автоматически создавались только нужные маршруты до рабочих ресурсов, нужно указать их в файле с именем `/etc/ppp/ip-up`. Примерное содержимое файла:\n\n```bash\n#!/bin/sh\n/sbin/route add confluence.example.com -interface $1\n/sbin/route add monitor.example.com -interface $1\n/sbin/route add staff.example.com -interface $1\n```\n","source":"_posts/2015-06-17-routes-on-vpn-connect-osx.md","raw":"---\nlayout: post\ntitle: Автосоздание маршрутов при подключении к VPN на macOS\nmodified: 2015-06-17\ntags: [vpn, environment]\n---\nНе хочется весь трафик пускать через VPN.\n\nЧтобы при подключении автоматически создавались только нужные маршруты до рабочих ресурсов, нужно указать их в файле с именем `/etc/ppp/ip-up`. Примерное содержимое файла:\n\n```bash\n#!/bin/sh\n/sbin/route add confluence.example.com -interface $1\n/sbin/route add monitor.example.com -interface $1\n/sbin/route add staff.example.com -interface $1\n```\n","slug":"2015-06-17-routes-on-vpn-connect-osx","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo8r000lgkur4eca66wa","content":"<p>Не хочется весь трафик пускать через VPN.</p>\n<p>Чтобы при подключении автоматически создавались только нужные маршруты до рабочих ресурсов, нужно указать их в файле с именем <code>/etc/ppp/ip-up</code>. Примерное содержимое файла:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#!/bin/sh</span></div><div class=\"line\">/sbin/route add confluence.example.com -interface <span class=\"variable\">$1</span></div><div class=\"line\">/sbin/route add monitor.example.com -interface <span class=\"variable\">$1</span></div><div class=\"line\">/sbin/route add staff.example.com -interface <span class=\"variable\">$1</span></div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>Не хочется весь трафик пускать через VPN.</p>\n<p>Чтобы при подключении автоматически создавались только нужные маршруты до рабочих ресурсов, нужно указать их в файле с именем <code>/etc/ppp/ip-up</code>. Примерное содержимое файла:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">#!/bin/sh</span></div><div class=\"line\">/sbin/route add confluence.example.com -interface <span class=\"variable\">$1</span></div><div class=\"line\">/sbin/route add monitor.example.com -interface <span class=\"variable\">$1</span></div><div class=\"line\">/sbin/route add staff.example.com -interface <span class=\"variable\">$1</span></div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Инициализация сканирования устройств SATA-контроллером в Linux","modified":"2015-06-16T21:00:00.000Z","_content":"Некоторые платформы не определяют диски автоматически - после “горячего” подключения в системе их не видно.\n\nМожно запустить сканирование подключённых к SATA-контроллеру устройств:\n\n```\necho \"- - -\" > /sys/class/scsi_host/host0/scan\n```","source":"_posts/2015-06-17-sata-host-scan.md","raw":"---\nlayout: post\ntitle: Инициализация сканирования устройств SATA-контроллером в Linux\nmodified: 2015-06-17\ntags: [hardware]\n---\nНекоторые платформы не определяют диски автоматически - после “горячего” подключения в системе их не видно.\n\nМожно запустить сканирование подключённых к SATA-контроллеру устройств:\n\n```\necho \"- - -\" > /sys/class/scsi_host/host0/scan\n```","slug":"2015-06-17-sata-host-scan","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo8t000ngkurbjvm8t7f","content":"<p>Некоторые платформы не определяют диски автоматически - после “горячего” подключения в системе их не видно.</p>\n<p>Можно запустить сканирование подключённых к SATA-контроллеру устройств:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host0/scan</div></pre></td></tr></table></figure>","excerpt":"","more":"<p>Некоторые платформы не определяют диски автоматически - после “горячего” подключения в системе их не видно.</p>\n<p>Можно запустить сканирование подключённых к SATA-контроллеру устройств:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">echo &quot;- - -&quot; &gt; /sys/class/scsi_host/host0/scan</div></pre></td></tr></table></figure>"},{"layout":"post","title":"Назначение интерфейсу нескольких IP-адресов при загрузке","modified":"2015-06-16T21:00:00.000Z","_content":"В RHEL-совместимых дистрибутивах конфигурация сетевых интерфейсов хранится в файлах `/etc/sysconfig/network-scripts/ifcfg-<iface>`. Пример файла `ifcfg-eth0`:\n\n```\nDEVICE=\"eth0\"\nIPADDR0=\"1.2.3.4\"\nNETMASK0=\"255.255.255.0\"\nBROADCAST0=\"1.2.3.255\"\nGATEWAY=\"1.2.3.1\"\nIPADDR1=\"5.6.7.8\"\nNETMASK1=\"255.255.0.0\"\nBROADCAST1=\"5.6.255.255\"\nONBOOT=\"yes\"\n```\n\nПри такой конфигурации интерфейс eth0 при загрузке получит два сетевых адреса с разной маской, также в таблицу маршрутизации будет добавлена указанная запись для шлюза по умолчанию.\nВ Debian и дистрибутивах, основанных на нём, конфигурация хранится в одном файле - `/etc/network/interfaces`. Debian Handbook рекомендует добавлять в этот файл дополнительные секции с параметрами псевдонимов. Пример файла:\n\n```\nauto eth0\niface eth0 inet static\naddress 11.2.3.4\nnetmask 255.255.255.0\ngateway 11.2.3.1\ndns-nameservers 8.8.8.8 8.8.4.4\n\niface eth0 inet static\naddress 192.168.1.66\nnetmask 255.255.255.0\n\nauto lo\niface lo inet loopback\n```\n\nНаиболее удобный способ предоставляет дистрибутив Gentoo. Примерное содержание файла конфигурации сети `/etc/conf.d/net`:\n\n```\nconfig_eth0=(\n    \"1.2.3.4/24\"\n    \"5.6.7.8/16\"\n)\nroutes_eth0=( \"default via 1.2.3.1\" )\n```\n","source":"_posts/2015-06-17-several-ip-assign.md","raw":"---\nlayout: post\ntitle: Назначение интерфейсу нескольких IP-адресов при загрузке\nmodified: 2015-06-17\ntags: [network]\n---\nВ RHEL-совместимых дистрибутивах конфигурация сетевых интерфейсов хранится в файлах `/etc/sysconfig/network-scripts/ifcfg-<iface>`. Пример файла `ifcfg-eth0`:\n\n```\nDEVICE=\"eth0\"\nIPADDR0=\"1.2.3.4\"\nNETMASK0=\"255.255.255.0\"\nBROADCAST0=\"1.2.3.255\"\nGATEWAY=\"1.2.3.1\"\nIPADDR1=\"5.6.7.8\"\nNETMASK1=\"255.255.0.0\"\nBROADCAST1=\"5.6.255.255\"\nONBOOT=\"yes\"\n```\n\nПри такой конфигурации интерфейс eth0 при загрузке получит два сетевых адреса с разной маской, также в таблицу маршрутизации будет добавлена указанная запись для шлюза по умолчанию.\nВ Debian и дистрибутивах, основанных на нём, конфигурация хранится в одном файле - `/etc/network/interfaces`. Debian Handbook рекомендует добавлять в этот файл дополнительные секции с параметрами псевдонимов. Пример файла:\n\n```\nauto eth0\niface eth0 inet static\naddress 11.2.3.4\nnetmask 255.255.255.0\ngateway 11.2.3.1\ndns-nameservers 8.8.8.8 8.8.4.4\n\niface eth0 inet static\naddress 192.168.1.66\nnetmask 255.255.255.0\n\nauto lo\niface lo inet loopback\n```\n\nНаиболее удобный способ предоставляет дистрибутив Gentoo. Примерное содержание файла конфигурации сети `/etc/conf.d/net`:\n\n```\nconfig_eth0=(\n    \"1.2.3.4/24\"\n    \"5.6.7.8/16\"\n)\nroutes_eth0=( \"default via 1.2.3.1\" )\n```\n","slug":"2015-06-17-several-ip-assign","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo8x000qgkurfleendd9","content":"<p>В RHEL-совместимых дистрибутивах конфигурация сетевых интерфейсов хранится в файлах <code>/etc/sysconfig/network-scripts/ifcfg-&lt;iface&gt;</code>. Пример файла <code>ifcfg-eth0</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=&quot;eth0&quot;</div><div class=\"line\">IPADDR0=&quot;1.2.3.4&quot;</div><div class=\"line\">NETMASK0=&quot;255.255.255.0&quot;</div><div class=\"line\">BROADCAST0=&quot;1.2.3.255&quot;</div><div class=\"line\">GATEWAY=&quot;1.2.3.1&quot;</div><div class=\"line\">IPADDR1=&quot;5.6.7.8&quot;</div><div class=\"line\">NETMASK1=&quot;255.255.0.0&quot;</div><div class=\"line\">BROADCAST1=&quot;5.6.255.255&quot;</div><div class=\"line\">ONBOOT=&quot;yes&quot;</div></pre></td></tr></table></figure>\n<p>При такой конфигурации интерфейс eth0 при загрузке получит два сетевых адреса с разной маской, также в таблицу маршрутизации будет добавлена указанная запись для шлюза по умолчанию.<br>В Debian и дистрибутивах, основанных на нём, конфигурация хранится в одном файле - <code>/etc/network/interfaces</code>. Debian Handbook рекомендует добавлять в этот файл дополнительные секции с параметрами псевдонимов. Пример файла:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">auto eth0</div><div class=\"line\">iface eth0 inet static</div><div class=\"line\">address 11.2.3.4</div><div class=\"line\">netmask 255.255.255.0</div><div class=\"line\">gateway 11.2.3.1</div><div class=\"line\">dns-nameservers 8.8.8.8 8.8.4.4</div><div class=\"line\"></div><div class=\"line\">iface eth0 inet static</div><div class=\"line\">address 192.168.1.66</div><div class=\"line\">netmask 255.255.255.0</div><div class=\"line\"></div><div class=\"line\">auto lo</div><div class=\"line\">iface lo inet loopback</div></pre></td></tr></table></figure>\n<p>Наиболее удобный способ предоставляет дистрибутив Gentoo. Примерное содержание файла конфигурации сети <code>/etc/conf.d/net</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">config_eth0=(</div><div class=\"line\">    &quot;1.2.3.4/24&quot;</div><div class=\"line\">    &quot;5.6.7.8/16&quot;</div><div class=\"line\">)</div><div class=\"line\">routes_eth0=( &quot;default via 1.2.3.1&quot; )</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>В RHEL-совместимых дистрибутивах конфигурация сетевых интерфейсов хранится в файлах <code>/etc/sysconfig/network-scripts/ifcfg-&lt;iface&gt;</code>. Пример файла <code>ifcfg-eth0</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">DEVICE=&quot;eth0&quot;</div><div class=\"line\">IPADDR0=&quot;1.2.3.4&quot;</div><div class=\"line\">NETMASK0=&quot;255.255.255.0&quot;</div><div class=\"line\">BROADCAST0=&quot;1.2.3.255&quot;</div><div class=\"line\">GATEWAY=&quot;1.2.3.1&quot;</div><div class=\"line\">IPADDR1=&quot;5.6.7.8&quot;</div><div class=\"line\">NETMASK1=&quot;255.255.0.0&quot;</div><div class=\"line\">BROADCAST1=&quot;5.6.255.255&quot;</div><div class=\"line\">ONBOOT=&quot;yes&quot;</div></pre></td></tr></table></figure>\n<p>При такой конфигурации интерфейс eth0 при загрузке получит два сетевых адреса с разной маской, также в таблицу маршрутизации будет добавлена указанная запись для шлюза по умолчанию.<br>В Debian и дистрибутивах, основанных на нём, конфигурация хранится в одном файле - <code>/etc/network/interfaces</code>. Debian Handbook рекомендует добавлять в этот файл дополнительные секции с параметрами псевдонимов. Пример файла:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">auto eth0</div><div class=\"line\">iface eth0 inet static</div><div class=\"line\">address 11.2.3.4</div><div class=\"line\">netmask 255.255.255.0</div><div class=\"line\">gateway 11.2.3.1</div><div class=\"line\">dns-nameservers 8.8.8.8 8.8.4.4</div><div class=\"line\"></div><div class=\"line\">iface eth0 inet static</div><div class=\"line\">address 192.168.1.66</div><div class=\"line\">netmask 255.255.255.0</div><div class=\"line\"></div><div class=\"line\">auto lo</div><div class=\"line\">iface lo inet loopback</div></pre></td></tr></table></figure>\n<p>Наиболее удобный способ предоставляет дистрибутив Gentoo. Примерное содержание файла конфигурации сети <code>/etc/conf.d/net</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">config_eth0=(</div><div class=\"line\">    &quot;1.2.3.4/24&quot;</div><div class=\"line\">    &quot;5.6.7.8/16&quot;</div><div class=\"line\">)</div><div class=\"line\">routes_eth0=( &quot;default via 1.2.3.1&quot; )</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Отладка ошибки 502, вызываемой падением PHP-сценария","modified":"2015-06-18T21:00:00.000Z","_content":"Ошибка 502 является, пожалуй, наиболее сложной для отладки.\n\nОднако, если ошибка вызывана аварийным завершением работы PHP-сценария, найти причину можно достаточно быстро. На помощь придёт `gdb`.\n\nПервое, что нам нужно, это настроит сбор core-дампов в веб-сервере. Имея файл (предположим, что его имя core), загрузим его в `gdb`:\n\n```\n# gdb /opt/apache/bin/httpd core\nGNU gdb 6.8\nCopyright (C) 2008 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-pc-linux-gnu\"...\n(no debugging symbols found)\n\nwarning: Can't read pathname for load map: Input/output error.\nReading symbols from /lib64/libm.so.6...(no debugging symbols found)...done.\nLoaded symbols for /lib/libm.so.6\nReading symbols from /lib64/libcrypt.so.1...(no debugging symbols found)...done.\n...\n\nCore was generated by `/opt/apache/bin/httpd -f /etc/opt/apache/config/labirintum.conf'.\nProgram terminated with signal 11, Segmentation fault.\n[New process 30762]\n#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6\n(gdb)\n```\n\nВыводим backtrace командой `bt`:\n\n```\n#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6\n#1  0x00007f31f6048f94 in zend_prepare_string_for_scanning (str=<value optimized out>, filename=0x7f31f65e55bf \"\")\n    at Zend/zend_language_scanner.l:447\n#2  0x00007f31f600342f in zif_token_get_all (ht=<value optimized out>, return_value=0x33cc2d0,\n    return_value_ptr=<value optimized out>, this_ptr=<value optimized out>, return_value_used=<value optimized out>)\n    at /usr/src/php5.3/ext/tokenizer/tokenizer.c:177\n#3  0x00007f31f609de63 in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc5dc0)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:320\n#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#5  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#6  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc58d8)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n#7  0x00007f31f609d023 in execute (op_array=0x33e5738) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#8  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#9  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc3118)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n#10 0x00007f31f609d023 in execute (op_array=0x1dae780) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#11 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#12 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc2f90)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n#13 0x00007f31f609d023 in execute (op_array=0x25445c0) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#14 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#15 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc20a0)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n...\n```\n\nНам нужно перейти в четвёртый фрейм, соответствующий функции `execute()`, в которой происходит непосредственное исполнение интерпретатором сценария.\n\n```\n(gdb) frame 4\n#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n107\t\t\tif ((ret = EX(opline)->handler(execute_data TSRMLS_CC)) > 0) {\n```\n\nДалее можно узнать имя файла и имя функции, в которой возникает Segmentation Fault.\n\n```\n(gdb) print op_array.function_name\n$1 = 0x33e37a8 \"getPhpChunks\"\n(gdb) print op_array.filename\n$2 = 0x33828b8 \"/home/j/johndoe/beta.example.com/public_html/bitrix/modules/main/classes/general/php_parser.php\"\n(gdb)\n```\n\nИтак, теперь мы знаем имя файла, функции, и даже строку, в которой происходит падение интерпретатора.\n","source":"_posts/2015-06-19-debug-502-php.md","raw":"---\nlayout: post\ntitle: Отладка ошибки 502, вызываемой падением PHP-сценария\nmodified: 2015-06-19\ntags: [php, troubleshooting, apache]\n---\nОшибка 502 является, пожалуй, наиболее сложной для отладки.\n\nОднако, если ошибка вызывана аварийным завершением работы PHP-сценария, найти причину можно достаточно быстро. На помощь придёт `gdb`.\n\nПервое, что нам нужно, это настроит сбор core-дампов в веб-сервере. Имея файл (предположим, что его имя core), загрузим его в `gdb`:\n\n```\n# gdb /opt/apache/bin/httpd core\nGNU gdb 6.8\nCopyright (C) 2008 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.  Type \"show copying\"\nand \"show warranty\" for details.\nThis GDB was configured as \"x86_64-pc-linux-gnu\"...\n(no debugging symbols found)\n\nwarning: Can't read pathname for load map: Input/output error.\nReading symbols from /lib64/libm.so.6...(no debugging symbols found)...done.\nLoaded symbols for /lib/libm.so.6\nReading symbols from /lib64/libcrypt.so.1...(no debugging symbols found)...done.\n...\n\nCore was generated by `/opt/apache/bin/httpd -f /etc/opt/apache/config/labirintum.conf'.\nProgram terminated with signal 11, Segmentation fault.\n[New process 30762]\n#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6\n(gdb)\n```\n\nВыводим backtrace командой `bt`:\n\n```\n#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6\n#1  0x00007f31f6048f94 in zend_prepare_string_for_scanning (str=<value optimized out>, filename=0x7f31f65e55bf \"\")\n    at Zend/zend_language_scanner.l:447\n#2  0x00007f31f600342f in zif_token_get_all (ht=<value optimized out>, return_value=0x33cc2d0,\n    return_value_ptr=<value optimized out>, this_ptr=<value optimized out>, return_value_used=<value optimized out>)\n    at /usr/src/php5.3/ext/tokenizer/tokenizer.c:177\n#3  0x00007f31f609de63 in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc5dc0)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:320\n#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#5  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#6  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc58d8)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n#7  0x00007f31f609d023 in execute (op_array=0x33e5738) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#8  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#9  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc3118)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n#10 0x00007f31f609d023 in execute (op_array=0x1dae780) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#11 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#12 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc2f90)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n#13 0x00007f31f609d023 in execute (op_array=0x25445c0) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n#14 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so\n#15 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc20a0)\n    at /usr/src/php5.3/Zend/zend_vm_execute.h:344\n...\n```\n\nНам нужно перейти в четвёртый фрейм, соответствующий функции `execute()`, в которой происходит непосредственное исполнение интерпретатором сценария.\n\n```\n(gdb) frame 4\n#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107\n107\t\t\tif ((ret = EX(opline)->handler(execute_data TSRMLS_CC)) > 0) {\n```\n\nДалее можно узнать имя файла и имя функции, в которой возникает Segmentation Fault.\n\n```\n(gdb) print op_array.function_name\n$1 = 0x33e37a8 \"getPhpChunks\"\n(gdb) print op_array.filename\n$2 = 0x33828b8 \"/home/j/johndoe/beta.example.com/public_html/bitrix/modules/main/classes/general/php_parser.php\"\n(gdb)\n```\n\nИтак, теперь мы знаем имя файла, функции, и даже строку, в которой происходит падение интерпретатора.\n","slug":"2015-06-19-debug-502-php","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo91000sgkurh4h4cfha","content":"<p>Ошибка 502 является, пожалуй, наиболее сложной для отладки.</p>\n<p>Однако, если ошибка вызывана аварийным завершением работы PHP-сценария, найти причину можно достаточно быстро. На помощь придёт <code>gdb</code>.</p>\n<p>Первое, что нам нужно, это настроит сбор core-дампов в веб-сервере. Имея файл (предположим, что его имя core), загрузим его в <code>gdb</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"># gdb /opt/apache/bin/httpd core</div><div class=\"line\">GNU gdb 6.8</div><div class=\"line\">Copyright (C) 2008 Free Software Foundation, Inc.</div><div class=\"line\">License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;</div><div class=\"line\">This is free software: you are free to change and redistribute it.</div><div class=\"line\">There is NO WARRANTY, to the extent permitted by law.  Type &quot;show copying&quot;</div><div class=\"line\">and &quot;show warranty&quot; for details.</div><div class=\"line\">This GDB was configured as &quot;x86_64-pc-linux-gnu&quot;...</div><div class=\"line\">(no debugging symbols found)</div><div class=\"line\"></div><div class=\"line\">warning: Can&apos;t read pathname for load map: Input/output error.</div><div class=\"line\">Reading symbols from /lib64/libm.so.6...(no debugging symbols found)...done.</div><div class=\"line\">Loaded symbols for /lib/libm.so.6</div><div class=\"line\">Reading symbols from /lib64/libcrypt.so.1...(no debugging symbols found)...done.</div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\">Core was generated by `/opt/apache/bin/httpd -f /etc/opt/apache/config/labirintum.conf&apos;.</div><div class=\"line\">Program terminated with signal 11, Segmentation fault.</div><div class=\"line\">[New process 30762]</div><div class=\"line\">#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6</div><div class=\"line\">(gdb)</div></pre></td></tr></table></figure>\n<p>Выводим backtrace командой <code>bt</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6</div><div class=\"line\">#1  0x00007f31f6048f94 in zend_prepare_string_for_scanning (str=&lt;value optimized out&gt;, filename=0x7f31f65e55bf &quot;&quot;)</div><div class=\"line\">    at Zend/zend_language_scanner.l:447</div><div class=\"line\">#2  0x00007f31f600342f in zif_token_get_all (ht=&lt;value optimized out&gt;, return_value=0x33cc2d0,</div><div class=\"line\">    return_value_ptr=&lt;value optimized out&gt;, this_ptr=&lt;value optimized out&gt;, return_value_used=&lt;value optimized out&gt;)</div><div class=\"line\">    at /usr/src/php5.3/ext/tokenizer/tokenizer.c:177</div><div class=\"line\">#3  0x00007f31f609de63 in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc5dc0)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:320</div><div class=\"line\">#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#5  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#6  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc58d8)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">#7  0x00007f31f609d023 in execute (op_array=0x33e5738) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#8  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#9  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc3118)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">#10 0x00007f31f609d023 in execute (op_array=0x1dae780) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#11 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#12 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc2f90)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">#13 0x00007f31f609d023 in execute (op_array=0x25445c0) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#14 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#15 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc20a0)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">...</div></pre></td></tr></table></figure>\n<p>Нам нужно перейти в четвёртый фрейм, соответствующий функции <code>execute()</code>, в которой происходит непосредственное исполнение интерпретатором сценария.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">(gdb) frame 4</div><div class=\"line\">#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">107\t\t\tif ((ret = EX(opline)-&gt;handler(execute_data TSRMLS_CC)) &gt; 0) &#123;</div></pre></td></tr></table></figure>\n<p>Далее можно узнать имя файла и имя функции, в которой возникает Segmentation Fault.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">(gdb) print op_array.function_name</div><div class=\"line\">$1 = 0x33e37a8 &quot;getPhpChunks&quot;</div><div class=\"line\">(gdb) print op_array.filename</div><div class=\"line\">$2 = 0x33828b8 &quot;/home/j/johndoe/beta.example.com/public_html/bitrix/modules/main/classes/general/php_parser.php&quot;</div><div class=\"line\">(gdb)</div></pre></td></tr></table></figure>\n<p>Итак, теперь мы знаем имя файла, функции, и даже строку, в которой происходит падение интерпретатора.</p>\n","excerpt":"","more":"<p>Ошибка 502 является, пожалуй, наиболее сложной для отладки.</p>\n<p>Однако, если ошибка вызывана аварийным завершением работы PHP-сценария, найти причину можно достаточно быстро. На помощь придёт <code>gdb</code>.</p>\n<p>Первое, что нам нужно, это настроит сбор core-дампов в веб-сервере. Имея файл (предположим, что его имя core), загрузим его в <code>gdb</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\"># gdb /opt/apache/bin/httpd core</div><div class=\"line\">GNU gdb 6.8</div><div class=\"line\">Copyright (C) 2008 Free Software Foundation, Inc.</div><div class=\"line\">License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;</div><div class=\"line\">This is free software: you are free to change and redistribute it.</div><div class=\"line\">There is NO WARRANTY, to the extent permitted by law.  Type &quot;show copying&quot;</div><div class=\"line\">and &quot;show warranty&quot; for details.</div><div class=\"line\">This GDB was configured as &quot;x86_64-pc-linux-gnu&quot;...</div><div class=\"line\">(no debugging symbols found)</div><div class=\"line\"></div><div class=\"line\">warning: Can&apos;t read pathname for load map: Input/output error.</div><div class=\"line\">Reading symbols from /lib64/libm.so.6...(no debugging symbols found)...done.</div><div class=\"line\">Loaded symbols for /lib/libm.so.6</div><div class=\"line\">Reading symbols from /lib64/libcrypt.so.1...(no debugging symbols found)...done.</div><div class=\"line\">...</div><div class=\"line\"></div><div class=\"line\">Core was generated by `/opt/apache/bin/httpd -f /etc/opt/apache/config/labirintum.conf&apos;.</div><div class=\"line\">Program terminated with signal 11, Segmentation fault.</div><div class=\"line\">[New process 30762]</div><div class=\"line\">#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6</div><div class=\"line\">(gdb)</div></pre></td></tr></table></figure>\n<p>Выводим backtrace командой <code>bt</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">#0  0x00007f31f727649b in memcpy () from /lib/libc.so.6</div><div class=\"line\">#1  0x00007f31f6048f94 in zend_prepare_string_for_scanning (str=&lt;value optimized out&gt;, filename=0x7f31f65e55bf &quot;&quot;)</div><div class=\"line\">    at Zend/zend_language_scanner.l:447</div><div class=\"line\">#2  0x00007f31f600342f in zif_token_get_all (ht=&lt;value optimized out&gt;, return_value=0x33cc2d0,</div><div class=\"line\">    return_value_ptr=&lt;value optimized out&gt;, this_ptr=&lt;value optimized out&gt;, return_value_used=&lt;value optimized out&gt;)</div><div class=\"line\">    at /usr/src/php5.3/ext/tokenizer/tokenizer.c:177</div><div class=\"line\">#3  0x00007f31f609de63 in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc5dc0)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:320</div><div class=\"line\">#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#5  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#6  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc58d8)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">#7  0x00007f31f609d023 in execute (op_array=0x33e5738) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#8  0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#9  0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc3118)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">#10 0x00007f31f609d023 in execute (op_array=0x1dae780) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#11 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#12 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc2f90)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">#13 0x00007f31f609d023 in execute (op_array=0x25445c0) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">#14 0x00007f31f124faa6 in zend_oe () from /usr/local/lib/php/extensions/ZendGuardLoader.so</div><div class=\"line\">#15 0x00007f31f609d98e in zend_do_fcall_common_helper_SPEC (execute_data=0x7f31e2fc20a0)</div><div class=\"line\">    at /usr/src/php5.3/Zend/zend_vm_execute.h:344</div><div class=\"line\">...</div></pre></td></tr></table></figure>\n<p>Нам нужно перейти в четвёртый фрейм, соответствующий функции <code>execute()</code>, в которой происходит непосредственное исполнение интерпретатором сценария.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">(gdb) frame 4</div><div class=\"line\">#4  0x00007f31f609d023 in execute (op_array=0x33e2c08) at /usr/src/php5.3/Zend/zend_vm_execute.h:107</div><div class=\"line\">107\t\t\tif ((ret = EX(opline)-&gt;handler(execute_data TSRMLS_CC)) &gt; 0) &#123;</div></pre></td></tr></table></figure>\n<p>Далее можно узнать имя файла и имя функции, в которой возникает Segmentation Fault.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">(gdb) print op_array.function_name</div><div class=\"line\">$1 = 0x33e37a8 &quot;getPhpChunks&quot;</div><div class=\"line\">(gdb) print op_array.filename</div><div class=\"line\">$2 = 0x33828b8 &quot;/home/j/johndoe/beta.example.com/public_html/bitrix/modules/main/classes/general/php_parser.php&quot;</div><div class=\"line\">(gdb)</div></pre></td></tr></table></figure>\n<p>Итак, теперь мы знаем имя файла, функции, и даже строку, в которой происходит падение интерпретатора.</p>\n"},{"layout":"post","title":"nginx не запускается, безуспешно пытается bind 0.0.0.0:80","modified":"2015-06-16T21:00:00.000Z","_content":"При запуске nginx столкнулся с ошибкой:\n\n```\n* Checking nginx' configuration ...\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful                               [ ok ]\n * Starting nginx ...\nnginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)\n```\n\nПри этом `listen 80;` в конфигах не указывается. А забиндить `0.0.0.0:80` nginx не смог, так как на 80 порту на `localhost` слушает Apache.\nОказалось, что в одном из конфигов в `/etc/nginx/ssl-enabled`, которые подключаются директивой `include`, не указана директива `listen` вовсе. И `nginx` брал для неё значение по умолчанию, то есть `0.0.0.0:80`","source":"_posts/2015-06-23-nginx-bind-error.md","raw":"---\nlayout: post\ntitle: nginx не запускается, безуспешно пытается bind 0.0.0.0:80\nmodified: 2015-06-17\ntags: [nginx, troubleshooting]\n---\nПри запуске nginx столкнулся с ошибкой:\n\n```\n* Checking nginx' configuration ...\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful                               [ ok ]\n * Starting nginx ...\nnginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)\n```\n\nПри этом `listen 80;` в конфигах не указывается. А забиндить `0.0.0.0:80` nginx не смог, так как на 80 порту на `localhost` слушает Apache.\nОказалось, что в одном из конфигов в `/etc/nginx/ssl-enabled`, которые подключаются директивой `include`, не указана директива `listen` вовсе. И `nginx` брал для неё значение по умолчанию, то есть `0.0.0.0:80`","slug":"2015-06-23-nginx-bind-error","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo94000ugkur9tmn2a6e","content":"<p>При запуске nginx столкнулся с ошибкой:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">* Checking nginx&apos; configuration ...</div><div class=\"line\">nginx: the configuration file /etc/nginx/nginx.conf syntax is ok</div><div class=\"line\">nginx: configuration file /etc/nginx/nginx.conf test is successful                               [ ok ]</div><div class=\"line\"> * Starting nginx ...</div><div class=\"line\">nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)</div></pre></td></tr></table></figure>\n<p>При этом <code>listen 80;</code> в конфигах не указывается. А забиндить <code>0.0.0.0:80</code> nginx не смог, так как на 80 порту на <code>localhost</code> слушает Apache.<br>Оказалось, что в одном из конфигов в <code>/etc/nginx/ssl-enabled</code>, которые подключаются директивой <code>include</code>, не указана директива <code>listen</code> вовсе. И <code>nginx</code> брал для неё значение по умолчанию, то есть <code>0.0.0.0:80</code></p>\n","excerpt":"","more":"<p>При запуске nginx столкнулся с ошибкой:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">* Checking nginx&apos; configuration ...</div><div class=\"line\">nginx: the configuration file /etc/nginx/nginx.conf syntax is ok</div><div class=\"line\">nginx: configuration file /etc/nginx/nginx.conf test is successful                               [ ok ]</div><div class=\"line\"> * Starting nginx ...</div><div class=\"line\">nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Address already in use)</div></pre></td></tr></table></figure>\n<p>При этом <code>listen 80;</code> в конфигах не указывается. А забиндить <code>0.0.0.0:80</code> nginx не смог, так как на 80 порту на <code>localhost</code> слушает Apache.<br>Оказалось, что в одном из конфигов в <code>/etc/nginx/ssl-enabled</code>, которые подключаются директивой <code>include</code>, не указана директива <code>listen</code> вовсе. И <code>nginx</code> брал для неё значение по умолчанию, то есть <code>0.0.0.0:80</code></p>\n"},{"layout":"post","title":"Запуск ELK stack локально для быстрого анализа лог-файлов","modified":"2015-07-13T21:00:00.000Z","_content":"Столкнулся с необходимостью проанализировать логи Apache хостингового сервера. Период - около недели. Логов много - почти 2 миллиона строк.\n\nСамое удобное решение - развернуть на локальной машине ELK stack (Elasticsearch, Logstash, Kibana) и запихнуть туда логи. Делается это очень быстро.\n\n1) Скачиваем ELK с [elastic.co](http://elastic.co) (версия Elasticsearch должна быть та, которая совпадает с Logstash. В моём случае это 1.5.2 - последнняя версия Logstash)\n\n2)  Пишем конфиг для Logstash. Вот мой, для логов Apache:\n\n```\ninput {\n    file {\n        path => [ \"/home/gena/Desktop/galileo.log\" ]\n        sincedb_path => \"/dev/null\"\n        start_position => \"beginning\"\n    }\n}\nfilter {\n     grok {\n         match => { \"message\" => \"apache_access: %{IPORHOST:http_host} %{DATA:remote_addr} .* \\[%{HTTPDATE:time_local}\\] \\\"(?<request_method>[A-Z]+) %{DATA:request} HTTP\\/[01]\\.[0-9]\\\" (?<status>\\d\\d\\d) (?<body_bytes_sent>.*) %{QS:http_referer} %{QS:http_user_agent}\" }\n     }\n     date {\n         match => [ \"time_local\", \"dd/MMM/YYYY:HH:mm:ss Z\" ]\n     }\n}\noutput {\n    elasticsearch {\n    }\n}\n```\n\nСледует обратить внимание на опции `sincedb_path` и `start_position`. Если их не указать, можно впасть в долгие попытки понять, почему же не работает ввод из файла (если, к примеру, были ошибки в конфигурации и пришлось запускать Logstash несколько раз).\n\n3) Запускаем Elastisearch и Logstash:\n\n```\n$ logstash-1.5.2/bin/logstash -f apache.conf\n$ elasticsearch-1.5.2/bin/elasticsearch\n```\n\n4) Логи уже потекли в Elasticsearch. Теперь надо создать индекс `.kibana` для служебных нужд Kibana и включить для него Dynamic Mapping.\n```\n$ curl -XPUT localhost:9200/.kibana -d '{ \"index.mapper.dynamic\": true }'\n```\n\n5) Запускаем Kibana\n\n```\n$ kibana-4.1.1-linux-x64/bin/kibana\n```\n\n6) Открываем [http://localhost:5601](http://localhost:5601) (Kibana) и настраиваем шаблон для отображения индексов.\n\n7) ...\n\n8) PROFIT!!!\n\nТеперь можно работать с логами по-человечески.\n","source":"_posts/2015-07-14-local-elk-fast-start.md","raw":"---\nlayout: post\ntitle: Запуск ELK stack локально для быстрого анализа лог-файлов\nmodified: 2015-07-14\ntags: [logs, elk, apache]\n---\nСтолкнулся с необходимостью проанализировать логи Apache хостингового сервера. Период - около недели. Логов много - почти 2 миллиона строк.\n\nСамое удобное решение - развернуть на локальной машине ELK stack (Elasticsearch, Logstash, Kibana) и запихнуть туда логи. Делается это очень быстро.\n\n1) Скачиваем ELK с [elastic.co](http://elastic.co) (версия Elasticsearch должна быть та, которая совпадает с Logstash. В моём случае это 1.5.2 - последнняя версия Logstash)\n\n2)  Пишем конфиг для Logstash. Вот мой, для логов Apache:\n\n```\ninput {\n    file {\n        path => [ \"/home/gena/Desktop/galileo.log\" ]\n        sincedb_path => \"/dev/null\"\n        start_position => \"beginning\"\n    }\n}\nfilter {\n     grok {\n         match => { \"message\" => \"apache_access: %{IPORHOST:http_host} %{DATA:remote_addr} .* \\[%{HTTPDATE:time_local}\\] \\\"(?<request_method>[A-Z]+) %{DATA:request} HTTP\\/[01]\\.[0-9]\\\" (?<status>\\d\\d\\d) (?<body_bytes_sent>.*) %{QS:http_referer} %{QS:http_user_agent}\" }\n     }\n     date {\n         match => [ \"time_local\", \"dd/MMM/YYYY:HH:mm:ss Z\" ]\n     }\n}\noutput {\n    elasticsearch {\n    }\n}\n```\n\nСледует обратить внимание на опции `sincedb_path` и `start_position`. Если их не указать, можно впасть в долгие попытки понять, почему же не работает ввод из файла (если, к примеру, были ошибки в конфигурации и пришлось запускать Logstash несколько раз).\n\n3) Запускаем Elastisearch и Logstash:\n\n```\n$ logstash-1.5.2/bin/logstash -f apache.conf\n$ elasticsearch-1.5.2/bin/elasticsearch\n```\n\n4) Логи уже потекли в Elasticsearch. Теперь надо создать индекс `.kibana` для служебных нужд Kibana и включить для него Dynamic Mapping.\n```\n$ curl -XPUT localhost:9200/.kibana -d '{ \"index.mapper.dynamic\": true }'\n```\n\n5) Запускаем Kibana\n\n```\n$ kibana-4.1.1-linux-x64/bin/kibana\n```\n\n6) Открываем [http://localhost:5601](http://localhost:5601) (Kibana) и настраиваем шаблон для отображения индексов.\n\n7) ...\n\n8) PROFIT!!!\n\nТеперь можно работать с логами по-человечески.\n","slug":"2015-07-14-local-elk-fast-start","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo96000wgkurbls1gdbn","content":"<p>Столкнулся с необходимостью проанализировать логи Apache хостингового сервера. Период - около недели. Логов много - почти 2 миллиона строк.</p>\n<p>Самое удобное решение - развернуть на локальной машине ELK stack (Elasticsearch, Logstash, Kibana) и запихнуть туда логи. Делается это очень быстро.</p>\n<p>1) Скачиваем ELK с <a href=\"http://elastic.co\" target=\"_blank\" rel=\"external\">elastic.co</a> (версия Elasticsearch должна быть та, которая совпадает с Logstash. В моём случае это 1.5.2 - последнняя версия Logstash)</p>\n<p>2)  Пишем конфиг для Logstash. Вот мой, для логов Apache:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">input &#123;</div><div class=\"line\">    file &#123;</div><div class=\"line\">        path =&gt; [ &quot;/home/gena/Desktop/galileo.log&quot; ]</div><div class=\"line\">        sincedb_path =&gt; &quot;/dev/null&quot;</div><div class=\"line\">        start_position =&gt; &quot;beginning&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\">filter &#123;</div><div class=\"line\">     grok &#123;</div><div class=\"line\">         match =&gt; &#123; &quot;message&quot; =&gt; &quot;apache_access: %&#123;IPORHOST:http_host&#125; %&#123;DATA:remote_addr&#125; .* \\[%&#123;HTTPDATE:time_local&#125;\\] \\&quot;(?&lt;request_method&gt;[A-Z]+) %&#123;DATA:request&#125; HTTP\\/[01]\\.[0-9]\\&quot; (?&lt;status&gt;\\d\\d\\d) (?&lt;body_bytes_sent&gt;.*) %&#123;QS:http_referer&#125; %&#123;QS:http_user_agent&#125;&quot; &#125;</div><div class=\"line\">     &#125;</div><div class=\"line\">     date &#123;</div><div class=\"line\">         match =&gt; [ &quot;time_local&quot;, &quot;dd/MMM/YYYY:HH:mm:ss Z&quot; ]</div><div class=\"line\">     &#125;</div><div class=\"line\">&#125;</div><div class=\"line\">output &#123;</div><div class=\"line\">    elasticsearch &#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Следует обратить внимание на опции <code>sincedb_path</code> и <code>start_position</code>. Если их не указать, можно впасть в долгие попытки понять, почему же не работает ввод из файла (если, к примеру, были ошибки в конфигурации и пришлось запускать Logstash несколько раз).</p>\n<p>3) Запускаем Elastisearch и Logstash:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ logstash-1.5.2/bin/logstash -f apache.conf</div><div class=\"line\">$ elasticsearch-1.5.2/bin/elasticsearch</div></pre></td></tr></table></figure>\n<p>4) Логи уже потекли в Elasticsearch. Теперь надо создать индекс <code>.kibana</code> для служебных нужд Kibana и включить для него Dynamic Mapping.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl -XPUT localhost:9200/.kibana -d &apos;&#123; &quot;index.mapper.dynamic&quot;: true &#125;&apos;</div></pre></td></tr></table></figure></p>\n<p>5) Запускаем Kibana</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ kibana-4.1.1-linux-x64/bin/kibana</div></pre></td></tr></table></figure>\n<p>6) Открываем <a href=\"http://localhost:5601\" target=\"_blank\" rel=\"external\">http://localhost:5601</a> (Kibana) и настраиваем шаблон для отображения индексов.</p>\n<p>7) …</p>\n<p>8) PROFIT!!!</p>\n<p>Теперь можно работать с логами по-человечески.</p>\n","excerpt":"","more":"<p>Столкнулся с необходимостью проанализировать логи Apache хостингового сервера. Период - около недели. Логов много - почти 2 миллиона строк.</p>\n<p>Самое удобное решение - развернуть на локальной машине ELK stack (Elasticsearch, Logstash, Kibana) и запихнуть туда логи. Делается это очень быстро.</p>\n<p>1) Скачиваем ELK с <a href=\"http://elastic.co\">elastic.co</a> (версия Elasticsearch должна быть та, которая совпадает с Logstash. В моём случае это 1.5.2 - последнняя версия Logstash)</p>\n<p>2)  Пишем конфиг для Logstash. Вот мой, для логов Apache:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div></pre></td><td class=\"code\"><pre><div class=\"line\">input &#123;</div><div class=\"line\">    file &#123;</div><div class=\"line\">        path =&gt; [ &quot;/home/gena/Desktop/galileo.log&quot; ]</div><div class=\"line\">        sincedb_path =&gt; &quot;/dev/null&quot;</div><div class=\"line\">        start_position =&gt; &quot;beginning&quot;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div><div class=\"line\">filter &#123;</div><div class=\"line\">     grok &#123;</div><div class=\"line\">         match =&gt; &#123; &quot;message&quot; =&gt; &quot;apache_access: %&#123;IPORHOST:http_host&#125; %&#123;DATA:remote_addr&#125; .* \\[%&#123;HTTPDATE:time_local&#125;\\] \\&quot;(?&lt;request_method&gt;[A-Z]+) %&#123;DATA:request&#125; HTTP\\/[01]\\.[0-9]\\&quot; (?&lt;status&gt;\\d\\d\\d) (?&lt;body_bytes_sent&gt;.*) %&#123;QS:http_referer&#125; %&#123;QS:http_user_agent&#125;&quot; &#125;</div><div class=\"line\">     &#125;</div><div class=\"line\">     date &#123;</div><div class=\"line\">         match =&gt; [ &quot;time_local&quot;, &quot;dd/MMM/YYYY:HH:mm:ss Z&quot; ]</div><div class=\"line\">     &#125;</div><div class=\"line\">&#125;</div><div class=\"line\">output &#123;</div><div class=\"line\">    elasticsearch &#123;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Следует обратить внимание на опции <code>sincedb_path</code> и <code>start_position</code>. Если их не указать, можно впасть в долгие попытки понять, почему же не работает ввод из файла (если, к примеру, были ошибки в конфигурации и пришлось запускать Logstash несколько раз).</p>\n<p>3) Запускаем Elastisearch и Logstash:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ logstash-1.5.2/bin/logstash -f apache.conf</div><div class=\"line\">$ elasticsearch-1.5.2/bin/elasticsearch</div></pre></td></tr></table></figure>\n<p>4) Логи уже потекли в Elasticsearch. Теперь надо создать индекс <code>.kibana</code> для служебных нужд Kibana и включить для него Dynamic Mapping.<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ curl -XPUT localhost:9200/.kibana -d &apos;&#123; &quot;index.mapper.dynamic&quot;: true &#125;&apos;</div></pre></td></tr></table></figure></p>\n<p>5) Запускаем Kibana</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ kibana-4.1.1-linux-x64/bin/kibana</div></pre></td></tr></table></figure>\n<p>6) Открываем <a href=\"http://localhost:5601\">http://localhost:5601</a> (Kibana) и настраиваем шаблон для отображения индексов.</p>\n<p>7) …</p>\n<p>8) PROFIT!!!</p>\n<p>Теперь можно работать с логами по-человечески.</p>\n"},{"layout":"post","title":"Неприятная особенность модуля Puppet concat","modified":"2015-07-16T21:00:00.000Z","_content":"Я потратил два часа в поисках причины неправильного порядка фрагментов в результирующем файле.\n\nВ документации к популярному и поддерживаемому Puppet Labs [модулю Puppet concat](https://forge.puppetlabs.com/puppetlabs/concat) говорится, что значение параметра `order` для дефайна `concat::fragment` может быть\n\n> a string (recommended) or an integer\n\nПо факту (по крайней мере в Puppet 3.7) integer не сработает. Нужно указывать string. Ниже пример.\n\nПлохо:\n\n```puppet\nconcat::fragment { 'opening':\n  target  => $::dummy_module::conf::conf_path,\n  order   => 1,\n  content => \"databases = {\\n\",\n}\n```\n\nХорошо:\n\n```puppet\nconcat::fragment { 'opening':\n  target  => $::dummy_module::conf::conf_path,\n  order   => '01',\n  content => \"databases = {\\n\",\n}\n```\n","source":"_posts/2015-07-17-puppet-concat-order.md","raw":"---\nlayout: post\ntitle: Неприятная особенность модуля Puppet concat\nmodified: 2015-07-17\ntags: [puppet, troubleshooting]\n---\nЯ потратил два часа в поисках причины неправильного порядка фрагментов в результирующем файле.\n\nВ документации к популярному и поддерживаемому Puppet Labs [модулю Puppet concat](https://forge.puppetlabs.com/puppetlabs/concat) говорится, что значение параметра `order` для дефайна `concat::fragment` может быть\n\n> a string (recommended) or an integer\n\nПо факту (по крайней мере в Puppet 3.7) integer не сработает. Нужно указывать string. Ниже пример.\n\nПлохо:\n\n```puppet\nconcat::fragment { 'opening':\n  target  => $::dummy_module::conf::conf_path,\n  order   => 1,\n  content => \"databases = {\\n\",\n}\n```\n\nХорошо:\n\n```puppet\nconcat::fragment { 'opening':\n  target  => $::dummy_module::conf::conf_path,\n  order   => '01',\n  content => \"databases = {\\n\",\n}\n```\n","slug":"2015-07-17-puppet-concat-order","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo97000zgkurjd0g273i","content":"<p>Я потратил два часа в поисках причины неправильного порядка фрагментов в результирующем файле.</p>\n<p>В документации к популярному и поддерживаемому Puppet Labs <a href=\"https://forge.puppetlabs.com/puppetlabs/concat\" target=\"_blank\" rel=\"external\">модулю Puppet concat</a> говорится, что значение параметра <code>order</code> для дефайна <code>concat::fragment</code> может быть</p>\n<blockquote>\n<p>a string (recommended) or an integer</p>\n</blockquote>\n<p>По факту (по крайней мере в Puppet 3.7) integer не сработает. Нужно указывать string. Ниже пример.</p>\n<p>Плохо:</p>\n<figure class=\"highlight puppet\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">concat::<span class=\"keyword\">fragment</span> &#123; <span class=\"string\">'opening'</span>:</div><div class=\"line\">  <span class=\"attr\">target</span>  =&gt; <span class=\"variable\">$::dummy_module::conf::conf_path</span>,</div><div class=\"line\">  <span class=\"attr\">order</span>   =&gt; <span class=\"number\">1</span>,</div><div class=\"line\">  <span class=\"attr\">content</span> =&gt; <span class=\"string\">\"databases = &#123;\\n\"</span>,</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Хорошо:</p>\n<figure class=\"highlight puppet\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">concat::<span class=\"keyword\">fragment</span> &#123; <span class=\"string\">'opening'</span>:</div><div class=\"line\">  <span class=\"attr\">target</span>  =&gt; <span class=\"variable\">$::dummy_module::conf::conf_path</span>,</div><div class=\"line\">  <span class=\"attr\">order</span>   =&gt; <span class=\"string\">'01'</span>,</div><div class=\"line\">  <span class=\"attr\">content</span> =&gt; <span class=\"string\">\"databases = &#123;\\n\"</span>,</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>Я потратил два часа в поисках причины неправильного порядка фрагментов в результирующем файле.</p>\n<p>В документации к популярному и поддерживаемому Puppet Labs <a href=\"https://forge.puppetlabs.com/puppetlabs/concat\">модулю Puppet concat</a> говорится, что значение параметра <code>order</code> для дефайна <code>concat::fragment</code> может быть</p>\n<blockquote>\n<p>a string (recommended) or an integer</p>\n</blockquote>\n<p>По факту (по крайней мере в Puppet 3.7) integer не сработает. Нужно указывать string. Ниже пример.</p>\n<p>Плохо:</p>\n<figure class=\"highlight puppet\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">concat::<span class=\"keyword\">fragment</span> &#123; <span class=\"string\">'opening'</span>:</div><div class=\"line\">  <span class=\"attr\">target</span>  =&gt; <span class=\"variable\">$::dummy_module::conf::conf_path</span>,</div><div class=\"line\">  <span class=\"attr\">order</span>   =&gt; <span class=\"number\">1</span>,</div><div class=\"line\">  <span class=\"attr\">content</span> =&gt; <span class=\"string\">\"databases = &#123;\\n\"</span>,</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>Хорошо:</p>\n<figure class=\"highlight puppet\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">concat::<span class=\"keyword\">fragment</span> &#123; <span class=\"string\">'opening'</span>:</div><div class=\"line\">  <span class=\"attr\">target</span>  =&gt; <span class=\"variable\">$::dummy_module::conf::conf_path</span>,</div><div class=\"line\">  <span class=\"attr\">order</span>   =&gt; <span class=\"string\">'01'</span>,</div><div class=\"line\">  <span class=\"attr\">content</span> =&gt; <span class=\"string\">\"databases = &#123;\\n\"</span>,</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Сравнение IP-адресов в MySQL","modified":"2015-09-06T21:00:00.000Z","_content":"\nВ MySQL есть две интересные функции: `INET_ATON()` и `INET_NTOA()`.\n\nОни позволяют переводить IP-адреса в десятичный вид и обратно. Это очень удобно, если нужно выбрать из таблицы IP, принадлежащий определённой подсети.\nНапример:\n\n```sql\nSELECT\n    ip AS stor_backup_ip\nFROM\n    `billing`.`servers_backup_interfaces`\nWHERE\n    (INET_ATON(ip) & (-1<<11)) = INET_NTOA(\"172.16.16.0\")\nAND\n    name = \"storage75\";\n```\n","source":"_posts/2015-09-07-mysql-ip.md","raw":"---\nlayout: post\ntitle: Сравнение IP-адресов в MySQL\nmodified: 2015-09-07\ntags: [mysql]\n---\n\nВ MySQL есть две интересные функции: `INET_ATON()` и `INET_NTOA()`.\n\nОни позволяют переводить IP-адреса в десятичный вид и обратно. Это очень удобно, если нужно выбрать из таблицы IP, принадлежащий определённой подсети.\nНапример:\n\n```sql\nSELECT\n    ip AS stor_backup_ip\nFROM\n    `billing`.`servers_backup_interfaces`\nWHERE\n    (INET_ATON(ip) & (-1<<11)) = INET_NTOA(\"172.16.16.0\")\nAND\n    name = \"storage75\";\n```\n","slug":"2015-09-07-mysql-ip","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo980010gkurq3j4bzd2","content":"<p>В MySQL есть две интересные функции: <code>INET_ATON()</code> и <code>INET_NTOA()</code>.</p>\n<p>Они позволяют переводить IP-адреса в десятичный вид и обратно. Это очень удобно, если нужно выбрать из таблицы IP, принадлежащий определённой подсети.<br>Например:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span></div><div class=\"line\">    ip <span class=\"keyword\">AS</span> stor_backup_ip</div><div class=\"line\"><span class=\"keyword\">FROM</span></div><div class=\"line\">    <span class=\"string\">`billing`</span>.<span class=\"string\">`servers_backup_interfaces`</span></div><div class=\"line\"><span class=\"keyword\">WHERE</span></div><div class=\"line\">    (<span class=\"keyword\">INET_ATON</span>(ip) &amp; (<span class=\"number\">-1</span>&lt;&lt;<span class=\"number\">11</span>)) = <span class=\"keyword\">INET_NTOA</span>(<span class=\"string\">\"172.16.16.0\"</span>)</div><div class=\"line\"><span class=\"keyword\">AND</span></div><div class=\"line\">    <span class=\"keyword\">name</span> = <span class=\"string\">\"storage75\"</span>;</div></pre></td></tr></table></figure>\n","excerpt":"","more":"<p>В MySQL есть две интересные функции: <code>INET_ATON()</code> и <code>INET_NTOA()</code>.</p>\n<p>Они позволяют переводить IP-адреса в десятичный вид и обратно. Это очень удобно, если нужно выбрать из таблицы IP, принадлежащий определённой подсети.<br>Например:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span></div><div class=\"line\">    ip <span class=\"keyword\">AS</span> stor_backup_ip</div><div class=\"line\"><span class=\"keyword\">FROM</span></div><div class=\"line\">    <span class=\"string\">`billing`</span>.<span class=\"string\">`servers_backup_interfaces`</span></div><div class=\"line\"><span class=\"keyword\">WHERE</span></div><div class=\"line\">    (<span class=\"keyword\">INET_ATON</span>(ip) &amp; (<span class=\"number\">-1</span>&lt;&lt;<span class=\"number\">11</span>)) = <span class=\"keyword\">INET_NTOA</span>(<span class=\"string\">\"172.16.16.0\"</span>)</div><div class=\"line\"><span class=\"keyword\">AND</span></div><div class=\"line\">    <span class=\"keyword\">name</span> = <span class=\"string\">\"storage75\"</span>;</div></pre></td></tr></table></figure>\n"},{"layout":"post","title":"Хранимые процедуры и кодировка","modified":"2015-09-23T21:00:00.000Z","_content":"\nСтолкнулись с серьёзной деградацией производительности хранимых функций MySQL на реплике.\n\nВыяснилось, что запросы к хранимой функции выполняются слишком долго. Анализ PROCESSLIST'а выявил, что на мастере и на реплике запросы, выполняющиеся внутри функции, выглядят по-рзному.\n\nМастер:\n\n```\nmysql> SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = 'johndoe' AND end_date < NOW() AND NOT g.name <=> \"certificate\";\n+-----------+\n| SUM(cost) |\n+-----------+\n|        50 |\n+-----------+\n1 row in set (0.00 sec)\n\n```\n\nРеплика:\n\n```\nmysql> SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = NAME_CONST('customer',_utf8'johndoe' COLLATE 'utf8_general_ci') AND end_date < NOW() AND NOT g.name <=> \"certificate\";\n+-----------+\n| SUM(cost) |\n+-----------+\n|        50 |\n+-----------+\n1 row in set (1.64 sec)\n\nmysql>\n```\n\nНа реплике происходит перевод аргумента функции в другую кодировку. Из-за того, что в запросе поле _customer_id_ сравнивается с результатом встроенной функции, а не с константой, не используется индекс. Из-за этого и происходит деградация производительности.\n\nПричина оказалась в том, что база данных на реплике создана с другими CHARACTER SET и COLLATION, нежели чем на мастере (utf8 против koi8r).\n\nКак временное решение пришлось изменить код функции на реплике, явно указав аргументу `customer` кодировку koi8r. Чтобы предотвратить появление таких ситуаций в будущем, надо лишь выполнить `ALTER SCHEMA billing CHARACTER SET = \"koi8r\" COLLATE = \"koi8r_general_ci\"`.\n\nСсылки по теме:\n\n1. [ http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/](http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/)\n","source":"_posts/2015-09-24-mysql-charset-proc.md","raw":"---\nlayout: post\ntitle: Хранимые процедуры и кодировка\nmodified: 2015-09-24\ntags: [mysql, performance]\n---\n\nСтолкнулись с серьёзной деградацией производительности хранимых функций MySQL на реплике.\n\nВыяснилось, что запросы к хранимой функции выполняются слишком долго. Анализ PROCESSLIST'а выявил, что на мастере и на реплике запросы, выполняющиеся внутри функции, выглядят по-рзному.\n\nМастер:\n\n```\nmysql> SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = 'johndoe' AND end_date < NOW() AND NOT g.name <=> \"certificate\";\n+-----------+\n| SUM(cost) |\n+-----------+\n|        50 |\n+-----------+\n1 row in set (0.00 sec)\n\n```\n\nРеплика:\n\n```\nmysql> SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = NAME_CONST('customer',_utf8'johndoe' COLLATE 'utf8_general_ci') AND end_date < NOW() AND NOT g.name <=> \"certificate\";\n+-----------+\n| SUM(cost) |\n+-----------+\n|        50 |\n+-----------+\n1 row in set (1.64 sec)\n\nmysql>\n```\n\nНа реплике происходит перевод аргумента функции в другую кодировку. Из-за того, что в запросе поле _customer_id_ сравнивается с результатом встроенной функции, а не с константой, не используется индекс. Из-за этого и происходит деградация производительности.\n\nПричина оказалась в том, что база данных на реплике создана с другими CHARACTER SET и COLLATION, нежели чем на мастере (utf8 против koi8r).\n\nКак временное решение пришлось изменить код функции на реплике, явно указав аргументу `customer` кодировку koi8r. Чтобы предотвратить появление таких ситуаций в будущем, надо лишь выполнить `ALTER SCHEMA billing CHARACTER SET = \"koi8r\" COLLATE = \"koi8r_general_ci\"`.\n\nСсылки по теме:\n\n1. [ http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/](http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/)\n","slug":"2015-09-24-mysql-charset-proc","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo9a0012gkurcn2sdnsv","content":"<p>Столкнулись с серьёзной деградацией производительности хранимых функций MySQL на реплике.</p>\n<p>Выяснилось, что запросы к хранимой функции выполняются слишком долго. Анализ PROCESSLIST’а выявил, что на мастере и на реплике запросы, выполняющиеся внутри функции, выглядят по-рзному.</p>\n<p>Мастер:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = &apos;johndoe&apos; AND end_date &lt; NOW() AND NOT g.name &lt;=&gt; &quot;certificate&quot;;</div><div class=\"line\">+-----------+</div><div class=\"line\">| SUM(cost) |</div><div class=\"line\">+-----------+</div><div class=\"line\">|        50 |</div><div class=\"line\">+-----------+</div><div class=\"line\">1 row in set (0.00 sec)</div></pre></td></tr></table></figure>\n<p>Реплика:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = NAME_CONST(&apos;customer&apos;,_utf8&apos;johndoe&apos; COLLATE &apos;utf8_general_ci&apos;) AND end_date &lt; NOW() AND NOT g.name &lt;=&gt; &quot;certificate&quot;;</div><div class=\"line\">+-----------+</div><div class=\"line\">| SUM(cost) |</div><div class=\"line\">+-----------+</div><div class=\"line\">|        50 |</div><div class=\"line\">+-----------+</div><div class=\"line\">1 row in set (1.64 sec)</div><div class=\"line\"></div><div class=\"line\">mysql&gt;</div></pre></td></tr></table></figure>\n<p>На реплике происходит перевод аргумента функции в другую кодировку. Из-за того, что в запросе поле _customer<em>id</em> сравнивается с результатом встроенной функции, а не с константой, не используется индекс. Из-за этого и происходит деградация производительности.</p>\n<p>Причина оказалась в том, что база данных на реплике создана с другими CHARACTER SET и COLLATION, нежели чем на мастере (utf8 против koi8r).</p>\n<p>Как временное решение пришлось изменить код функции на реплике, явно указав аргументу <code>customer</code> кодировку koi8r. Чтобы предотвратить появление таких ситуаций в будущем, надо лишь выполнить <code>ALTER SCHEMA billing CHARACTER SET = &quot;koi8r&quot; COLLATE = &quot;koi8r_general_ci&quot;</code>.</p>\n<p>Ссылки по теме:</p>\n<ol>\n<li><a href=\"http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/\" target=\"_blank\" rel=\"external\"> http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/</a></li>\n</ol>\n","excerpt":"","more":"<p>Столкнулись с серьёзной деградацией производительности хранимых функций MySQL на реплике.</p>\n<p>Выяснилось, что запросы к хранимой функции выполняются слишком долго. Анализ PROCESSLIST’а выявил, что на мастере и на реплике запросы, выполняющиеся внутри функции, выглядят по-рзному.</p>\n<p>Мастер:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = &apos;johndoe&apos; AND end_date &lt; NOW() AND NOT g.name &lt;=&gt; &quot;certificate&quot;;</div><div class=\"line\">+-----------+</div><div class=\"line\">| SUM(cost) |</div><div class=\"line\">+-----------+</div><div class=\"line\">|        50 |</div><div class=\"line\">+-----------+</div><div class=\"line\">1 row in set (0.00 sec)</div></pre></td></tr></table></figure>\n<p>Реплика:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">mysql&gt; SELECT SUM(cost) FROM ... LEFT JOIN ... WHERE customer_id = NAME_CONST(&apos;customer&apos;,_utf8&apos;johndoe&apos; COLLATE &apos;utf8_general_ci&apos;) AND end_date &lt; NOW() AND NOT g.name &lt;=&gt; &quot;certificate&quot;;</div><div class=\"line\">+-----------+</div><div class=\"line\">| SUM(cost) |</div><div class=\"line\">+-----------+</div><div class=\"line\">|        50 |</div><div class=\"line\">+-----------+</div><div class=\"line\">1 row in set (1.64 sec)</div><div class=\"line\"></div><div class=\"line\">mysql&gt;</div></pre></td></tr></table></figure>\n<p>На реплике происходит перевод аргумента функции в другую кодировку. Из-за того, что в запросе поле _customer<em>id</em> сравнивается с результатом встроенной функции, а не с константой, не используется индекс. Из-за этого и происходит деградация производительности.</p>\n<p>Причина оказалась в том, что база данных на реплике создана с другими CHARACTER SET и COLLATION, нежели чем на мастере (utf8 против koi8r).</p>\n<p>Как временное решение пришлось изменить код функции на реплике, явно указав аргументу <code>customer</code> кодировку koi8r. Чтобы предотвратить появление таких ситуаций в будущем, надо лишь выполнить <code>ALTER SCHEMA billing CHARACTER SET = &quot;koi8r&quot; COLLATE = &quot;koi8r_general_ci&quot;</code>.</p>\n<p>Ссылки по теме:</p>\n<ol>\n<li><a href=\"http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/\"> http://www.justincarmony.com/blog/2011/02/02/mysql-stored-procedure-name_const-and-character-sets/</a></li>\n</ol>\n"},{"layout":"post","title":"Ошибка puppet cert - header too long","modified":"2015-10-11T21:00:00.000Z","_content":"\nВызов `puppet cert list` завершается с неочевидной ошибкой:\n\n```\nroot@puppet.example.com:~# puppet cert list\nError: header too long\nroot@puppet.example.com:~#\n```\n\nНаиболее частая причина - пустой запрос на подпись сертификата. В таком случае нам поможет пара команд:\n\n```\nroot@puppet.example.com:~# cd /var/lib/puppet/ssl/ca/requests\nroot@puppet.example.com:/var/lib/puppet/ssl/ca/requests# find . -type f -empty\n./bogushost.example.com.pem\nroot@puppet.example.com:/var/lib/puppet/ssl/ca/requests# rm ./bogushost.example.com.pem\n```\n\nМожно, конечно, запустить `find` с ключом `-delete`, но тогда вы не узнаете, какой хост отправил некорректный запрос.\n","source":"_posts/2015-10-12-puppet-cert-error-header-too-long.md","raw":"---\nlayout: post\ntitle: Ошибка puppet cert - header too long\nmodified: 2015-10-12\ntags: [puppet, troubleshooting]\n---\n\nВызов `puppet cert list` завершается с неочевидной ошибкой:\n\n```\nroot@puppet.example.com:~# puppet cert list\nError: header too long\nroot@puppet.example.com:~#\n```\n\nНаиболее частая причина - пустой запрос на подпись сертификата. В таком случае нам поможет пара команд:\n\n```\nroot@puppet.example.com:~# cd /var/lib/puppet/ssl/ca/requests\nroot@puppet.example.com:/var/lib/puppet/ssl/ca/requests# find . -type f -empty\n./bogushost.example.com.pem\nroot@puppet.example.com:/var/lib/puppet/ssl/ca/requests# rm ./bogushost.example.com.pem\n```\n\nМожно, конечно, запустить `find` с ключом `-delete`, но тогда вы не узнаете, какой хост отправил некорректный запрос.\n","slug":"2015-10-12-puppet-cert-error-header-too-long","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo9c0014gkurhr3meh8u","content":"<p>Вызов <code>puppet cert list</code> завершается с неочевидной ошибкой:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">root@puppet.example.com:~# puppet cert list</div><div class=\"line\">Error: header too long</div><div class=\"line\">root@puppet.example.com:~#</div></pre></td></tr></table></figure>\n<p>Наиболее частая причина - пустой запрос на подпись сертификата. В таком случае нам поможет пара команд:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">root@puppet.example.com:~# cd /var/lib/puppet/ssl/ca/requests</div><div class=\"line\">root@puppet.example.com:/var/lib/puppet/ssl/ca/requests# find . -type f -empty</div><div class=\"line\">./bogushost.example.com.pem</div><div class=\"line\">root@puppet.example.com:/var/lib/puppet/ssl/ca/requests# rm ./bogushost.example.com.pem</div></pre></td></tr></table></figure>\n<p>Можно, конечно, запустить <code>find</code> с ключом <code>-delete</code>, но тогда вы не узнаете, какой хост отправил некорректный запрос.</p>\n","excerpt":"","more":"<p>Вызов <code>puppet cert list</code> завершается с неочевидной ошибкой:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">root@puppet.example.com:~# puppet cert list</div><div class=\"line\">Error: header too long</div><div class=\"line\">root@puppet.example.com:~#</div></pre></td></tr></table></figure>\n<p>Наиболее частая причина - пустой запрос на подпись сертификата. В таком случае нам поможет пара команд:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">root@puppet.example.com:~# cd /var/lib/puppet/ssl/ca/requests</div><div class=\"line\">root@puppet.example.com:/var/lib/puppet/ssl/ca/requests# find . -type f -empty</div><div class=\"line\">./bogushost.example.com.pem</div><div class=\"line\">root@puppet.example.com:/var/lib/puppet/ssl/ca/requests# rm ./bogushost.example.com.pem</div></pre></td></tr></table></figure>\n<p>Можно, конечно, запустить <code>find</code> с ключом <code>-delete</code>, но тогда вы не узнаете, какой хост отправил некорректный запрос.</p>\n"},{"layout":"post","title":"Настройка логирование в Python","modified":"2015-12-18T21:00:00.000Z","_content":"Архитектура логирования в Python описана в [PEP 282](https://www.python.org/dev/peps/pep-0282/). В состав стандартной библиотеки входит модуль `logging`.\nПример настройки логирования для скрипта. Вывод сообщений уровня DEBUG и выше идёт в файл, вывод сообщений уровня INFO и выше - на консоль.\n\n```python\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\nconsole.setFormatter(logging.Formatter('[%(levelname)s] %(message)s'))\nlogger.addHandler(console)\n\nlogfile = logging.FileHandler(LOGFILE)\nlogfile.setLevel(logging.DEBUG)\nlogfile.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s',\n                                       datefmt='[%d.%m.%Y - %H:%M:%S]'))\nlogger.addHandler(logfile)\n```\n\nНачиная с Python 2.7 настройки `logging` можно описать в словаре. Это намного более удобный способ, хоть и менее гибкий:\n\n```python\nimport logging\nfrom logging.config import dictConfig\n\nlogging_config = dict(\n    version=1,\n    formatters={\n        'console': {\n            'format': '[%(levelname)s] %(message)s'\n        },\n        'file': {\n            'format': '%(asctime)s [%(levelname)s] %(message)s',\n            'datefmt': '[%d.%m.%Y - %H:%M:%S]'\n        }\n    },\n    handlers={\n        'console': {\n            'class': 'logging.StreamHandler',\n            'formatter': 'console',\n            'level': logging.INFO\n        },\n        'file': {\n            'class': 'logging.FileHandler',\n            'formatter': 'file',\n            'filename': logfile,\n            'level': logging.DEBUG\n        }\n    },\n    loggers={\n        'root': {'handlers': ['console', 'file'], 'level': logging.DEBUG}\n    }\n)\n\ndictConfig(logging_config)\nlogger = logging.getLogger('root')\n```\n\nБолее подробно о логировании в Python написано тут: [Hitchhiker's Guide to Python](http://docs.python-guide.org/en/latest/writing/logging/)\n","source":"_posts/2015-11-10-python-no-sys-exit-in-signal-handlers.md","raw":"---\nlayout: post\ntitle: Настройка логирование в Python\nmodified: 2015-12-19\ntags: [python]\n---\nАрхитектура логирования в Python описана в [PEP 282](https://www.python.org/dev/peps/pep-0282/). В состав стандартной библиотеки входит модуль `logging`.\nПример настройки логирования для скрипта. Вывод сообщений уровня DEBUG и выше идёт в файл, вывод сообщений уровня INFO и выше - на консоль.\n\n```python\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\nconsole.setFormatter(logging.Formatter('[%(levelname)s] %(message)s'))\nlogger.addHandler(console)\n\nlogfile = logging.FileHandler(LOGFILE)\nlogfile.setLevel(logging.DEBUG)\nlogfile.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s',\n                                       datefmt='[%d.%m.%Y - %H:%M:%S]'))\nlogger.addHandler(logfile)\n```\n\nНачиная с Python 2.7 настройки `logging` можно описать в словаре. Это намного более удобный способ, хоть и менее гибкий:\n\n```python\nimport logging\nfrom logging.config import dictConfig\n\nlogging_config = dict(\n    version=1,\n    formatters={\n        'console': {\n            'format': '[%(levelname)s] %(message)s'\n        },\n        'file': {\n            'format': '%(asctime)s [%(levelname)s] %(message)s',\n            'datefmt': '[%d.%m.%Y - %H:%M:%S]'\n        }\n    },\n    handlers={\n        'console': {\n            'class': 'logging.StreamHandler',\n            'formatter': 'console',\n            'level': logging.INFO\n        },\n        'file': {\n            'class': 'logging.FileHandler',\n            'formatter': 'file',\n            'filename': logfile,\n            'level': logging.DEBUG\n        }\n    },\n    loggers={\n        'root': {'handlers': ['console', 'file'], 'level': logging.DEBUG}\n    }\n)\n\ndictConfig(logging_config)\nlogger = logging.getLogger('root')\n```\n\nБолее подробно о логировании в Python написано тут: [Hitchhiker's Guide to Python](http://docs.python-guide.org/en/latest/writing/logging/)\n","slug":"2015-11-10-python-no-sys-exit-in-signal-handlers","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo9e0017gkur1gm7aagl","content":"<p>Архитектура логирования в Python описана в <a href=\"https://www.python.org/dev/peps/pep-0282/\" target=\"_blank\" rel=\"external\">PEP 282</a>. В состав стандартной библиотеки входит модуль <code>logging</code>.<br>Пример настройки логирования для скрипта. Вывод сообщений уровня DEBUG и выше идёт в файл, вывод сообщений уровня INFO и выше - на консоль.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> logging</div><div class=\"line\"></div><div class=\"line\">logger = logging.getLogger(__name__)</div><div class=\"line\">logger.setLevel(logging.DEBUG)</div><div class=\"line\"></div><div class=\"line\">console = logging.StreamHandler()</div><div class=\"line\">console.setLevel(logging.INFO)</div><div class=\"line\">console.setFormatter(logging.Formatter(<span class=\"string\">'[%(levelname)s] %(message)s'</span>))</div><div class=\"line\">logger.addHandler(console)</div><div class=\"line\"></div><div class=\"line\">logfile = logging.FileHandler(LOGFILE)</div><div class=\"line\">logfile.setLevel(logging.DEBUG)</div><div class=\"line\">logfile.setFormatter(logging.Formatter(<span class=\"string\">'%(asctime)s [%(levelname)s] %(message)s'</span>,</div><div class=\"line\">                                       datefmt=<span class=\"string\">'[%d.%m.%Y - %H:%M:%S]'</span>))</div><div class=\"line\">logger.addHandler(logfile)</div></pre></td></tr></table></figure>\n<p>Начиная с Python 2.7 настройки <code>logging</code> можно описать в словаре. Это намного более удобный способ, хоть и менее гибкий:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> logging</div><div class=\"line\"><span class=\"keyword\">from</span> logging.config <span class=\"keyword\">import</span> dictConfig</div><div class=\"line\"></div><div class=\"line\">logging_config = dict(</div><div class=\"line\">    version=<span class=\"number\">1</span>,</div><div class=\"line\">    formatters=&#123;</div><div class=\"line\">        <span class=\"string\">'console'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'format'</span>: <span class=\"string\">'[%(levelname)s] %(message)s'</span></div><div class=\"line\">        &#125;,</div><div class=\"line\">        <span class=\"string\">'file'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'format'</span>: <span class=\"string\">'%(asctime)s [%(levelname)s] %(message)s'</span>,</div><div class=\"line\">            <span class=\"string\">'datefmt'</span>: <span class=\"string\">'[%d.%m.%Y - %H:%M:%S]'</span></div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    handlers=&#123;</div><div class=\"line\">        <span class=\"string\">'console'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'class'</span>: <span class=\"string\">'logging.StreamHandler'</span>,</div><div class=\"line\">            <span class=\"string\">'formatter'</span>: <span class=\"string\">'console'</span>,</div><div class=\"line\">            <span class=\"string\">'level'</span>: logging.INFO</div><div class=\"line\">        &#125;,</div><div class=\"line\">        <span class=\"string\">'file'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'class'</span>: <span class=\"string\">'logging.FileHandler'</span>,</div><div class=\"line\">            <span class=\"string\">'formatter'</span>: <span class=\"string\">'file'</span>,</div><div class=\"line\">            <span class=\"string\">'filename'</span>: logfile,</div><div class=\"line\">            <span class=\"string\">'level'</span>: logging.DEBUG</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    loggers=&#123;</div><div class=\"line\">        <span class=\"string\">'root'</span>: &#123;<span class=\"string\">'handlers'</span>: [<span class=\"string\">'console'</span>, <span class=\"string\">'file'</span>], <span class=\"string\">'level'</span>: logging.DEBUG&#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">)</div><div class=\"line\"></div><div class=\"line\">dictConfig(logging_config)</div><div class=\"line\">logger = logging.getLogger(<span class=\"string\">'root'</span>)</div></pre></td></tr></table></figure>\n<p>Более подробно о логировании в Python написано тут: <a href=\"http://docs.python-guide.org/en/latest/writing/logging/\" target=\"_blank\" rel=\"external\">Hitchhiker’s Guide to Python</a></p>\n","excerpt":"","more":"<p>Архитектура логирования в Python описана в <a href=\"https://www.python.org/dev/peps/pep-0282/\">PEP 282</a>. В состав стандартной библиотеки входит модуль <code>logging</code>.<br>Пример настройки логирования для скрипта. Вывод сообщений уровня DEBUG и выше идёт в файл, вывод сообщений уровня INFO и выше - на консоль.</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> logging</div><div class=\"line\"></div><div class=\"line\">logger = logging.getLogger(__name__)</div><div class=\"line\">logger.setLevel(logging.DEBUG)</div><div class=\"line\"></div><div class=\"line\">console = logging.StreamHandler()</div><div class=\"line\">console.setLevel(logging.INFO)</div><div class=\"line\">console.setFormatter(logging.Formatter(<span class=\"string\">'[%(levelname)s] %(message)s'</span>))</div><div class=\"line\">logger.addHandler(console)</div><div class=\"line\"></div><div class=\"line\">logfile = logging.FileHandler(LOGFILE)</div><div class=\"line\">logfile.setLevel(logging.DEBUG)</div><div class=\"line\">logfile.setFormatter(logging.Formatter(<span class=\"string\">'%(asctime)s [%(levelname)s] %(message)s'</span>,</div><div class=\"line\">                                       datefmt=<span class=\"string\">'[%d.%m.%Y - %H:%M:%S]'</span>))</div><div class=\"line\">logger.addHandler(logfile)</div></pre></td></tr></table></figure>\n<p>Начиная с Python 2.7 настройки <code>logging</code> можно описать в словаре. Это намного более удобный способ, хоть и менее гибкий:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> logging</div><div class=\"line\"><span class=\"keyword\">from</span> logging.config <span class=\"keyword\">import</span> dictConfig</div><div class=\"line\"></div><div class=\"line\">logging_config = dict(</div><div class=\"line\">    version=<span class=\"number\">1</span>,</div><div class=\"line\">    formatters=&#123;</div><div class=\"line\">        <span class=\"string\">'console'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'format'</span>: <span class=\"string\">'[%(levelname)s] %(message)s'</span></div><div class=\"line\">        &#125;,</div><div class=\"line\">        <span class=\"string\">'file'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'format'</span>: <span class=\"string\">'%(asctime)s [%(levelname)s] %(message)s'</span>,</div><div class=\"line\">            <span class=\"string\">'datefmt'</span>: <span class=\"string\">'[%d.%m.%Y - %H:%M:%S]'</span></div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    handlers=&#123;</div><div class=\"line\">        <span class=\"string\">'console'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'class'</span>: <span class=\"string\">'logging.StreamHandler'</span>,</div><div class=\"line\">            <span class=\"string\">'formatter'</span>: <span class=\"string\">'console'</span>,</div><div class=\"line\">            <span class=\"string\">'level'</span>: logging.INFO</div><div class=\"line\">        &#125;,</div><div class=\"line\">        <span class=\"string\">'file'</span>: &#123;</div><div class=\"line\">            <span class=\"string\">'class'</span>: <span class=\"string\">'logging.FileHandler'</span>,</div><div class=\"line\">            <span class=\"string\">'formatter'</span>: <span class=\"string\">'file'</span>,</div><div class=\"line\">            <span class=\"string\">'filename'</span>: logfile,</div><div class=\"line\">            <span class=\"string\">'level'</span>: logging.DEBUG</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;,</div><div class=\"line\">    loggers=&#123;</div><div class=\"line\">        <span class=\"string\">'root'</span>: &#123;<span class=\"string\">'handlers'</span>: [<span class=\"string\">'console'</span>, <span class=\"string\">'file'</span>], <span class=\"string\">'level'</span>: logging.DEBUG&#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">)</div><div class=\"line\"></div><div class=\"line\">dictConfig(logging_config)</div><div class=\"line\">logger = logging.getLogger(<span class=\"string\">'root'</span>)</div></pre></td></tr></table></figure>\n<p>Более подробно о логировании в Python написано тут: <a href=\"http://docs.python-guide.org/en/latest/writing/logging/\">Hitchhiker’s Guide to Python</a></p>\n"},{"layout":"post","title":"TPC-H","link":"http://www.tpc.org/tpch/","modified":"2016-01-11T21:00:00.000Z","_content":"TPC-H - превосходный набор данных и запросов к ним для проведения тестов производительности баз данных.\nЕщё один отличный набор данных из разных областей деятельности: http://www.databaseanswers.org/data_models/\n","source":"_posts/2016-01-12-tpc-h.md","raw":"---\nlayout: post\ntitle: TPC-H\nlink: http://www.tpc.org/tpch/\nmodified: 2016-01-12\ntags: [tool, performance]\n---\nTPC-H - превосходный набор данных и запросов к ним для проведения тестов производительности баз данных.\nЕщё один отличный набор данных из разных областей деятельности: http://www.databaseanswers.org/data_models/\n","slug":"2016-01-12-tpc-h","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"_id":"civzlxo9g0019gkur0adelw4m","content":"<p>TPC-H - превосходный набор данных и запросов к ним для проведения тестов производительности баз данных.<br>Ещё один отличный набор данных из разных областей деятельности: <a href=\"http://www.databaseanswers.org/data_models/\" target=\"_blank\" rel=\"external\">http://www.databaseanswers.org/data_models/</a></p>\n","excerpt":"","more":"<p>TPC-H - превосходный набор данных и запросов к ним для проведения тестов производительности баз данных.<br>Ещё один отличный набор данных из разных областей деятельности: <a href=\"http://www.databaseanswers.org/data_models/\">http://www.databaseanswers.org/data_models/</a></p>\n"},{"layout":"post","title":"Объяснение работы range access method и ICP в MySQL","link":"http://jorgenloland.blogspot.ru/2011/08/mysql-range-access-method-explained.html","modified":"2016-01-11T21:00:00.000Z","_content":"В статье объясняется, почему при использовании композитного индекса вот такой запрос будет использовать весь индекс:\n\n```sql\nSELECT * FROM orders WHERE customer_id = 2 AND value > 1000;\n```\nа такой:\n\n```sql\nSELECT * FROM orders WHERE customer_id < 2 AND value = 1000;\n```\nлишь первую его часть.\n\nВ MySQL 5.6 реализован [Index Condition Pushdown](http://jorgenloland.blogspot.co.uk/2012/03/index-condition-pushdown-to-rescue.html), который помогает в ряде случаев обойти описанное ограничение.\n","source":"_posts/2016-01-12-mysql-range-access-method-explained.md","raw":"---\nlayout: post\ntitle: Объяснение работы range access method и ICP в MySQL\nlink: http://jorgenloland.blogspot.ru/2011/08/mysql-range-access-method-explained.html\nmodified: 2016-01-12\ntags: [mysql, performance]\n---\nВ статье объясняется, почему при использовании композитного индекса вот такой запрос будет использовать весь индекс:\n\n```sql\nSELECT * FROM orders WHERE customer_id = 2 AND value > 1000;\n```\nа такой:\n\n```sql\nSELECT * FROM orders WHERE customer_id < 2 AND value = 1000;\n```\nлишь первую его часть.\n\nВ MySQL 5.6 реализован [Index Condition Pushdown](http://jorgenloland.blogspot.co.uk/2012/03/index-condition-pushdown-to-rescue.html), который помогает в ряде случаев обойти описанное ограничение.\n","slug":"2016-01-12-mysql-range-access-method-explained","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"_id":"civzlxo9l001cgkurlen2untg","content":"<p>В статье объясняется, почему при использовании композитного индекса вот такой запрос будет использовать весь индекс:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> orders <span class=\"keyword\">WHERE</span> customer_id = <span class=\"number\">2</span> <span class=\"keyword\">AND</span> <span class=\"keyword\">value</span> &gt; <span class=\"number\">1000</span>;</div></pre></td></tr></table></figure>\n<p>а такой:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> orders <span class=\"keyword\">WHERE</span> customer_id &lt; <span class=\"number\">2</span> <span class=\"keyword\">AND</span> <span class=\"keyword\">value</span> = <span class=\"number\">1000</span>;</div></pre></td></tr></table></figure>\n<p>лишь первую его часть.</p>\n<p>В MySQL 5.6 реализован <a href=\"http://jorgenloland.blogspot.co.uk/2012/03/index-condition-pushdown-to-rescue.html\" target=\"_blank\" rel=\"external\">Index Condition Pushdown</a>, который помогает в ряде случаев обойти описанное ограничение.</p>\n","excerpt":"","more":"<p>В статье объясняется, почему при использовании композитного индекса вот такой запрос будет использовать весь индекс:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> orders <span class=\"keyword\">WHERE</span> customer_id = <span class=\"number\">2</span> <span class=\"keyword\">AND</span> <span class=\"keyword\">value</span> &gt; <span class=\"number\">1000</span>;</div></pre></td></tr></table></figure>\n<p>а такой:</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">SELECT</span> * <span class=\"keyword\">FROM</span> orders <span class=\"keyword\">WHERE</span> customer_id &lt; <span class=\"number\">2</span> <span class=\"keyword\">AND</span> <span class=\"keyword\">value</span> = <span class=\"number\">1000</span>;</div></pre></td></tr></table></figure>\n<p>лишь первую его часть.</p>\n<p>В MySQL 5.6 реализован <a href=\"http://jorgenloland.blogspot.co.uk/2012/03/index-condition-pushdown-to-rescue.html\">Index Condition Pushdown</a>, который помогает в ряде случаев обойти описанное ограничение.</p>\n"},{"layout":"post","title":"Политики кэширования в RAID-контроллерах Avago (LSI)","modified":"2016-01-14T21:00:00.000Z","_content":"Разъяснение настроек кэширования данных в контроллерах LSI (оригинал по [ссылке](http://lists.us.dell.com/pipermail/linux-poweredge/2006-May/025738.html)):\n\nWhen dealing with LSI controllers there are actually 3 caches to deal with. From the OMSA documentation (I have deleted all references to non-LSI ptions)\n\n#### Read Policy:\n\nThe read policies indicate whether or not the controller should read sequential sectors of the logical drive when seeking data.\n\n* **Read-Ahead**. When using read-ahead policy, the controller reads sequential sectors of the logical drive when seeking data. Read-ahead policy may improve system performance if the data is actually written to sequential sectors of the logical drive.\n* **No-Read-Ahead**. Selecting no-read-ahead policy indicates that the controller should not use read-ahead policy.\n* **Adaptive Read-Ahead**. When using adaptive read-ahead policy, the controller initiates read-ahead only if the two most recent read requests ccessed sequential sectors of the disk. If subsequent read requests access random sectors of the disk, the controller reverts to no-read-ahead olicy. The controller continues to evaluate whether read requests are accessing sequential sectors of the disk, and can initiate read-ahead if ecessary.\n\n\n#### Write Policy:\n\nThe write policies specify whether the controller sends a write-request completion signal as soon as the data is in the cache or after it has been ritten to disk.\n\n* **Write-Back**. When using write-back caching, the controller sends a write-request completion signal as soon as the data is in the controller ache but has not yet been written to disk. Write-back caching may provide improved performance since subsequent read requests can more quickly retrieve data from the controller cache than they could from the disk. Write-back caching also entails a data security risk, however, since a system failure could prevent the data from being written to disk even though the controller has sent a write-request completion signal. In this case, data may be lost. Other applications may also experience problems when taking actions that assume the data is available on the disk.\n* **Write-Through**. When using write-through caching, the controller sends a write-request completion signal only after the data is written to he disk. Write-through caching provides better data security than write-back caching, since the system assumes the data is available only after it as been safely written to the disk.\n\n\n#### Cache Policy:\n\nThe Direct I/O and Cache I/O cache policies apply to reads on a specific virtual disk. These settings do not affect the read-ahead policy. The cache policies are as follows:\n\n* **Cache I/O**. Specifies that all reads are buffered in cache memory.\n* **Direct I/O**. Specifies that reads are not buffered in cache memory. When using direct I/O, data is transferred to the controller cache and he host system simultaneously during a read request. If a subsequent read request requires data from the same data block, it can be read directly from the controller cache. The direct I/O setting does not override the cache policy settings. Direct I/O is also the default setting.\n","source":"_posts/2016-01-15-lsi-raid-controller-cache-policies.md","raw":"---\nlayout: post\ntitle: Политики кэширования в RAID-контроллерах Avago (LSI)\nmodified: 2016-01-15\ntags: [storage]\n---\nРазъяснение настроек кэширования данных в контроллерах LSI (оригинал по [ссылке](http://lists.us.dell.com/pipermail/linux-poweredge/2006-May/025738.html)):\n\nWhen dealing with LSI controllers there are actually 3 caches to deal with. From the OMSA documentation (I have deleted all references to non-LSI ptions)\n\n#### Read Policy:\n\nThe read policies indicate whether or not the controller should read sequential sectors of the logical drive when seeking data.\n\n* **Read-Ahead**. When using read-ahead policy, the controller reads sequential sectors of the logical drive when seeking data. Read-ahead policy may improve system performance if the data is actually written to sequential sectors of the logical drive.\n* **No-Read-Ahead**. Selecting no-read-ahead policy indicates that the controller should not use read-ahead policy.\n* **Adaptive Read-Ahead**. When using adaptive read-ahead policy, the controller initiates read-ahead only if the two most recent read requests ccessed sequential sectors of the disk. If subsequent read requests access random sectors of the disk, the controller reverts to no-read-ahead olicy. The controller continues to evaluate whether read requests are accessing sequential sectors of the disk, and can initiate read-ahead if ecessary.\n\n\n#### Write Policy:\n\nThe write policies specify whether the controller sends a write-request completion signal as soon as the data is in the cache or after it has been ritten to disk.\n\n* **Write-Back**. When using write-back caching, the controller sends a write-request completion signal as soon as the data is in the controller ache but has not yet been written to disk. Write-back caching may provide improved performance since subsequent read requests can more quickly retrieve data from the controller cache than they could from the disk. Write-back caching also entails a data security risk, however, since a system failure could prevent the data from being written to disk even though the controller has sent a write-request completion signal. In this case, data may be lost. Other applications may also experience problems when taking actions that assume the data is available on the disk.\n* **Write-Through**. When using write-through caching, the controller sends a write-request completion signal only after the data is written to he disk. Write-through caching provides better data security than write-back caching, since the system assumes the data is available only after it as been safely written to the disk.\n\n\n#### Cache Policy:\n\nThe Direct I/O and Cache I/O cache policies apply to reads on a specific virtual disk. These settings do not affect the read-ahead policy. The cache policies are as follows:\n\n* **Cache I/O**. Specifies that all reads are buffered in cache memory.\n* **Direct I/O**. Specifies that reads are not buffered in cache memory. When using direct I/O, data is transferred to the controller cache and he host system simultaneously during a read request. If a subsequent read request requires data from the same data block, it can be read directly from the controller cache. The direct I/O setting does not override the cache policy settings. Direct I/O is also the default setting.\n","slug":"2016-01-15-lsi-raid-controller-cache-policies","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"link":"","_id":"civzlxo9m001dgkurkfhjmfdn","content":"<p>Разъяснение настроек кэширования данных в контроллерах LSI (оригинал по <a href=\"http://lists.us.dell.com/pipermail/linux-poweredge/2006-May/025738.html\" target=\"_blank\" rel=\"external\">ссылке</a>):</p>\n<p>When dealing with LSI controllers there are actually 3 caches to deal with. From the OMSA documentation (I have deleted all references to non-LSI ptions)</p>\n<h4 id=\"Read-Policy\"><a href=\"#Read-Policy\" class=\"headerlink\" title=\"Read Policy:\"></a>Read Policy:</h4><p>The read policies indicate whether or not the controller should read sequential sectors of the logical drive when seeking data.</p>\n<ul>\n<li><strong>Read-Ahead</strong>. When using read-ahead policy, the controller reads sequential sectors of the logical drive when seeking data. Read-ahead policy may improve system performance if the data is actually written to sequential sectors of the logical drive.</li>\n<li><strong>No-Read-Ahead</strong>. Selecting no-read-ahead policy indicates that the controller should not use read-ahead policy.</li>\n<li><strong>Adaptive Read-Ahead</strong>. When using adaptive read-ahead policy, the controller initiates read-ahead only if the two most recent read requests ccessed sequential sectors of the disk. If subsequent read requests access random sectors of the disk, the controller reverts to no-read-ahead olicy. The controller continues to evaluate whether read requests are accessing sequential sectors of the disk, and can initiate read-ahead if ecessary.</li>\n</ul>\n<h4 id=\"Write-Policy\"><a href=\"#Write-Policy\" class=\"headerlink\" title=\"Write Policy:\"></a>Write Policy:</h4><p>The write policies specify whether the controller sends a write-request completion signal as soon as the data is in the cache or after it has been ritten to disk.</p>\n<ul>\n<li><strong>Write-Back</strong>. When using write-back caching, the controller sends a write-request completion signal as soon as the data is in the controller ache but has not yet been written to disk. Write-back caching may provide improved performance since subsequent read requests can more quickly retrieve data from the controller cache than they could from the disk. Write-back caching also entails a data security risk, however, since a system failure could prevent the data from being written to disk even though the controller has sent a write-request completion signal. In this case, data may be lost. Other applications may also experience problems when taking actions that assume the data is available on the disk.</li>\n<li><strong>Write-Through</strong>. When using write-through caching, the controller sends a write-request completion signal only after the data is written to he disk. Write-through caching provides better data security than write-back caching, since the system assumes the data is available only after it as been safely written to the disk.</li>\n</ul>\n<h4 id=\"Cache-Policy\"><a href=\"#Cache-Policy\" class=\"headerlink\" title=\"Cache Policy:\"></a>Cache Policy:</h4><p>The Direct I/O and Cache I/O cache policies apply to reads on a specific virtual disk. These settings do not affect the read-ahead policy. The cache policies are as follows:</p>\n<ul>\n<li><strong>Cache I/O</strong>. Specifies that all reads are buffered in cache memory.</li>\n<li><strong>Direct I/O</strong>. Specifies that reads are not buffered in cache memory. When using direct I/O, data is transferred to the controller cache and he host system simultaneously during a read request. If a subsequent read request requires data from the same data block, it can be read directly from the controller cache. The direct I/O setting does not override the cache policy settings. Direct I/O is also the default setting.</li>\n</ul>\n","excerpt":"","more":"<p>Разъяснение настроек кэширования данных в контроллерах LSI (оригинал по <a href=\"http://lists.us.dell.com/pipermail/linux-poweredge/2006-May/025738.html\">ссылке</a>):</p>\n<p>When dealing with LSI controllers there are actually 3 caches to deal with. From the OMSA documentation (I have deleted all references to non-LSI ptions)</p>\n<h4 id=\"Read-Policy\"><a href=\"#Read-Policy\" class=\"headerlink\" title=\"Read Policy:\"></a>Read Policy:</h4><p>The read policies indicate whether or not the controller should read sequential sectors of the logical drive when seeking data.</p>\n<ul>\n<li><strong>Read-Ahead</strong>. When using read-ahead policy, the controller reads sequential sectors of the logical drive when seeking data. Read-ahead policy may improve system performance if the data is actually written to sequential sectors of the logical drive.</li>\n<li><strong>No-Read-Ahead</strong>. Selecting no-read-ahead policy indicates that the controller should not use read-ahead policy.</li>\n<li><strong>Adaptive Read-Ahead</strong>. When using adaptive read-ahead policy, the controller initiates read-ahead only if the two most recent read requests ccessed sequential sectors of the disk. If subsequent read requests access random sectors of the disk, the controller reverts to no-read-ahead olicy. The controller continues to evaluate whether read requests are accessing sequential sectors of the disk, and can initiate read-ahead if ecessary.</li>\n</ul>\n<h4 id=\"Write-Policy\"><a href=\"#Write-Policy\" class=\"headerlink\" title=\"Write Policy:\"></a>Write Policy:</h4><p>The write policies specify whether the controller sends a write-request completion signal as soon as the data is in the cache or after it has been ritten to disk.</p>\n<ul>\n<li><strong>Write-Back</strong>. When using write-back caching, the controller sends a write-request completion signal as soon as the data is in the controller ache but has not yet been written to disk. Write-back caching may provide improved performance since subsequent read requests can more quickly retrieve data from the controller cache than they could from the disk. Write-back caching also entails a data security risk, however, since a system failure could prevent the data from being written to disk even though the controller has sent a write-request completion signal. In this case, data may be lost. Other applications may also experience problems when taking actions that assume the data is available on the disk.</li>\n<li><strong>Write-Through</strong>. When using write-through caching, the controller sends a write-request completion signal only after the data is written to he disk. Write-through caching provides better data security than write-back caching, since the system assumes the data is available only after it as been safely written to the disk.</li>\n</ul>\n<h4 id=\"Cache-Policy\"><a href=\"#Cache-Policy\" class=\"headerlink\" title=\"Cache Policy:\"></a>Cache Policy:</h4><p>The Direct I/O and Cache I/O cache policies apply to reads on a specific virtual disk. These settings do not affect the read-ahead policy. The cache policies are as follows:</p>\n<ul>\n<li><strong>Cache I/O</strong>. Specifies that all reads are buffered in cache memory.</li>\n<li><strong>Direct I/O</strong>. Specifies that reads are not buffered in cache memory. When using direct I/O, data is transferred to the controller cache and he host system simultaneously during a read request. If a subsequent read request requires data from the same data block, it can be read directly from the controller cache. The direct I/O setting does not override the cache policy settings. Direct I/O is also the default setting.</li>\n</ul>\n"},{"layout":"post","title":"Всё о сокетах в состоянии TIME_WAIT","link":"http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html","modified":"2016-01-20T21:00:00.000Z","_content":"Превосходная статья о сокетах, находящихся в состоянии `TIME_WAIT`.\n","source":"_posts/2016-01-21-time_wait-sockets.md","raw":"---\nlayout: post\ntitle: Всё о сокетах в состоянии TIME_WAIT\nlink: http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html\nmodified: 2016-01-21\ntags: [network]\n---\nПревосходная статья о сокетах, находящихся в состоянии `TIME_WAIT`.\n","slug":"2016-01-21-time_wait-sockets","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"photos":[],"_id":"civzlxo9o001egkurskpimuek","content":"<p>Превосходная статья о сокетах, находящихся в состоянии <code>TIME_WAIT</code>.</p>\n","excerpt":"","more":"<p>Превосходная статья о сокетах, находящихся в состоянии <code>TIME_WAIT</code>.</p>\n"},{"title":"Смена устройства, хранящего внешний журнал ext4","_content":"Недавно столкнулся со следующей ситуацией.\n\nЕсть файловая система ext4 на 22 Тб. Настроили для неё размещение журнала на отдельной SSD, указали опцию монтирования `journal_async_commit`.\nСпустя сутки ФС внезапно стала read-only. Оказалось, диск, на котором размещался журнал, был извлечён из системы с помощью `MegaCli`.\nОтмонтировать ФС не удавалось, umount \"висел\". Были вынуждены перезагрузить сервер через reset.\n\nПосле загрузки сменились major и minor номера всех блочных устройств, они стали такими:\n\n```\n# cat /proc/partitions\nmajor minor  #blocks  name\n\n   8       16  233897984 sdb\n   8       17  233896960 sdb1\n   8       32  175276032 sdc\n   8        0 23437770752 sda\n   8        1 23437768704 sda1\n   8       48   97685784 sdd\n   8       49   97684480 sdd1\n#\n```\n\nФС не монтировалась, несмотря на то, что при подключении внешнего журнала был указан UUID. Примонтировали ФС только со сменой устройства журнала:\n\n```\nmount -t ext4 -o journal_dev=$(stat -c \"0x%t%T\" /dev/sdc) /dev/sda1 /var/spool/maildir\n```\n\nТрудность была в том, что в мануале `mount` не указано, в каком формате необходимо передавать аргумент опции `journal_dev`. Информацию я нашёл лишь где-то в списках рассылки.\n\nСтоит отметить, что в современных версиях `mount` есть опция `journal_path`, которая позволяет указать просто путь к устройству. Но в Ubuntu 12.04 этой опции в `mount` нет.\n\nПосле успешного монтирования мы опять выполнили `umount`, чтобы \"прогнать\" `e2fsck`. После ФС успешно примонтировалась просто по `mount -a`.\n","source":"_posts/2016-02-10-change-ext-journal-device-ext4.md","raw":"---\ntitle: Смена устройства, хранящего внешний журнал ext4\ntags: [storage]\n---\nНедавно столкнулся со следующей ситуацией.\n\nЕсть файловая система ext4 на 22 Тб. Настроили для неё размещение журнала на отдельной SSD, указали опцию монтирования `journal_async_commit`.\nСпустя сутки ФС внезапно стала read-only. Оказалось, диск, на котором размещался журнал, был извлечён из системы с помощью `MegaCli`.\nОтмонтировать ФС не удавалось, umount \"висел\". Были вынуждены перезагрузить сервер через reset.\n\nПосле загрузки сменились major и minor номера всех блочных устройств, они стали такими:\n\n```\n# cat /proc/partitions\nmajor minor  #blocks  name\n\n   8       16  233897984 sdb\n   8       17  233896960 sdb1\n   8       32  175276032 sdc\n   8        0 23437770752 sda\n   8        1 23437768704 sda1\n   8       48   97685784 sdd\n   8       49   97684480 sdd1\n#\n```\n\nФС не монтировалась, несмотря на то, что при подключении внешнего журнала был указан UUID. Примонтировали ФС только со сменой устройства журнала:\n\n```\nmount -t ext4 -o journal_dev=$(stat -c \"0x%t%T\" /dev/sdc) /dev/sda1 /var/spool/maildir\n```\n\nТрудность была в том, что в мануале `mount` не указано, в каком формате необходимо передавать аргумент опции `journal_dev`. Информацию я нашёл лишь где-то в списках рассылки.\n\nСтоит отметить, что в современных версиях `mount` есть опция `journal_path`, которая позволяет указать просто путь к устройству. Но в Ubuntu 12.04 этой опции в `mount` нет.\n\nПосле успешного монтирования мы опять выполнили `umount`, чтобы \"прогнать\" `e2fsck`. После ФС успешно примонтировалась просто по `mount -a`.\n","slug":"2016-02-10-change-ext-journal-device-ext4","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo9q001hgkur68af91xl","content":"<p>Недавно столкнулся со следующей ситуацией.</p>\n<p>Есть файловая система ext4 на 22 Тб. Настроили для неё размещение журнала на отдельной SSD, указали опцию монтирования <code>journal_async_commit</code>.<br>Спустя сутки ФС внезапно стала read-only. Оказалось, диск, на котором размещался журнал, был извлечён из системы с помощью <code>MegaCli</code>.<br>Отмонтировать ФС не удавалось, umount “висел”. Были вынуждены перезагрузить сервер через reset.</p>\n<p>После загрузки сменились major и minor номера всех блочных устройств, они стали такими:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"># cat /proc/partitions</div><div class=\"line\">major minor  #blocks  name</div><div class=\"line\"></div><div class=\"line\">   8       16  233897984 sdb</div><div class=\"line\">   8       17  233896960 sdb1</div><div class=\"line\">   8       32  175276032 sdc</div><div class=\"line\">   8        0 23437770752 sda</div><div class=\"line\">   8        1 23437768704 sda1</div><div class=\"line\">   8       48   97685784 sdd</div><div class=\"line\">   8       49   97684480 sdd1</div><div class=\"line\">#</div></pre></td></tr></table></figure>\n<p>ФС не монтировалась, несмотря на то, что при подключении внешнего журнала был указан UUID. Примонтировали ФС только со сменой устройства журнала:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mount -t ext4 -o journal_dev=$(stat -c &quot;0x%t%T&quot; /dev/sdc) /dev/sda1 /var/spool/maildir</div></pre></td></tr></table></figure>\n<p>Трудность была в том, что в мануале <code>mount</code> не указано, в каком формате необходимо передавать аргумент опции <code>journal_dev</code>. Информацию я нашёл лишь где-то в списках рассылки.</p>\n<p>Стоит отметить, что в современных версиях <code>mount</code> есть опция <code>journal_path</code>, которая позволяет указать просто путь к устройству. Но в Ubuntu 12.04 этой опции в <code>mount</code> нет.</p>\n<p>После успешного монтирования мы опять выполнили <code>umount</code>, чтобы “прогнать” <code>e2fsck</code>. После ФС успешно примонтировалась просто по <code>mount -a</code>.</p>\n","excerpt":"","more":"<p>Недавно столкнулся со следующей ситуацией.</p>\n<p>Есть файловая система ext4 на 22 Тб. Настроили для неё размещение журнала на отдельной SSD, указали опцию монтирования <code>journal_async_commit</code>.<br>Спустя сутки ФС внезапно стала read-only. Оказалось, диск, на котором размещался журнал, был извлечён из системы с помощью <code>MegaCli</code>.<br>Отмонтировать ФС не удавалось, umount “висел”. Были вынуждены перезагрузить сервер через reset.</p>\n<p>После загрузки сменились major и minor номера всех блочных устройств, они стали такими:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"># cat /proc/partitions</div><div class=\"line\">major minor  #blocks  name</div><div class=\"line\"></div><div class=\"line\">   8       16  233897984 sdb</div><div class=\"line\">   8       17  233896960 sdb1</div><div class=\"line\">   8       32  175276032 sdc</div><div class=\"line\">   8        0 23437770752 sda</div><div class=\"line\">   8        1 23437768704 sda1</div><div class=\"line\">   8       48   97685784 sdd</div><div class=\"line\">   8       49   97684480 sdd1</div><div class=\"line\">#</div></pre></td></tr></table></figure>\n<p>ФС не монтировалась, несмотря на то, что при подключении внешнего журнала был указан UUID. Примонтировали ФС только со сменой устройства журнала:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">mount -t ext4 -o journal_dev=$(stat -c &quot;0x%t%T&quot; /dev/sdc) /dev/sda1 /var/spool/maildir</div></pre></td></tr></table></figure>\n<p>Трудность была в том, что в мануале <code>mount</code> не указано, в каком формате необходимо передавать аргумент опции <code>journal_dev</code>. Информацию я нашёл лишь где-то в списках рассылки.</p>\n<p>Стоит отметить, что в современных версиях <code>mount</code> есть опция <code>journal_path</code>, которая позволяет указать просто путь к устройству. Но в Ubuntu 12.04 этой опции в <code>mount</code> нет.</p>\n<p>После успешного монтирования мы опять выполнили <code>umount</code>, чтобы “прогнать” <code>e2fsck</code>. После ФС успешно примонтировалась просто по <code>mount -a</code>.</p>\n"},{"link":"https://habrahabr.ru/post/154235/","title":"Как правильно мерять производительность диска","_content":"Методология измерения параметров хранилищ. Must read.\n","source":"_posts/2016-06-30-fio.md","raw":"---\nlink: https://habrahabr.ru/post/154235/\ntitle: Как правильно мерять производительность диска\ntags: [storage, performance]\n---\nМетодология измерения параметров хранилищ. Must read.\n","slug":"2016-06-30-fio","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"_id":"civzlxo9r001jgkur19ah1r72","content":"<p>Методология измерения параметров хранилищ. Must read.</p>\n","excerpt":"","more":"<p>Методология измерения параметров хранилищ. Must read.</p>\n"},{"title":"Настройка рабочего окружения","_content":"Вот как я настраиваю рабочее окружение.\n\n## Клавиша \"#\"\nМне не нужен символ номера (shift+3 на русской раскладке). Но я часто пользуюсь символом #. Это нумерованный список в Redmine плюс ссылки на задачи начинаются также с #. В Ubuntu 16.04 исправить недоразумение и сделать так, чтобы в русской раскладке также печатался символ #, можно, отредактировав файл `/usr/share/X11/xkb/symbols/ru`. Достаточно закомментировать строку 13 (это секция, где переопределяются значения сочетаний shift+цифра). Вот эту строку, если быть точным:\n\n```\n// Keyboard layouts for Russia.\n// AEN <aen@logic.ru>\n// 2001/12/23 by Leon Kanter <leon@blackcatlinux.com>\n// 2005/12/09 Valery Inozemtsev <shrek@altlinux.ru>\n\n// Windows layout\ndefault  partial alphanumeric_keys\nxkb_symbols \"winkeys\" {\n\n    include \"ru(common)\"\n    name[Group1]= \"Russian\";\n\n//    key <AE03> { [           3,  numerosign  ] };\n    key <AE04> { [           4,   semicolon  ] };\n    key <AE05> { [           5,     percent  ] };\n```\n\n## Редактор\nЛучший редактор для меня - Atom. Список модулей, которые я использую:\n\n* autocomplete-python\n* build\n* busy\n* file-icons\n* git-plus\n* hyperclick _(В сочетании с autocomplete-python даёт возможность Ctrl-кликнуть на символ в коде, чтобы перейти к его определению)_\n* language-puppet\n* linter\n* linter-flake8\n* linter-puppet-lint\n* linter-rubocop\n* minimap\n\n## Build\nУдобно писать код в Atom и тестировать его запуском на удалённом сервере через SSH. Для этого я написал build-сценарий для соответствующего модуля:\n\n```\n{\n  \"name\": \"Runscript\",\n  \"cmd\": \"echo 'Choose target'\",\n  \"sh\": true,\n  \"targets\": {\n    \"host_accessed_with_fabric\": { \"cmd\": \"fab -f /home/gena/rexec.py -H srvname runscript:\\\"{FILE_ACTIVE}\\\"\" },\n    \"host_accessed_with_plain_ssh\": { \"cmd\": \"scp {FILE_ACTIVE} srvname:~/atom-build.script; ssh srvname ~g.aleksandrov/atom-build.script; ssh srvname rm ~g.aleksandrov/atom-build.script\" },\n    \"local_python\": { \"cmd\": \"python {FILE_ACTIVE}\" }\n  }\n}\n```\n\n## .ssh/config\nМы используем SSH-шлюз, доступ на сервера осуществляется через него. Для тестирования скриптов это не очень удобно, иногда нужен прямой доступ. Его можно получить, настроив SSH-клиент, вот конфиг:\n\n```\nHost gateway\n    Hostname gateway.example.com\n    User g.aleksandrov\n    IdentityFile ~/.ssh/g.aleksandrov-tw_key\n\nHost directaccess\n    Hostname directaccess.example.com\n    User root\n    IdentityFile ~/.ssh/g.aleksandrov-tw_key\n\nHost gitlab.example.com\n    User git\n    IdentityFile ~/.ssh/g.aleksandrov-tw_key\n\nHost github.com\n    User git\n    IdentityFile ~/Dropbox/keys/github_main_key\n\nHost !gateway* !directaccess* !gitlab.example.com !github.com !*.* *\n    User root\n    ProxyCommand ssh gateway -W %h:22\n    IdentityFile ~/.ssh/id_rsa.admins\n    StrictHostKeyChecking no\n```\nПри таком конфиге доступ на любой сервер будет осуществляться через gateway. За исключением, кхм, исключений.\n\n## Fabric\nДля выполнения команд/скриптов на удалённых серверах я написал fabfile. Вот его шаблон:\n\n```python\n#!/usr/bin/python\n\nfrom fabric.api import run, task, env, put, settings, hosts\nfrom fabric.state import output\n\n\nenv.use_ssh_config = True\nenv.colorize_errors = True\nenv.warn_only = True\nenv.skip_bad_hosts = True\noutput['running'] = False\n\n\ndef get_srv_list(**kwargs):\n    where = ''\n    for arg in kwargs:\n        if isinstance(kwargs[arg], int) or isinstance(kwargs[arg], float):\n            where += '{} = {} AND '.format(arg, kwargs[arg])\n        elif isinstance(kwargs[arg], str):\n            where += '{} = \"{}\" AND '.format(arg, kwargs[arg])\n    where = where[:-5]\n    if not where:\n        raise(ValueError('Query params not set!'))\n    # srv_list = DBClient.select_rows(where)\n    return srv_list\n\n\nenv.roledefs = {\n    role1: ['srv1', 'srv2', 'srv3'],\n}\n\n\n@task\ndef runcmd(cmd):\n    run(cmd)\n\n\n@task\ndef runscript(script_path):\n    with settings(warn_only=False):\n        res = put(script_path, remote_path='/root')\n    for script in res:\n        run('chmod u+x {}'.format(script))\n        run(script)\n        run('rm {}'.format(script))\n\n\n@task\ndef putfile(file_path, remote_path):\n    put(file_path, remote_path=remote_path)\n\n\n@task\n@hosts('localhost')\ndef srvlist():\n    output['status'] = False\n    for role in env.roles:\n        for srv in env.roledefs[role]:\n            print(srv)\n```\nПользуюсь им при помощи алиаса командной строки. Добавил в `~/.bashrc`:\n\n```\nalias rex='fab -f /home/g.aleksandrov/rexec.py'\n```\n\n## Mission Control в Unity\nВ macOS часто пользуюсь Mission Control ради просмотра всех открытых окон. Такую штуку можно сделать и в Unity.\nДля вывода всех окон по наведению курсора в угол экрана в `ccsm` надо выставить настройку \"Scaling\" > \"initiate_all_edge\" (как-то так).\n","source":"_posts/2016-07-01-work-env.md","raw":"---\ntitle: Настройка рабочего окружения\ntags: [environment]\n---\nВот как я настраиваю рабочее окружение.\n\n## Клавиша \"#\"\nМне не нужен символ номера (shift+3 на русской раскладке). Но я часто пользуюсь символом #. Это нумерованный список в Redmine плюс ссылки на задачи начинаются также с #. В Ubuntu 16.04 исправить недоразумение и сделать так, чтобы в русской раскладке также печатался символ #, можно, отредактировав файл `/usr/share/X11/xkb/symbols/ru`. Достаточно закомментировать строку 13 (это секция, где переопределяются значения сочетаний shift+цифра). Вот эту строку, если быть точным:\n\n```\n// Keyboard layouts for Russia.\n// AEN <aen@logic.ru>\n// 2001/12/23 by Leon Kanter <leon@blackcatlinux.com>\n// 2005/12/09 Valery Inozemtsev <shrek@altlinux.ru>\n\n// Windows layout\ndefault  partial alphanumeric_keys\nxkb_symbols \"winkeys\" {\n\n    include \"ru(common)\"\n    name[Group1]= \"Russian\";\n\n//    key <AE03> { [           3,  numerosign  ] };\n    key <AE04> { [           4,   semicolon  ] };\n    key <AE05> { [           5,     percent  ] };\n```\n\n## Редактор\nЛучший редактор для меня - Atom. Список модулей, которые я использую:\n\n* autocomplete-python\n* build\n* busy\n* file-icons\n* git-plus\n* hyperclick _(В сочетании с autocomplete-python даёт возможность Ctrl-кликнуть на символ в коде, чтобы перейти к его определению)_\n* language-puppet\n* linter\n* linter-flake8\n* linter-puppet-lint\n* linter-rubocop\n* minimap\n\n## Build\nУдобно писать код в Atom и тестировать его запуском на удалённом сервере через SSH. Для этого я написал build-сценарий для соответствующего модуля:\n\n```\n{\n  \"name\": \"Runscript\",\n  \"cmd\": \"echo 'Choose target'\",\n  \"sh\": true,\n  \"targets\": {\n    \"host_accessed_with_fabric\": { \"cmd\": \"fab -f /home/gena/rexec.py -H srvname runscript:\\\"{FILE_ACTIVE}\\\"\" },\n    \"host_accessed_with_plain_ssh\": { \"cmd\": \"scp {FILE_ACTIVE} srvname:~/atom-build.script; ssh srvname ~g.aleksandrov/atom-build.script; ssh srvname rm ~g.aleksandrov/atom-build.script\" },\n    \"local_python\": { \"cmd\": \"python {FILE_ACTIVE}\" }\n  }\n}\n```\n\n## .ssh/config\nМы используем SSH-шлюз, доступ на сервера осуществляется через него. Для тестирования скриптов это не очень удобно, иногда нужен прямой доступ. Его можно получить, настроив SSH-клиент, вот конфиг:\n\n```\nHost gateway\n    Hostname gateway.example.com\n    User g.aleksandrov\n    IdentityFile ~/.ssh/g.aleksandrov-tw_key\n\nHost directaccess\n    Hostname directaccess.example.com\n    User root\n    IdentityFile ~/.ssh/g.aleksandrov-tw_key\n\nHost gitlab.example.com\n    User git\n    IdentityFile ~/.ssh/g.aleksandrov-tw_key\n\nHost github.com\n    User git\n    IdentityFile ~/Dropbox/keys/github_main_key\n\nHost !gateway* !directaccess* !gitlab.example.com !github.com !*.* *\n    User root\n    ProxyCommand ssh gateway -W %h:22\n    IdentityFile ~/.ssh/id_rsa.admins\n    StrictHostKeyChecking no\n```\nПри таком конфиге доступ на любой сервер будет осуществляться через gateway. За исключением, кхм, исключений.\n\n## Fabric\nДля выполнения команд/скриптов на удалённых серверах я написал fabfile. Вот его шаблон:\n\n```python\n#!/usr/bin/python\n\nfrom fabric.api import run, task, env, put, settings, hosts\nfrom fabric.state import output\n\n\nenv.use_ssh_config = True\nenv.colorize_errors = True\nenv.warn_only = True\nenv.skip_bad_hosts = True\noutput['running'] = False\n\n\ndef get_srv_list(**kwargs):\n    where = ''\n    for arg in kwargs:\n        if isinstance(kwargs[arg], int) or isinstance(kwargs[arg], float):\n            where += '{} = {} AND '.format(arg, kwargs[arg])\n        elif isinstance(kwargs[arg], str):\n            where += '{} = \"{}\" AND '.format(arg, kwargs[arg])\n    where = where[:-5]\n    if not where:\n        raise(ValueError('Query params not set!'))\n    # srv_list = DBClient.select_rows(where)\n    return srv_list\n\n\nenv.roledefs = {\n    role1: ['srv1', 'srv2', 'srv3'],\n}\n\n\n@task\ndef runcmd(cmd):\n    run(cmd)\n\n\n@task\ndef runscript(script_path):\n    with settings(warn_only=False):\n        res = put(script_path, remote_path='/root')\n    for script in res:\n        run('chmod u+x {}'.format(script))\n        run(script)\n        run('rm {}'.format(script))\n\n\n@task\ndef putfile(file_path, remote_path):\n    put(file_path, remote_path=remote_path)\n\n\n@task\n@hosts('localhost')\ndef srvlist():\n    output['status'] = False\n    for role in env.roles:\n        for srv in env.roledefs[role]:\n            print(srv)\n```\nПользуюсь им при помощи алиаса командной строки. Добавил в `~/.bashrc`:\n\n```\nalias rex='fab -f /home/g.aleksandrov/rexec.py'\n```\n\n## Mission Control в Unity\nВ macOS часто пользуюсь Mission Control ради просмотра всех открытых окон. Такую штуку можно сделать и в Unity.\nДля вывода всех окон по наведению курсора в угол экрана в `ccsm` надо выставить настройку \"Scaling\" > \"initiate_all_edge\" (как-то так).\n","slug":"2016-07-01-work-env","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo9t001mgkurfgkldcf9","content":"<p>Вот как я настраиваю рабочее окружение.</p>\n<h2 id=\"Клавиша-“-”\"><a href=\"#Клавиша-“-”\" class=\"headerlink\" title=\"Клавиша “#”\"></a>Клавиша “#”</h2><p>Мне не нужен символ номера (shift+3 на русской раскладке). Но я часто пользуюсь символом #. Это нумерованный список в Redmine плюс ссылки на задачи начинаются также с #. В Ubuntu 16.04 исправить недоразумение и сделать так, чтобы в русской раскладке также печатался символ #, можно, отредактировав файл <code>/usr/share/X11/xkb/symbols/ru</code>. Достаточно закомментировать строку 13 (это секция, где переопределяются значения сочетаний shift+цифра). Вот эту строку, если быть точным:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Keyboard layouts for Russia.</div><div class=\"line\">// AEN &lt;aen@logic.ru&gt;</div><div class=\"line\">// 2001/12/23 by Leon Kanter &lt;leon@blackcatlinux.com&gt;</div><div class=\"line\">// 2005/12/09 Valery Inozemtsev &lt;shrek@altlinux.ru&gt;</div><div class=\"line\"></div><div class=\"line\">// Windows layout</div><div class=\"line\">default  partial alphanumeric_keys</div><div class=\"line\">xkb_symbols &quot;winkeys&quot; &#123;</div><div class=\"line\"></div><div class=\"line\">    include &quot;ru(common)&quot;</div><div class=\"line\">    name[Group1]= &quot;Russian&quot;;</div><div class=\"line\"></div><div class=\"line\">//    key &lt;AE03&gt; &#123; [           3,  numerosign  ] &#125;;</div><div class=\"line\">    key &lt;AE04&gt; &#123; [           4,   semicolon  ] &#125;;</div><div class=\"line\">    key &lt;AE05&gt; &#123; [           5,     percent  ] &#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"Редактор\"><a href=\"#Редактор\" class=\"headerlink\" title=\"Редактор\"></a>Редактор</h2><p>Лучший редактор для меня - Atom. Список модулей, которые я использую:</p>\n<ul>\n<li>autocomplete-python</li>\n<li>build</li>\n<li>busy</li>\n<li>file-icons</li>\n<li>git-plus</li>\n<li>hyperclick <em>(В сочетании с autocomplete-python даёт возможность Ctrl-кликнуть на символ в коде, чтобы перейти к его определению)</em></li>\n<li>language-puppet</li>\n<li>linter</li>\n<li>linter-flake8</li>\n<li>linter-puppet-lint</li>\n<li>linter-rubocop</li>\n<li>minimap</li>\n</ul>\n<h2 id=\"Build\"><a href=\"#Build\" class=\"headerlink\" title=\"Build\"></a>Build</h2><p>Удобно писать код в Atom и тестировать его запуском на удалённом сервере через SSH. Для этого я написал build-сценарий для соответствующего модуля:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;name&quot;: &quot;Runscript&quot;,</div><div class=\"line\">  &quot;cmd&quot;: &quot;echo &apos;Choose target&apos;&quot;,</div><div class=\"line\">  &quot;sh&quot;: true,</div><div class=\"line\">  &quot;targets&quot;: &#123;</div><div class=\"line\">    &quot;host_accessed_with_fabric&quot;: &#123; &quot;cmd&quot;: &quot;fab -f /home/gena/rexec.py -H srvname runscript:\\&quot;&#123;FILE_ACTIVE&#125;\\&quot;&quot; &#125;,</div><div class=\"line\">    &quot;host_accessed_with_plain_ssh&quot;: &#123; &quot;cmd&quot;: &quot;scp &#123;FILE_ACTIVE&#125; srvname:~/atom-build.script; ssh srvname ~g.aleksandrov/atom-build.script; ssh srvname rm ~g.aleksandrov/atom-build.script&quot; &#125;,</div><div class=\"line\">    &quot;local_python&quot;: &#123; &quot;cmd&quot;: &quot;python &#123;FILE_ACTIVE&#125;&quot; &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"ssh-config\"><a href=\"#ssh-config\" class=\"headerlink\" title=\".ssh/config\"></a>.ssh/config</h2><p>Мы используем SSH-шлюз, доступ на сервера осуществляется через него. Для тестирования скриптов это не очень удобно, иногда нужен прямой доступ. Его можно получить, настроив SSH-клиент, вот конфиг:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">Host gateway</div><div class=\"line\">    Hostname gateway.example.com</div><div class=\"line\">    User g.aleksandrov</div><div class=\"line\">    IdentityFile ~/.ssh/g.aleksandrov-tw_key</div><div class=\"line\"></div><div class=\"line\">Host directaccess</div><div class=\"line\">    Hostname directaccess.example.com</div><div class=\"line\">    User root</div><div class=\"line\">    IdentityFile ~/.ssh/g.aleksandrov-tw_key</div><div class=\"line\"></div><div class=\"line\">Host gitlab.example.com</div><div class=\"line\">    User git</div><div class=\"line\">    IdentityFile ~/.ssh/g.aleksandrov-tw_key</div><div class=\"line\"></div><div class=\"line\">Host github.com</div><div class=\"line\">    User git</div><div class=\"line\">    IdentityFile ~/Dropbox/keys/github_main_key</div><div class=\"line\"></div><div class=\"line\">Host !gateway* !directaccess* !gitlab.example.com !github.com !*.* *</div><div class=\"line\">    User root</div><div class=\"line\">    ProxyCommand ssh gateway -W %h:22</div><div class=\"line\">    IdentityFile ~/.ssh/id_rsa.admins</div><div class=\"line\">    StrictHostKeyChecking no</div></pre></td></tr></table></figure>\n<p>При таком конфиге доступ на любой сервер будет осуществляться через gateway. За исключением, кхм, исключений.</p>\n<h2 id=\"Fabric\"><a href=\"#Fabric\" class=\"headerlink\" title=\"Fabric\"></a>Fabric</h2><p>Для выполнения команд/скриптов на удалённых серверах я написал fabfile. Вот его шаблон:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#!/usr/bin/python</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> fabric.api <span class=\"keyword\">import</span> run, task, env, put, settings, hosts</div><div class=\"line\"><span class=\"keyword\">from</span> fabric.state <span class=\"keyword\">import</span> output</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">env.use_ssh_config = <span class=\"keyword\">True</span></div><div class=\"line\">env.colorize_errors = <span class=\"keyword\">True</span></div><div class=\"line\">env.warn_only = <span class=\"keyword\">True</span></div><div class=\"line\">env.skip_bad_hosts = <span class=\"keyword\">True</span></div><div class=\"line\">output[<span class=\"string\">'running'</span>] = <span class=\"keyword\">False</span></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_srv_list</span><span class=\"params\">(**kwargs)</span>:</span></div><div class=\"line\">    where = <span class=\"string\">''</span></div><div class=\"line\">    <span class=\"keyword\">for</span> arg <span class=\"keyword\">in</span> kwargs:</div><div class=\"line\">        <span class=\"keyword\">if</span> isinstance(kwargs[arg], int) <span class=\"keyword\">or</span> isinstance(kwargs[arg], float):</div><div class=\"line\">            where += <span class=\"string\">'&#123;&#125; = &#123;&#125; AND '</span>.format(arg, kwargs[arg])</div><div class=\"line\">        <span class=\"keyword\">elif</span> isinstance(kwargs[arg], str):</div><div class=\"line\">            where += <span class=\"string\">'&#123;&#125; = \"&#123;&#125;\" AND '</span>.format(arg, kwargs[arg])</div><div class=\"line\">    where = where[:<span class=\"number\">-5</span>]</div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> where:</div><div class=\"line\">        <span class=\"keyword\">raise</span>(ValueError(<span class=\"string\">'Query params not set!'</span>))</div><div class=\"line\">    <span class=\"comment\"># srv_list = DBClient.select_rows(where)</span></div><div class=\"line\">    <span class=\"keyword\">return</span> srv_list</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">env.roledefs = &#123;</div><div class=\"line\">    role1: [<span class=\"string\">'srv1'</span>, <span class=\"string\">'srv2'</span>, <span class=\"string\">'srv3'</span>],</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">runcmd</span><span class=\"params\">(cmd)</span>:</span></div><div class=\"line\">    run(cmd)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">runscript</span><span class=\"params\">(script_path)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">with</span> settings(warn_only=<span class=\"keyword\">False</span>):</div><div class=\"line\">        res = put(script_path, remote_path=<span class=\"string\">'/root'</span>)</div><div class=\"line\">    <span class=\"keyword\">for</span> script <span class=\"keyword\">in</span> res:</div><div class=\"line\">        run(<span class=\"string\">'chmod u+x &#123;&#125;'</span>.format(script))</div><div class=\"line\">        run(script)</div><div class=\"line\">        run(<span class=\"string\">'rm &#123;&#125;'</span>.format(script))</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">putfile</span><span class=\"params\">(file_path, remote_path)</span>:</span></div><div class=\"line\">    put(file_path, remote_path=remote_path)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"meta\">@hosts('localhost')</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">srvlist</span><span class=\"params\">()</span>:</span></div><div class=\"line\">    output[<span class=\"string\">'status'</span>] = <span class=\"keyword\">False</span></div><div class=\"line\">    <span class=\"keyword\">for</span> role <span class=\"keyword\">in</span> env.roles:</div><div class=\"line\">        <span class=\"keyword\">for</span> srv <span class=\"keyword\">in</span> env.roledefs[role]:</div><div class=\"line\">            print(srv)</div></pre></td></tr></table></figure>\n<p>Пользуюсь им при помощи алиаса командной строки. Добавил в <code>~/.bashrc</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">alias rex=&apos;fab -f /home/g.aleksandrov/rexec.py&apos;</div></pre></td></tr></table></figure>\n<h2 id=\"Mission-Control-в-Unity\"><a href=\"#Mission-Control-в-Unity\" class=\"headerlink\" title=\"Mission Control в Unity\"></a>Mission Control в Unity</h2><p>В macOS часто пользуюсь Mission Control ради просмотра всех открытых окон. Такую штуку можно сделать и в Unity.<br>Для вывода всех окон по наведению курсора в угол экрана в <code>ccsm</code> надо выставить настройку “Scaling” &gt; “initiate_all_edge” (как-то так).</p>\n","excerpt":"","more":"<p>Вот как я настраиваю рабочее окружение.</p>\n<h2 id=\"Клавиша-“-”\"><a href=\"#Клавиша-“-”\" class=\"headerlink\" title=\"Клавиша “#”\"></a>Клавиша “#”</h2><p>Мне не нужен символ номера (shift+3 на русской раскладке). Но я часто пользуюсь символом #. Это нумерованный список в Redmine плюс ссылки на задачи начинаются также с #. В Ubuntu 16.04 исправить недоразумение и сделать так, чтобы в русской раскладке также печатался символ #, можно, отредактировав файл <code>/usr/share/X11/xkb/symbols/ru</code>. Достаточно закомментировать строку 13 (это секция, где переопределяются значения сочетаний shift+цифра). Вот эту строку, если быть точным:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div></pre></td><td class=\"code\"><pre><div class=\"line\">// Keyboard layouts for Russia.</div><div class=\"line\">// AEN &lt;aen@logic.ru&gt;</div><div class=\"line\">// 2001/12/23 by Leon Kanter &lt;leon@blackcatlinux.com&gt;</div><div class=\"line\">// 2005/12/09 Valery Inozemtsev &lt;shrek@altlinux.ru&gt;</div><div class=\"line\"></div><div class=\"line\">// Windows layout</div><div class=\"line\">default  partial alphanumeric_keys</div><div class=\"line\">xkb_symbols &quot;winkeys&quot; &#123;</div><div class=\"line\"></div><div class=\"line\">    include &quot;ru(common)&quot;</div><div class=\"line\">    name[Group1]= &quot;Russian&quot;;</div><div class=\"line\"></div><div class=\"line\">//    key &lt;AE03&gt; &#123; [           3,  numerosign  ] &#125;;</div><div class=\"line\">    key &lt;AE04&gt; &#123; [           4,   semicolon  ] &#125;;</div><div class=\"line\">    key &lt;AE05&gt; &#123; [           5,     percent  ] &#125;;</div></pre></td></tr></table></figure>\n<h2 id=\"Редактор\"><a href=\"#Редактор\" class=\"headerlink\" title=\"Редактор\"></a>Редактор</h2><p>Лучший редактор для меня - Atom. Список модулей, которые я использую:</p>\n<ul>\n<li>autocomplete-python</li>\n<li>build</li>\n<li>busy</li>\n<li>file-icons</li>\n<li>git-plus</li>\n<li>hyperclick <em>(В сочетании с autocomplete-python даёт возможность Ctrl-кликнуть на символ в коде, чтобы перейти к его определению)</em></li>\n<li>language-puppet</li>\n<li>linter</li>\n<li>linter-flake8</li>\n<li>linter-puppet-lint</li>\n<li>linter-rubocop</li>\n<li>minimap</li>\n</ul>\n<h2 id=\"Build\"><a href=\"#Build\" class=\"headerlink\" title=\"Build\"></a>Build</h2><p>Удобно писать код в Atom и тестировать его запуском на удалённом сервере через SSH. Для этого я написал build-сценарий для соответствующего модуля:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  &quot;name&quot;: &quot;Runscript&quot;,</div><div class=\"line\">  &quot;cmd&quot;: &quot;echo &apos;Choose target&apos;&quot;,</div><div class=\"line\">  &quot;sh&quot;: true,</div><div class=\"line\">  &quot;targets&quot;: &#123;</div><div class=\"line\">    &quot;host_accessed_with_fabric&quot;: &#123; &quot;cmd&quot;: &quot;fab -f /home/gena/rexec.py -H srvname runscript:\\&quot;&#123;FILE_ACTIVE&#125;\\&quot;&quot; &#125;,</div><div class=\"line\">    &quot;host_accessed_with_plain_ssh&quot;: &#123; &quot;cmd&quot;: &quot;scp &#123;FILE_ACTIVE&#125; srvname:~/atom-build.script; ssh srvname ~g.aleksandrov/atom-build.script; ssh srvname rm ~g.aleksandrov/atom-build.script&quot; &#125;,</div><div class=\"line\">    &quot;local_python&quot;: &#123; &quot;cmd&quot;: &quot;python &#123;FILE_ACTIVE&#125;&quot; &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h2 id=\"ssh-config\"><a href=\"#ssh-config\" class=\"headerlink\" title=\".ssh/config\"></a>.ssh/config</h2><p>Мы используем SSH-шлюз, доступ на сервера осуществляется через него. Для тестирования скриптов это не очень удобно, иногда нужен прямой доступ. Его можно получить, настроив SSH-клиент, вот конфиг:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div></pre></td><td class=\"code\"><pre><div class=\"line\">Host gateway</div><div class=\"line\">    Hostname gateway.example.com</div><div class=\"line\">    User g.aleksandrov</div><div class=\"line\">    IdentityFile ~/.ssh/g.aleksandrov-tw_key</div><div class=\"line\"></div><div class=\"line\">Host directaccess</div><div class=\"line\">    Hostname directaccess.example.com</div><div class=\"line\">    User root</div><div class=\"line\">    IdentityFile ~/.ssh/g.aleksandrov-tw_key</div><div class=\"line\"></div><div class=\"line\">Host gitlab.example.com</div><div class=\"line\">    User git</div><div class=\"line\">    IdentityFile ~/.ssh/g.aleksandrov-tw_key</div><div class=\"line\"></div><div class=\"line\">Host github.com</div><div class=\"line\">    User git</div><div class=\"line\">    IdentityFile ~/Dropbox/keys/github_main_key</div><div class=\"line\"></div><div class=\"line\">Host !gateway* !directaccess* !gitlab.example.com !github.com !*.* *</div><div class=\"line\">    User root</div><div class=\"line\">    ProxyCommand ssh gateway -W %h:22</div><div class=\"line\">    IdentityFile ~/.ssh/id_rsa.admins</div><div class=\"line\">    StrictHostKeyChecking no</div></pre></td></tr></table></figure>\n<p>При таком конфиге доступ на любой сервер будет осуществляться через gateway. За исключением, кхм, исключений.</p>\n<h2 id=\"Fabric\"><a href=\"#Fabric\" class=\"headerlink\" title=\"Fabric\"></a>Fabric</h2><p>Для выполнения команд/скриптов на удалённых серверах я написал fabfile. Вот его шаблон:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div><div class=\"line\">48</div><div class=\"line\">49</div><div class=\"line\">50</div><div class=\"line\">51</div><div class=\"line\">52</div><div class=\"line\">53</div><div class=\"line\">54</div><div class=\"line\">55</div><div class=\"line\">56</div><div class=\"line\">57</div><div class=\"line\">58</div><div class=\"line\">59</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\">#!/usr/bin/python</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> fabric.api <span class=\"keyword\">import</span> run, task, env, put, settings, hosts</div><div class=\"line\"><span class=\"keyword\">from</span> fabric.state <span class=\"keyword\">import</span> output</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">env.use_ssh_config = <span class=\"keyword\">True</span></div><div class=\"line\">env.colorize_errors = <span class=\"keyword\">True</span></div><div class=\"line\">env.warn_only = <span class=\"keyword\">True</span></div><div class=\"line\">env.skip_bad_hosts = <span class=\"keyword\">True</span></div><div class=\"line\">output[<span class=\"string\">'running'</span>] = <span class=\"keyword\">False</span></div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_srv_list</span><span class=\"params\">(**kwargs)</span>:</span></div><div class=\"line\">    where = <span class=\"string\">''</span></div><div class=\"line\">    <span class=\"keyword\">for</span> arg <span class=\"keyword\">in</span> kwargs:</div><div class=\"line\">        <span class=\"keyword\">if</span> isinstance(kwargs[arg], int) <span class=\"keyword\">or</span> isinstance(kwargs[arg], float):</div><div class=\"line\">            where += <span class=\"string\">'&#123;&#125; = &#123;&#125; AND '</span>.format(arg, kwargs[arg])</div><div class=\"line\">        <span class=\"keyword\">elif</span> isinstance(kwargs[arg], str):</div><div class=\"line\">            where += <span class=\"string\">'&#123;&#125; = \"&#123;&#125;\" AND '</span>.format(arg, kwargs[arg])</div><div class=\"line\">    where = where[:<span class=\"number\">-5</span>]</div><div class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> where:</div><div class=\"line\">        <span class=\"keyword\">raise</span>(ValueError(<span class=\"string\">'Query params not set!'</span>))</div><div class=\"line\">    <span class=\"comment\"># srv_list = DBClient.select_rows(where)</span></div><div class=\"line\">    <span class=\"keyword\">return</span> srv_list</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\">env.roledefs = &#123;</div><div class=\"line\">    role1: [<span class=\"string\">'srv1'</span>, <span class=\"string\">'srv2'</span>, <span class=\"string\">'srv3'</span>],</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">runcmd</span><span class=\"params\">(cmd)</span>:</span></div><div class=\"line\">    run(cmd)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">runscript</span><span class=\"params\">(script_path)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">with</span> settings(warn_only=<span class=\"keyword\">False</span>):</div><div class=\"line\">        res = put(script_path, remote_path=<span class=\"string\">'/root'</span>)</div><div class=\"line\">    <span class=\"keyword\">for</span> script <span class=\"keyword\">in</span> res:</div><div class=\"line\">        run(<span class=\"string\">'chmod u+x &#123;&#125;'</span>.format(script))</div><div class=\"line\">        run(script)</div><div class=\"line\">        run(<span class=\"string\">'rm &#123;&#125;'</span>.format(script))</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">putfile</span><span class=\"params\">(file_path, remote_path)</span>:</span></div><div class=\"line\">    put(file_path, remote_path=remote_path)</div><div class=\"line\"></div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">@task</span></div><div class=\"line\"><span class=\"meta\">@hosts('localhost')</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">srvlist</span><span class=\"params\">()</span>:</span></div><div class=\"line\">    output[<span class=\"string\">'status'</span>] = <span class=\"keyword\">False</span></div><div class=\"line\">    <span class=\"keyword\">for</span> role <span class=\"keyword\">in</span> env.roles:</div><div class=\"line\">        <span class=\"keyword\">for</span> srv <span class=\"keyword\">in</span> env.roledefs[role]:</div><div class=\"line\">            print(srv)</div></pre></td></tr></table></figure>\n<p>Пользуюсь им при помощи алиаса командной строки. Добавил в <code>~/.bashrc</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">alias rex=&apos;fab -f /home/g.aleksandrov/rexec.py&apos;</div></pre></td></tr></table></figure>\n<h2 id=\"Mission-Control-в-Unity\"><a href=\"#Mission-Control-в-Unity\" class=\"headerlink\" title=\"Mission Control в Unity\"></a>Mission Control в Unity</h2><p>В macOS часто пользуюсь Mission Control ради просмотра всех открытых окон. Такую штуку можно сделать и в Unity.<br>Для вывода всех окон по наведению курсора в угол экрана в <code>ccsm</code> надо выставить настройку “Scaling” &gt; “initiate_all_edge” (как-то так).</p>\n"},{"title":"Из книги \"Web Operations\" - Составление SLA","_content":"Прочёл превосходную книгу - \"Web Operations: Keeping the Data on Time\". Авторы: John Allspaw, Jesse Robbins. ISBN-13: 978-1449377441.\n\nНесмотря на то, что книга вышла в 2010-ом, информация в ней остаётся актуальной для многих компаний.\n\nТакже в книге изложены организационные принципы, которые вряд ли устареют в ближайшем будущем.\n\nХочу особо выделить некоторые моменты из книги, раскидаю по отдельным постам.\n\n### Составление SLA\nSLA (Service Level Agreement) - формальный договор между заказчиком услуги и её поставщиком, содержащий описание услуги, права и обязанности сторон, а также согласованный уровень качества предоставления данной услуги.\n\n> User-facing SLAs have several components (see Table 11-2). You need to be specific about these so that there’s no doubt whether an SLA was violated when someone claims that a problem occurred.\n\nПривожу таблицу 11-2.\n\n| SLA component       | What it means                                                  | How it’s expressed                                                                                                                         | Example |\n|---------------------|----------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|---------|\n| Task being measured | The thing being tested — the business process or function itself | This is usually expressed as a name or description of the test; avoid using just the url or page name as it makes the test harder to read. |“Updating  a contact  record”|\n|Metric being  calculated|The element of latency that’s being computed. If you can’t control it, it shouldn’t be in your SLA.|This is a measurement  that is specific and can be reproduced across systems. You should know, for example, that “page load time” means “from the first DNS lookup to the browser’s `onLoad` event.”|“Host latency”|\n|Calculation|The math used to generate the number|Unfortunately, this is usually an average. Don’t do this. Averages suck. Insist on a percentile (or  at the very least a trimmed  mean), and a single bad measurement won’t ruin an otherwise good month.|“95th percentile”|\n|Valid times|The times and days when the metric is valid. If you don’t include this, you won’t have room for maintenance. Some business processes matter at only certain times.|This is expressed as hours, days, and time zones.|“8:00 a.m. to 9:00  p.m., pST, Monday to Friday”|\n|Test conditions (or filters)|The circumstances of the test or the visits included in the report: - For synthetic monitoring, this may be an agreed- upon external service provider. - For RUM, it may be all visits from a particular client, location, IP range, or some other segment.|This is expressed as operating systems, network locations, browsers, user accounts, source IP ranges, and so on.|“Domestic United States on a PC running IE7”|\n|Time span|The time over which the calculation is performed|This is expressed as a time range, often a day, week, or month.|“In a 30-day period”|\n","source":"_posts/2016-07-03-web-operations-sla.md","raw":"---\ntitle: 'Из книги \"Web Operations\" - Составление SLA'\ntags: [book]\n---\nПрочёл превосходную книгу - \"Web Operations: Keeping the Data on Time\". Авторы: John Allspaw, Jesse Robbins. ISBN-13: 978-1449377441.\n\nНесмотря на то, что книга вышла в 2010-ом, информация в ней остаётся актуальной для многих компаний.\n\nТакже в книге изложены организационные принципы, которые вряд ли устареют в ближайшем будущем.\n\nХочу особо выделить некоторые моменты из книги, раскидаю по отдельным постам.\n\n### Составление SLA\nSLA (Service Level Agreement) - формальный договор между заказчиком услуги и её поставщиком, содержащий описание услуги, права и обязанности сторон, а также согласованный уровень качества предоставления данной услуги.\n\n> User-facing SLAs have several components (see Table 11-2). You need to be specific about these so that there’s no doubt whether an SLA was violated when someone claims that a problem occurred.\n\nПривожу таблицу 11-2.\n\n| SLA component       | What it means                                                  | How it’s expressed                                                                                                                         | Example |\n|---------------------|----------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------|---------|\n| Task being measured | The thing being tested — the business process or function itself | This is usually expressed as a name or description of the test; avoid using just the url or page name as it makes the test harder to read. |“Updating  a contact  record”|\n|Metric being  calculated|The element of latency that’s being computed. If you can’t control it, it shouldn’t be in your SLA.|This is a measurement  that is specific and can be reproduced across systems. You should know, for example, that “page load time” means “from the first DNS lookup to the browser’s `onLoad` event.”|“Host latency”|\n|Calculation|The math used to generate the number|Unfortunately, this is usually an average. Don’t do this. Averages suck. Insist on a percentile (or  at the very least a trimmed  mean), and a single bad measurement won’t ruin an otherwise good month.|“95th percentile”|\n|Valid times|The times and days when the metric is valid. If you don’t include this, you won’t have room for maintenance. Some business processes matter at only certain times.|This is expressed as hours, days, and time zones.|“8:00 a.m. to 9:00  p.m., pST, Monday to Friday”|\n|Test conditions (or filters)|The circumstances of the test or the visits included in the report: - For synthetic monitoring, this may be an agreed- upon external service provider. - For RUM, it may be all visits from a particular client, location, IP range, or some other segment.|This is expressed as operating systems, network locations, browsers, user accounts, source IP ranges, and so on.|“Domestic United States on a PC running IE7”|\n|Time span|The time over which the calculation is performed|This is expressed as a time range, often a day, week, or month.|“In a 30-day period”|\n","slug":"2016-07-03-web-operations-sla","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo9u001ogkurb8st6rga","content":"<p>Прочёл превосходную книгу - “Web Operations: Keeping the Data on Time”. Авторы: John Allspaw, Jesse Robbins. ISBN-13: 978-1449377441.</p>\n<p>Несмотря на то, что книга вышла в 2010-ом, информация в ней остаётся актуальной для многих компаний.</p>\n<p>Также в книге изложены организационные принципы, которые вряд ли устареют в ближайшем будущем.</p>\n<p>Хочу особо выделить некоторые моменты из книги, раскидаю по отдельным постам.</p>\n<h3 id=\"Составление-SLA\"><a href=\"#Составление-SLA\" class=\"headerlink\" title=\"Составление SLA\"></a>Составление SLA</h3><p>SLA (Service Level Agreement) - формальный договор между заказчиком услуги и её поставщиком, содержащий описание услуги, права и обязанности сторон, а также согласованный уровень качества предоставления данной услуги.</p>\n<blockquote>\n<p>User-facing SLAs have several components (see Table 11-2). You need to be specific about these so that there’s no doubt whether an SLA was violated when someone claims that a problem occurred.</p>\n</blockquote>\n<p>Привожу таблицу 11-2.</p>\n<table>\n<thead>\n<tr>\n<th>SLA component</th>\n<th>What it means</th>\n<th>How it’s expressed</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Task being measured</td>\n<td>The thing being tested — the business process or function itself</td>\n<td>This is usually expressed as a name or description of the test; avoid using just the url or page name as it makes the test harder to read.</td>\n<td>“Updating  a contact  record”</td>\n</tr>\n<tr>\n<td>Metric being  calculated</td>\n<td>The element of latency that’s being computed. If you can’t control it, it shouldn’t be in your SLA.</td>\n<td>This is a measurement  that is specific and can be reproduced across systems. You should know, for example, that “page load time” means “from the first DNS lookup to the browser’s <code>onLoad</code> event.”</td>\n<td>“Host latency”</td>\n</tr>\n<tr>\n<td>Calculation</td>\n<td>The math used to generate the number</td>\n<td>Unfortunately, this is usually an average. Don’t do this. Averages suck. Insist on a percentile (or  at the very least a trimmed  mean), and a single bad measurement won’t ruin an otherwise good month.</td>\n<td>“95th percentile”</td>\n</tr>\n<tr>\n<td>Valid times</td>\n<td>The times and days when the metric is valid. If you don’t include this, you won’t have room for maintenance. Some business processes matter at only certain times.</td>\n<td>This is expressed as hours, days, and time zones.</td>\n<td>“8:00 a.m. to 9:00  p.m., pST, Monday to Friday”</td>\n</tr>\n<tr>\n<td>Test conditions (or filters)</td>\n<td>The circumstances of the test or the visits included in the report: - For synthetic monitoring, this may be an agreed- upon external service provider. - For RUM, it may be all visits from a particular client, location, IP range, or some other segment.</td>\n<td>This is expressed as operating systems, network locations, browsers, user accounts, source IP ranges, and so on.</td>\n<td>“Domestic United States on a PC running IE7”</td>\n</tr>\n<tr>\n<td>Time span</td>\n<td>The time over which the calculation is performed</td>\n<td>This is expressed as a time range, often a day, week, or month.</td>\n<td>“In a 30-day period”</td>\n</tr>\n</tbody>\n</table>\n","excerpt":"","more":"<p>Прочёл превосходную книгу - “Web Operations: Keeping the Data on Time”. Авторы: John Allspaw, Jesse Robbins. ISBN-13: 978-1449377441.</p>\n<p>Несмотря на то, что книга вышла в 2010-ом, информация в ней остаётся актуальной для многих компаний.</p>\n<p>Также в книге изложены организационные принципы, которые вряд ли устареют в ближайшем будущем.</p>\n<p>Хочу особо выделить некоторые моменты из книги, раскидаю по отдельным постам.</p>\n<h3 id=\"Составление-SLA\"><a href=\"#Составление-SLA\" class=\"headerlink\" title=\"Составление SLA\"></a>Составление SLA</h3><p>SLA (Service Level Agreement) - формальный договор между заказчиком услуги и её поставщиком, содержащий описание услуги, права и обязанности сторон, а также согласованный уровень качества предоставления данной услуги.</p>\n<blockquote>\n<p>User-facing SLAs have several components (see Table 11-2). You need to be specific about these so that there’s no doubt whether an SLA was violated when someone claims that a problem occurred.</p>\n</blockquote>\n<p>Привожу таблицу 11-2.</p>\n<table>\n<thead>\n<tr>\n<th>SLA component</th>\n<th>What it means</th>\n<th>How it’s expressed</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Task being measured</td>\n<td>The thing being tested — the business process or function itself</td>\n<td>This is usually expressed as a name or description of the test; avoid using just the url or page name as it makes the test harder to read.</td>\n<td>“Updating  a contact  record”</td>\n</tr>\n<tr>\n<td>Metric being  calculated</td>\n<td>The element of latency that’s being computed. If you can’t control it, it shouldn’t be in your SLA.</td>\n<td>This is a measurement  that is specific and can be reproduced across systems. You should know, for example, that “page load time” means “from the first DNS lookup to the browser’s <code>onLoad</code> event.”</td>\n<td>“Host latency”</td>\n</tr>\n<tr>\n<td>Calculation</td>\n<td>The math used to generate the number</td>\n<td>Unfortunately, this is usually an average. Don’t do this. Averages suck. Insist on a percentile (or  at the very least a trimmed  mean), and a single bad measurement won’t ruin an otherwise good month.</td>\n<td>“95th percentile”</td>\n</tr>\n<tr>\n<td>Valid times</td>\n<td>The times and days when the metric is valid. If you don’t include this, you won’t have room for maintenance. Some business processes matter at only certain times.</td>\n<td>This is expressed as hours, days, and time zones.</td>\n<td>“8:00 a.m. to 9:00  p.m., pST, Monday to Friday”</td>\n</tr>\n<tr>\n<td>Test conditions (or filters)</td>\n<td>The circumstances of the test or the visits included in the report: - For synthetic monitoring, this may be an agreed- upon external service provider. - For RUM, it may be all visits from a particular client, location, IP range, or some other segment.</td>\n<td>This is expressed as operating systems, network locations, browsers, user accounts, source IP ranges, and so on.</td>\n<td>“Domestic United States on a PC running IE7”</td>\n</tr>\n<tr>\n<td>Time span</td>\n<td>The time over which the calculation is performed</td>\n<td>This is expressed as a time range, often a day, week, or month.</td>\n<td>“In a 30-day period”</td>\n</tr>\n</tbody>\n</table>\n"},{"title":"Из книги \"Web Operations\" - Data Assets","_content":"Продолжаю постить выдержки из книги \"Web Operations: Keeping the Data on Time\".\n\nНа этот раз речь пойдёт об одной полезной практике. Она заключается в составлении таблицы, каждая строка в которой - какой-то ресурс данных вашей компании, будь то база данных, пользовательские данные, репозитории с кодом. Штука в том, что в эту таблицы обязательно должны быть записаны и бэкапы. Лучше всего проиллюстрировать эту технику готовой таблицей из книги.\n\nТаблица 14-5 из книги.\nRTO - recovery-time objective, RPO - recovery-point objective.\n\n> RTOs define the maximum length of time it should take to recover from any sort of disruption of service. Let’s say your expensive NAS appliance goes down, and part of your site depends on it. You’ll need to know how long the system can reasonably be unavailable before it has a serious negative impact on your product or users. It’s important that you talk with your product people to figure out how long the system can be down (and data inaccessible) before the business side of things starts to unravel. This is something you’ll want to know and agree upon before something bad happens.\n\n> RPOs describe the maximum amount of data loss that is acceptable after a disruption of service. The amount of data loss is usually measured in time. Let’s say the crops database I described earlier is backed up nightly at 10:00. If the storage system melts down and loses all its data at 9:00 p.m., the only backup you have is from 10:00 the night before, and you will have lost about a day’s worth of data if you restore from that backup. This means the maximum RPO for this system is about 24 hours, the time elapsed between nightly backups.\n\n|Location|System|System Type|Data type|RTO|RPO|Business impact|Data protection|\n|San Diego|database1.sd|Storage system|Database|10 minutes|15 minutes|Users can’t harvest crops or plant new crops|Nightly backups; local replication;  application-consistent snapshots every hour; continuously back up transaction logs from master to VTL|\n|San Diego|database2.sd|Storage system|Database|4 hours|2 hours|No local replica for primary crops database|Remote replica|\n|New York|database3.ny|Storage system|Database|4 hours|2 hours|No remote replica for primary crops database|None|\n|San Diego|vtl1.sd|VTL|Database backups and transaction logs|12 hours|24 hours|Can't back up or recover the crops database or transaction logs|None|\n","source":"_posts/2016-10-28-web-operations-data-assets.md","raw":"---\ntitle: 'Из книги \"Web Operations\" - Data Assets'\ntags: [book]\n---\nПродолжаю постить выдержки из книги \"Web Operations: Keeping the Data on Time\".\n\nНа этот раз речь пойдёт об одной полезной практике. Она заключается в составлении таблицы, каждая строка в которой - какой-то ресурс данных вашей компании, будь то база данных, пользовательские данные, репозитории с кодом. Штука в том, что в эту таблицы обязательно должны быть записаны и бэкапы. Лучше всего проиллюстрировать эту технику готовой таблицей из книги.\n\nТаблица 14-5 из книги.\nRTO - recovery-time objective, RPO - recovery-point objective.\n\n> RTOs define the maximum length of time it should take to recover from any sort of disruption of service. Let’s say your expensive NAS appliance goes down, and part of your site depends on it. You’ll need to know how long the system can reasonably be unavailable before it has a serious negative impact on your product or users. It’s important that you talk with your product people to figure out how long the system can be down (and data inaccessible) before the business side of things starts to unravel. This is something you’ll want to know and agree upon before something bad happens.\n\n> RPOs describe the maximum amount of data loss that is acceptable after a disruption of service. The amount of data loss is usually measured in time. Let’s say the crops database I described earlier is backed up nightly at 10:00. If the storage system melts down and loses all its data at 9:00 p.m., the only backup you have is from 10:00 the night before, and you will have lost about a day’s worth of data if you restore from that backup. This means the maximum RPO for this system is about 24 hours, the time elapsed between nightly backups.\n\n|Location|System|System Type|Data type|RTO|RPO|Business impact|Data protection|\n|San Diego|database1.sd|Storage system|Database|10 minutes|15 minutes|Users can’t harvest crops or plant new crops|Nightly backups; local replication;  application-consistent snapshots every hour; continuously back up transaction logs from master to VTL|\n|San Diego|database2.sd|Storage system|Database|4 hours|2 hours|No local replica for primary crops database|Remote replica|\n|New York|database3.ny|Storage system|Database|4 hours|2 hours|No remote replica for primary crops database|None|\n|San Diego|vtl1.sd|VTL|Database backups and transaction logs|12 hours|24 hours|Can't back up or recover the crops database or transaction logs|None|\n","slug":"2016-10-28-web-operations-data-assets","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo9x001rgkurxpgnhwma","content":"<p>Продолжаю постить выдержки из книги “Web Operations: Keeping the Data on Time”.</p>\n<p>На этот раз речь пойдёт об одной полезной практике. Она заключается в составлении таблицы, каждая строка в которой - какой-то ресурс данных вашей компании, будь то база данных, пользовательские данные, репозитории с кодом. Штука в том, что в эту таблицы обязательно должны быть записаны и бэкапы. Лучше всего проиллюстрировать эту технику готовой таблицей из книги.</p>\n<p>Таблица 14-5 из книги.<br>RTO - recovery-time objective, RPO - recovery-point objective.</p>\n<blockquote>\n<p>RTOs define the maximum length of time it should take to recover from any sort of disruption of service. Let’s say your expensive NAS appliance goes down, and part of your site depends on it. You’ll need to know how long the system can reasonably be unavailable before it has a serious negative impact on your product or users. It’s important that you talk with your product people to figure out how long the system can be down (and data inaccessible) before the business side of things starts to unravel. This is something you’ll want to know and agree upon before something bad happens.</p>\n<p>RPOs describe the maximum amount of data loss that is acceptable after a disruption of service. The amount of data loss is usually measured in time. Let’s say the crops database I described earlier is backed up nightly at 10:00. If the storage system melts down and loses all its data at 9:00 p.m., the only backup you have is from 10:00 the night before, and you will have lost about a day’s worth of data if you restore from that backup. This means the maximum RPO for this system is about 24 hours, the time elapsed between nightly backups.</p>\n</blockquote>\n<p>|Location|System|System Type|Data type|RTO|RPO|Business impact|Data protection|<br>|San Diego|database1.sd|Storage system|Database|10 minutes|15 minutes|Users can’t harvest crops or plant new crops|Nightly backups; local replication;  application-consistent snapshots every hour; continuously back up transaction logs from master to VTL|<br>|San Diego|database2.sd|Storage system|Database|4 hours|2 hours|No local replica for primary crops database|Remote replica|<br>|New York|database3.ny|Storage system|Database|4 hours|2 hours|No remote replica for primary crops database|None|<br>|San Diego|vtl1.sd|VTL|Database backups and transaction logs|12 hours|24 hours|Can’t back up or recover the crops database or transaction logs|None|</p>\n","excerpt":"","more":"<p>Продолжаю постить выдержки из книги “Web Operations: Keeping the Data on Time”.</p>\n<p>На этот раз речь пойдёт об одной полезной практике. Она заключается в составлении таблицы, каждая строка в которой - какой-то ресурс данных вашей компании, будь то база данных, пользовательские данные, репозитории с кодом. Штука в том, что в эту таблицы обязательно должны быть записаны и бэкапы. Лучше всего проиллюстрировать эту технику готовой таблицей из книги.</p>\n<p>Таблица 14-5 из книги.<br>RTO - recovery-time objective, RPO - recovery-point objective.</p>\n<blockquote>\n<p>RTOs define the maximum length of time it should take to recover from any sort of disruption of service. Let’s say your expensive NAS appliance goes down, and part of your site depends on it. You’ll need to know how long the system can reasonably be unavailable before it has a serious negative impact on your product or users. It’s important that you talk with your product people to figure out how long the system can be down (and data inaccessible) before the business side of things starts to unravel. This is something you’ll want to know and agree upon before something bad happens.</p>\n<p>RPOs describe the maximum amount of data loss that is acceptable after a disruption of service. The amount of data loss is usually measured in time. Let’s say the crops database I described earlier is backed up nightly at 10:00. If the storage system melts down and loses all its data at 9:00 p.m., the only backup you have is from 10:00 the night before, and you will have lost about a day’s worth of data if you restore from that backup. This means the maximum RPO for this system is about 24 hours, the time elapsed between nightly backups.</p>\n</blockquote>\n<p>|Location|System|System Type|Data type|RTO|RPO|Business impact|Data protection|<br>|San Diego|database1.sd|Storage system|Database|10 minutes|15 minutes|Users can’t harvest crops or plant new crops|Nightly backups; local replication;  application-consistent snapshots every hour; continuously back up transaction logs from master to VTL|<br>|San Diego|database2.sd|Storage system|Database|4 hours|2 hours|No local replica for primary crops database|Remote replica|<br>|New York|database3.ny|Storage system|Database|4 hours|2 hours|No remote replica for primary crops database|None|<br>|San Diego|vtl1.sd|VTL|Database backups and transaction logs|12 hours|24 hours|Can’t back up or recover the crops database or transaction logs|None|</p>\n"},{"title":"Из книги \"Web Operations\" - Postmortem (RCA)","_content":"Продолжаю постить выдержки из книги \"Web Operations: Keeping the Data on Time\".\n\nВ этом посте речь пойдёт о проведении Postmortem, или Root-Cause Analysis (RCA). По сути, это - анализ произошедшей аварии. В книге действительно хорошо всё описано, поэтому выдержки приведу as is.\n\n### What Is a Postmortem?\n\nA postmortem needs to cover these essentials at a minimum:\n\n1. A description of the incident\n2. A description of the root cause\n3. How the incident was stabilized and/or fixed\n4. A timeline of actions taken to resolve the incident\n5. How the incident affected customers\n6. Remediations or corrective actions\n\nThe first five items make sure everyone involved has a common understanding of the facts. Many incidents reoccur because people do not understand what really happened and how the problem was fixed. Different teams and different layers of management arrive at the postmortem with different understandings of what happened. During a postmortem, everyone with significant involvement in the incident should be present at the same time to document a common description of the facts of the incident. Without an accurate account of the facts, it will be impossible to determine and prioritize the corrective actions that are the biggest benefit of a postmortem.\n\nDetermining the root cause should go without saying, but I can’t tell you the number of times I have been in a postmortem where participants spent tons of time debating each possible remediation item or the number of customers affected, only to find that they had wasted their time because they didn’t have the root cause right.\n\nThe same goes for the stabilizing steps. Often during the chaos of a major incident, multiple people attempt multiple fixes. Determine the true root cause and the step that brought it to stable before moving on. Note that an incident might be stable without actually being fixed. You can eliminate customer impact without fixing an issue like when you reboot servers to address a memory leak. Although it will be stable for a short period, the servers are just going to run out of memory again if the root cause is not addressed.\n\nA timeline will be important for determining how the incident could have been fixed more quickly. Again, multiple people may have a different understanding of the time- line. Allow each participant to contribute the items they are aware of before moving to remediation items around decreasing Time to Resolve (TTR). Make sure to answer the following questions:\n\n- When did the incident begin to affect customers? (Note: Not all incidents affect customers.)\n- When did someone in the organization first become aware that there was a problem?\n- How did this person become aware? Through monitoring? The Customer Care team? A personal report?\n- How long did it take for the knowledge of the incident to get to the person who ultimately resolved it?\n- What would have allowed someone to diagnose the fault earlier? (For example, better monitoring, more comprehensive troubleshooting guides, etc.)\n- Did the stabilizing steps take a long time to implement? Could they be automated or simplified to speed them up?\n\nReducing the TTR of an incident is every bit as important as eliminating incidents themselves. Ultimately, total customer impact minutes (TTR × Number of Customers Affected) is what counts. Some outages may be unavoidable, but if you can ensure quick recovery, your customers will benefit.\n\nAfter determining the customer impact, you may want to assign a severity level to the incident. You can develop your own severity categories, or use this example:\n\nSeverity 1: site outages affecting a significant number of customers\n\nSeverity 2: site degradation, performance issues, or broken features which are difficult to work around\n\nSeverity 3: other service issues that have minimal customer impact or easy workarounds\n\nAssigning a severity level will help you to prioritize completion of your remediation items and is also useful during the triage stage of an active incident. You may have already assigned a severity level while attempting to resolve the issue so that you could determine whether it is a five-alarm fire requiring all hands on deck or a minor blip.\n\n### When to Conduct a Postmortem.\n\nYou should conduct a postmortem after every major outage that affects customers, preferably within 24 hours. This is a little more difficult than it sounds. Teams are usually busy. They are especially busy right after an incident occurs, because they probably spent unplanned cycles on firefighting. Some of the firefighters may have been up all night resolving the incident. Once an incident is stable, people have a tendency to get back to whatever they were doing before they were interrupted to try to make up for lost time.\n\nThe important thing to note is that until a postmortem is conducted and corrective actions are identified, your site is at risk of repeating the incident. If you can’t conduct the postmortem within 24 hours, don’t wait any longer than a week. After a week, incident participants will start to forget key details; you may be missing key logfiles; and of course, you remain at risk for reoccurrence.\n\nAlthough it’s good to complete a postmortem within 24 hours, you should not conduct a postmortem while the incident is still open. Trying to determine preventive actions or assign blame is a distraction that teams don’t need while they are attempting to stabi- lize the service. Remember, this process is ultimately intended to benefit your customers, and the process should never directly get in the way of restoring service to them.\n\n### Postmortem Follow-Up\n...\n\nAfter many years of postmortems, I’ve found a few areas that you will likely want to consider for corrective actions. I call this _site operability_.\n\n_Eliminate single points of failure_\n\nHardware can and will fail. Utilize redundancy to protect yourself. Don’t let hardware failure be a cause of a customer-impacting incident.\n\n_Capacity planning_\n\nUnderstand your site and its future capacity needs. Base your capacity planning on total utilization of primary constraints such as CPU, memory, I/O, and storage, not on secondary constraints such as number of users. Provision in the areas you need, before you need them.\n\n_Monitoring_\n\nThis is essential for detecting and diagnosing incidents. Other chapters in this book provide great recommendations for monitoring techniques.\n\n_Release management_\n\nChange is historically the most likely cause of incidents. Make sure your release process has the right quality controls in place. Consider implementing concepts such as automated testing, staging environments, limited production deployments, dark launches (rolling out code without activating functionality for customers until the code is proven stable), and the ability to roll back immediately.\n\n_Operational architecture reviews_\n\nHold an architecture review that is entirely focused on how the new release or product will perform in the production environment before rolling it out to customers. Consider maintainability, failure scenarios, and incident response as well as architectural reliability and scalability.\n\n_Configuration management_\n\nAs your systems grow, production configurations become increasingly ­complicated. The inability to understand the implications of changes to production configurations often leads to incidents attributed to human error. Having a configuration management system that is straightforward and logical will help engineers avoid unintended issues. Read Chapter 5 in this book for more recommendations.\n\n_On-call and escalation process_\n\nIdentify the issue and get it to the person who can resolve it as quickly as possible.\n\n_Unstable components_\n\nIdentify and fix software components with a history of crashing and unintended behavior. Make it a priority even when there is an easy manual fix. Those manual fixes add up to become a drag on customer experience and your ability to scale and be effective.\n\nBy proactively ensuring that your site is operable, you will be able to avoid many painful postmortems before they are even necessary.\n","source":"_posts/2016-09-27-web-operations-postmortem.md","raw":"---\ntitle: 'Из книги \"Web Operations\" - Postmortem (RCA)'\ntags: [book]\n---\nПродолжаю постить выдержки из книги \"Web Operations: Keeping the Data on Time\".\n\nВ этом посте речь пойдёт о проведении Postmortem, или Root-Cause Analysis (RCA). По сути, это - анализ произошедшей аварии. В книге действительно хорошо всё описано, поэтому выдержки приведу as is.\n\n### What Is a Postmortem?\n\nA postmortem needs to cover these essentials at a minimum:\n\n1. A description of the incident\n2. A description of the root cause\n3. How the incident was stabilized and/or fixed\n4. A timeline of actions taken to resolve the incident\n5. How the incident affected customers\n6. Remediations or corrective actions\n\nThe first five items make sure everyone involved has a common understanding of the facts. Many incidents reoccur because people do not understand what really happened and how the problem was fixed. Different teams and different layers of management arrive at the postmortem with different understandings of what happened. During a postmortem, everyone with significant involvement in the incident should be present at the same time to document a common description of the facts of the incident. Without an accurate account of the facts, it will be impossible to determine and prioritize the corrective actions that are the biggest benefit of a postmortem.\n\nDetermining the root cause should go without saying, but I can’t tell you the number of times I have been in a postmortem where participants spent tons of time debating each possible remediation item or the number of customers affected, only to find that they had wasted their time because they didn’t have the root cause right.\n\nThe same goes for the stabilizing steps. Often during the chaos of a major incident, multiple people attempt multiple fixes. Determine the true root cause and the step that brought it to stable before moving on. Note that an incident might be stable without actually being fixed. You can eliminate customer impact without fixing an issue like when you reboot servers to address a memory leak. Although it will be stable for a short period, the servers are just going to run out of memory again if the root cause is not addressed.\n\nA timeline will be important for determining how the incident could have been fixed more quickly. Again, multiple people may have a different understanding of the time- line. Allow each participant to contribute the items they are aware of before moving to remediation items around decreasing Time to Resolve (TTR). Make sure to answer the following questions:\n\n- When did the incident begin to affect customers? (Note: Not all incidents affect customers.)\n- When did someone in the organization first become aware that there was a problem?\n- How did this person become aware? Through monitoring? The Customer Care team? A personal report?\n- How long did it take for the knowledge of the incident to get to the person who ultimately resolved it?\n- What would have allowed someone to diagnose the fault earlier? (For example, better monitoring, more comprehensive troubleshooting guides, etc.)\n- Did the stabilizing steps take a long time to implement? Could they be automated or simplified to speed them up?\n\nReducing the TTR of an incident is every bit as important as eliminating incidents themselves. Ultimately, total customer impact minutes (TTR × Number of Customers Affected) is what counts. Some outages may be unavoidable, but if you can ensure quick recovery, your customers will benefit.\n\nAfter determining the customer impact, you may want to assign a severity level to the incident. You can develop your own severity categories, or use this example:\n\nSeverity 1: site outages affecting a significant number of customers\n\nSeverity 2: site degradation, performance issues, or broken features which are difficult to work around\n\nSeverity 3: other service issues that have minimal customer impact or easy workarounds\n\nAssigning a severity level will help you to prioritize completion of your remediation items and is also useful during the triage stage of an active incident. You may have already assigned a severity level while attempting to resolve the issue so that you could determine whether it is a five-alarm fire requiring all hands on deck or a minor blip.\n\n### When to Conduct a Postmortem.\n\nYou should conduct a postmortem after every major outage that affects customers, preferably within 24 hours. This is a little more difficult than it sounds. Teams are usually busy. They are especially busy right after an incident occurs, because they probably spent unplanned cycles on firefighting. Some of the firefighters may have been up all night resolving the incident. Once an incident is stable, people have a tendency to get back to whatever they were doing before they were interrupted to try to make up for lost time.\n\nThe important thing to note is that until a postmortem is conducted and corrective actions are identified, your site is at risk of repeating the incident. If you can’t conduct the postmortem within 24 hours, don’t wait any longer than a week. After a week, incident participants will start to forget key details; you may be missing key logfiles; and of course, you remain at risk for reoccurrence.\n\nAlthough it’s good to complete a postmortem within 24 hours, you should not conduct a postmortem while the incident is still open. Trying to determine preventive actions or assign blame is a distraction that teams don’t need while they are attempting to stabi- lize the service. Remember, this process is ultimately intended to benefit your customers, and the process should never directly get in the way of restoring service to them.\n\n### Postmortem Follow-Up\n...\n\nAfter many years of postmortems, I’ve found a few areas that you will likely want to consider for corrective actions. I call this _site operability_.\n\n_Eliminate single points of failure_\n\nHardware can and will fail. Utilize redundancy to protect yourself. Don’t let hardware failure be a cause of a customer-impacting incident.\n\n_Capacity planning_\n\nUnderstand your site and its future capacity needs. Base your capacity planning on total utilization of primary constraints such as CPU, memory, I/O, and storage, not on secondary constraints such as number of users. Provision in the areas you need, before you need them.\n\n_Monitoring_\n\nThis is essential for detecting and diagnosing incidents. Other chapters in this book provide great recommendations for monitoring techniques.\n\n_Release management_\n\nChange is historically the most likely cause of incidents. Make sure your release process has the right quality controls in place. Consider implementing concepts such as automated testing, staging environments, limited production deployments, dark launches (rolling out code without activating functionality for customers until the code is proven stable), and the ability to roll back immediately.\n\n_Operational architecture reviews_\n\nHold an architecture review that is entirely focused on how the new release or product will perform in the production environment before rolling it out to customers. Consider maintainability, failure scenarios, and incident response as well as architectural reliability and scalability.\n\n_Configuration management_\n\nAs your systems grow, production configurations become increasingly ­complicated. The inability to understand the implications of changes to production configurations often leads to incidents attributed to human error. Having a configuration management system that is straightforward and logical will help engineers avoid unintended issues. Read Chapter 5 in this book for more recommendations.\n\n_On-call and escalation process_\n\nIdentify the issue and get it to the person who can resolve it as quickly as possible.\n\n_Unstable components_\n\nIdentify and fix software components with a history of crashing and unintended behavior. Make it a priority even when there is an easy manual fix. Those manual fixes add up to become a drag on customer experience and your ability to scale and be effective.\n\nBy proactively ensuring that your site is operable, you will be able to avoid many painful postmortems before they are even necessary.\n","slug":"2016-09-27-web-operations-postmortem","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxo9y001sgkurinkvg42r","content":"<p>Продолжаю постить выдержки из книги “Web Operations: Keeping the Data on Time”.</p>\n<p>В этом посте речь пойдёт о проведении Postmortem, или Root-Cause Analysis (RCA). По сути, это - анализ произошедшей аварии. В книге действительно хорошо всё описано, поэтому выдержки приведу as is.</p>\n<h3 id=\"What-Is-a-Postmortem\"><a href=\"#What-Is-a-Postmortem\" class=\"headerlink\" title=\"What Is a Postmortem?\"></a>What Is a Postmortem?</h3><p>A postmortem needs to cover these essentials at a minimum:</p>\n<ol>\n<li>A description of the incident</li>\n<li>A description of the root cause</li>\n<li>How the incident was stabilized and/or fixed</li>\n<li>A timeline of actions taken to resolve the incident</li>\n<li>How the incident affected customers</li>\n<li>Remediations or corrective actions</li>\n</ol>\n<p>The first five items make sure everyone involved has a common understanding of the facts. Many incidents reoccur because people do not understand what really happened and how the problem was fixed. Different teams and different layers of management arrive at the postmortem with different understandings of what happened. During a postmortem, everyone with significant involvement in the incident should be present at the same time to document a common description of the facts of the incident. Without an accurate account of the facts, it will be impossible to determine and prioritize the corrective actions that are the biggest benefit of a postmortem.</p>\n<p>Determining the root cause should go without saying, but I can’t tell you the number of times I have been in a postmortem where participants spent tons of time debating each possible remediation item or the number of customers affected, only to find that they had wasted their time because they didn’t have the root cause right.</p>\n<p>The same goes for the stabilizing steps. Often during the chaos of a major incident, multiple people attempt multiple fixes. Determine the true root cause and the step that brought it to stable before moving on. Note that an incident might be stable without actually being fixed. You can eliminate customer impact without fixing an issue like when you reboot servers to address a memory leak. Although it will be stable for a short period, the servers are just going to run out of memory again if the root cause is not addressed.</p>\n<p>A timeline will be important for determining how the incident could have been fixed more quickly. Again, multiple people may have a different understanding of the time- line. Allow each participant to contribute the items they are aware of before moving to remediation items around decreasing Time to Resolve (TTR). Make sure to answer the following questions:</p>\n<ul>\n<li>When did the incident begin to affect customers? (Note: Not all incidents affect customers.)</li>\n<li>When did someone in the organization first become aware that there was a problem?</li>\n<li>How did this person become aware? Through monitoring? The Customer Care team? A personal report?</li>\n<li>How long did it take for the knowledge of the incident to get to the person who ultimately resolved it?</li>\n<li>What would have allowed someone to diagnose the fault earlier? (For example, better monitoring, more comprehensive troubleshooting guides, etc.)</li>\n<li>Did the stabilizing steps take a long time to implement? Could they be automated or simplified to speed them up?</li>\n</ul>\n<p>Reducing the TTR of an incident is every bit as important as eliminating incidents themselves. Ultimately, total customer impact minutes (TTR × Number of Customers Affected) is what counts. Some outages may be unavoidable, but if you can ensure quick recovery, your customers will benefit.</p>\n<p>After determining the customer impact, you may want to assign a severity level to the incident. You can develop your own severity categories, or use this example:</p>\n<p>Severity 1: site outages affecting a significant number of customers</p>\n<p>Severity 2: site degradation, performance issues, or broken features which are difficult to work around</p>\n<p>Severity 3: other service issues that have minimal customer impact or easy workarounds</p>\n<p>Assigning a severity level will help you to prioritize completion of your remediation items and is also useful during the triage stage of an active incident. You may have already assigned a severity level while attempting to resolve the issue so that you could determine whether it is a five-alarm fire requiring all hands on deck or a minor blip.</p>\n<h3 id=\"When-to-Conduct-a-Postmortem\"><a href=\"#When-to-Conduct-a-Postmortem\" class=\"headerlink\" title=\"When to Conduct a Postmortem.\"></a>When to Conduct a Postmortem.</h3><p>You should conduct a postmortem after every major outage that affects customers, preferably within 24 hours. This is a little more difficult than it sounds. Teams are usually busy. They are especially busy right after an incident occurs, because they probably spent unplanned cycles on firefighting. Some of the firefighters may have been up all night resolving the incident. Once an incident is stable, people have a tendency to get back to whatever they were doing before they were interrupted to try to make up for lost time.</p>\n<p>The important thing to note is that until a postmortem is conducted and corrective actions are identified, your site is at risk of repeating the incident. If you can’t conduct the postmortem within 24 hours, don’t wait any longer than a week. After a week, incident participants will start to forget key details; you may be missing key logfiles; and of course, you remain at risk for reoccurrence.</p>\n<p>Although it’s good to complete a postmortem within 24 hours, you should not conduct a postmortem while the incident is still open. Trying to determine preventive actions or assign blame is a distraction that teams don’t need while they are attempting to stabi- lize the service. Remember, this process is ultimately intended to benefit your customers, and the process should never directly get in the way of restoring service to them.</p>\n<h3 id=\"Postmortem-Follow-Up\"><a href=\"#Postmortem-Follow-Up\" class=\"headerlink\" title=\"Postmortem Follow-Up\"></a>Postmortem Follow-Up</h3><p>…</p>\n<p>After many years of postmortems, I’ve found a few areas that you will likely want to consider for corrective actions. I call this <em>site operability</em>.</p>\n<p><em>Eliminate single points of failure</em></p>\n<p>Hardware can and will fail. Utilize redundancy to protect yourself. Don’t let hardware failure be a cause of a customer-impacting incident.</p>\n<p><em>Capacity planning</em></p>\n<p>Understand your site and its future capacity needs. Base your capacity planning on total utilization of primary constraints such as CPU, memory, I/O, and storage, not on secondary constraints such as number of users. Provision in the areas you need, before you need them.</p>\n<p><em>Monitoring</em></p>\n<p>This is essential for detecting and diagnosing incidents. Other chapters in this book provide great recommendations for monitoring techniques.</p>\n<p><em>Release management</em></p>\n<p>Change is historically the most likely cause of incidents. Make sure your release process has the right quality controls in place. Consider implementing concepts such as automated testing, staging environments, limited production deployments, dark launches (rolling out code without activating functionality for customers until the code is proven stable), and the ability to roll back immediately.</p>\n<p><em>Operational architecture reviews</em></p>\n<p>Hold an architecture review that is entirely focused on how the new release or product will perform in the production environment before rolling it out to customers. Consider maintainability, failure scenarios, and incident response as well as architectural reliability and scalability.</p>\n<p><em>Configuration management</em></p>\n<p>As your systems grow, production configurations become increasingly ­complicated. The inability to understand the implications of changes to production configurations often leads to incidents attributed to human error. Having a configuration management system that is straightforward and logical will help engineers avoid unintended issues. Read Chapter 5 in this book for more recommendations.</p>\n<p><em>On-call and escalation process</em></p>\n<p>Identify the issue and get it to the person who can resolve it as quickly as possible.</p>\n<p><em>Unstable components</em></p>\n<p>Identify and fix software components with a history of crashing and unintended behavior. Make it a priority even when there is an easy manual fix. Those manual fixes add up to become a drag on customer experience and your ability to scale and be effective.</p>\n<p>By proactively ensuring that your site is operable, you will be able to avoid many painful postmortems before they are even necessary.</p>\n","excerpt":"","more":"<p>Продолжаю постить выдержки из книги “Web Operations: Keeping the Data on Time”.</p>\n<p>В этом посте речь пойдёт о проведении Postmortem, или Root-Cause Analysis (RCA). По сути, это - анализ произошедшей аварии. В книге действительно хорошо всё описано, поэтому выдержки приведу as is.</p>\n<h3 id=\"What-Is-a-Postmortem\"><a href=\"#What-Is-a-Postmortem\" class=\"headerlink\" title=\"What Is a Postmortem?\"></a>What Is a Postmortem?</h3><p>A postmortem needs to cover these essentials at a minimum:</p>\n<ol>\n<li>A description of the incident</li>\n<li>A description of the root cause</li>\n<li>How the incident was stabilized and/or fixed</li>\n<li>A timeline of actions taken to resolve the incident</li>\n<li>How the incident affected customers</li>\n<li>Remediations or corrective actions</li>\n</ol>\n<p>The first five items make sure everyone involved has a common understanding of the facts. Many incidents reoccur because people do not understand what really happened and how the problem was fixed. Different teams and different layers of management arrive at the postmortem with different understandings of what happened. During a postmortem, everyone with significant involvement in the incident should be present at the same time to document a common description of the facts of the incident. Without an accurate account of the facts, it will be impossible to determine and prioritize the corrective actions that are the biggest benefit of a postmortem.</p>\n<p>Determining the root cause should go without saying, but I can’t tell you the number of times I have been in a postmortem where participants spent tons of time debating each possible remediation item or the number of customers affected, only to find that they had wasted their time because they didn’t have the root cause right.</p>\n<p>The same goes for the stabilizing steps. Often during the chaos of a major incident, multiple people attempt multiple fixes. Determine the true root cause and the step that brought it to stable before moving on. Note that an incident might be stable without actually being fixed. You can eliminate customer impact without fixing an issue like when you reboot servers to address a memory leak. Although it will be stable for a short period, the servers are just going to run out of memory again if the root cause is not addressed.</p>\n<p>A timeline will be important for determining how the incident could have been fixed more quickly. Again, multiple people may have a different understanding of the time- line. Allow each participant to contribute the items they are aware of before moving to remediation items around decreasing Time to Resolve (TTR). Make sure to answer the following questions:</p>\n<ul>\n<li>When did the incident begin to affect customers? (Note: Not all incidents affect customers.)</li>\n<li>When did someone in the organization first become aware that there was a problem?</li>\n<li>How did this person become aware? Through monitoring? The Customer Care team? A personal report?</li>\n<li>How long did it take for the knowledge of the incident to get to the person who ultimately resolved it?</li>\n<li>What would have allowed someone to diagnose the fault earlier? (For example, better monitoring, more comprehensive troubleshooting guides, etc.)</li>\n<li>Did the stabilizing steps take a long time to implement? Could they be automated or simplified to speed them up?</li>\n</ul>\n<p>Reducing the TTR of an incident is every bit as important as eliminating incidents themselves. Ultimately, total customer impact minutes (TTR × Number of Customers Affected) is what counts. Some outages may be unavoidable, but if you can ensure quick recovery, your customers will benefit.</p>\n<p>After determining the customer impact, you may want to assign a severity level to the incident. You can develop your own severity categories, or use this example:</p>\n<p>Severity 1: site outages affecting a significant number of customers</p>\n<p>Severity 2: site degradation, performance issues, or broken features which are difficult to work around</p>\n<p>Severity 3: other service issues that have minimal customer impact or easy workarounds</p>\n<p>Assigning a severity level will help you to prioritize completion of your remediation items and is also useful during the triage stage of an active incident. You may have already assigned a severity level while attempting to resolve the issue so that you could determine whether it is a five-alarm fire requiring all hands on deck or a minor blip.</p>\n<h3 id=\"When-to-Conduct-a-Postmortem\"><a href=\"#When-to-Conduct-a-Postmortem\" class=\"headerlink\" title=\"When to Conduct a Postmortem.\"></a>When to Conduct a Postmortem.</h3><p>You should conduct a postmortem after every major outage that affects customers, preferably within 24 hours. This is a little more difficult than it sounds. Teams are usually busy. They are especially busy right after an incident occurs, because they probably spent unplanned cycles on firefighting. Some of the firefighters may have been up all night resolving the incident. Once an incident is stable, people have a tendency to get back to whatever they were doing before they were interrupted to try to make up for lost time.</p>\n<p>The important thing to note is that until a postmortem is conducted and corrective actions are identified, your site is at risk of repeating the incident. If you can’t conduct the postmortem within 24 hours, don’t wait any longer than a week. After a week, incident participants will start to forget key details; you may be missing key logfiles; and of course, you remain at risk for reoccurrence.</p>\n<p>Although it’s good to complete a postmortem within 24 hours, you should not conduct a postmortem while the incident is still open. Trying to determine preventive actions or assign blame is a distraction that teams don’t need while they are attempting to stabi- lize the service. Remember, this process is ultimately intended to benefit your customers, and the process should never directly get in the way of restoring service to them.</p>\n<h3 id=\"Postmortem-Follow-Up\"><a href=\"#Postmortem-Follow-Up\" class=\"headerlink\" title=\"Postmortem Follow-Up\"></a>Postmortem Follow-Up</h3><p>…</p>\n<p>After many years of postmortems, I’ve found a few areas that you will likely want to consider for corrective actions. I call this <em>site operability</em>.</p>\n<p><em>Eliminate single points of failure</em></p>\n<p>Hardware can and will fail. Utilize redundancy to protect yourself. Don’t let hardware failure be a cause of a customer-impacting incident.</p>\n<p><em>Capacity planning</em></p>\n<p>Understand your site and its future capacity needs. Base your capacity planning on total utilization of primary constraints such as CPU, memory, I/O, and storage, not on secondary constraints such as number of users. Provision in the areas you need, before you need them.</p>\n<p><em>Monitoring</em></p>\n<p>This is essential for detecting and diagnosing incidents. Other chapters in this book provide great recommendations for monitoring techniques.</p>\n<p><em>Release management</em></p>\n<p>Change is historically the most likely cause of incidents. Make sure your release process has the right quality controls in place. Consider implementing concepts such as automated testing, staging environments, limited production deployments, dark launches (rolling out code without activating functionality for customers until the code is proven stable), and the ability to roll back immediately.</p>\n<p><em>Operational architecture reviews</em></p>\n<p>Hold an architecture review that is entirely focused on how the new release or product will perform in the production environment before rolling it out to customers. Consider maintainability, failure scenarios, and incident response as well as architectural reliability and scalability.</p>\n<p><em>Configuration management</em></p>\n<p>As your systems grow, production configurations become increasingly ­complicated. The inability to understand the implications of changes to production configurations often leads to incidents attributed to human error. Having a configuration management system that is straightforward and logical will help engineers avoid unintended issues. Read Chapter 5 in this book for more recommendations.</p>\n<p><em>On-call and escalation process</em></p>\n<p>Identify the issue and get it to the person who can resolve it as quickly as possible.</p>\n<p><em>Unstable components</em></p>\n<p>Identify and fix software components with a history of crashing and unintended behavior. Make it a priority even when there is an easy manual fix. Those manual fixes add up to become a drag on customer experience and your ability to scale and be effective.</p>\n<p>By proactively ensuring that your site is operable, you will be able to avoid many painful postmortems before they are even necessary.</p>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2016-11-13T16:43:07.000Z","updated":"2016-11-13T16:43:07.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"civzlxoa1001ugkurgy2tcfw1","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"external\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"external\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"external\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"external\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy</div></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\">Deployment</a></p>\n"},{"link":"https://www.openapis.org/","title":"Открытая спецификация Open API Specification","_content":"Смотрел трансляцию конференции Highload++. Один из докладчиков был из Zalando - один из крупнейших в Европе онлайн-продавцов одежды и обуви (представьте себе нашу Lamoda, только в 50 раз крупнее). Он сказал, что у них микросервисная архитектура, и каджый сервис должен соответствовать OpenAPI (бывшая Swagger API Specification). Сохраняю ссылку себе, т.к. использование OAI - best practice в проектировании API.\n","source":"_posts/2016-11-13-openapi.md","raw":"---\nlink: https://www.openapis.org/\ntitle: Открытая спецификация Open API Specification\ntags: [development, api]\n---\nСмотрел трансляцию конференции Highload++. Один из докладчиков был из Zalando - один из крупнейших в Европе онлайн-продавцов одежды и обуви (представьте себе нашу Lamoda, только в 50 раз крупнее). Он сказал, что у них микросервисная архитектура, и каджый сервис должен соответствовать OpenAPI (бывшая Swagger API Specification). Сохраняю ссылку себе, т.к. использование OAI - best practice в проектировании API.\n","slug":"2016-11-13-openapi","published":1,"date":"2016-11-26T19:10:11.000Z","updated":"2016-11-26T19:10:11.000Z","comments":1,"layout":"post","photos":[],"_id":"civzlxoa4001wgkurbw01f4y1","content":"<p>Смотрел трансляцию конференции Highload++. Один из докладчиков был из Zalando - один из крупнейших в Европе онлайн-продавцов одежды и обуви (представьте себе нашу Lamoda, только в 50 раз крупнее). Он сказал, что у них микросервисная архитектура, и каджый сервис должен соответствовать OpenAPI (бывшая Swagger API Specification). Сохраняю ссылку себе, т.к. использование OAI - best practice в проектировании API.</p>\n","excerpt":"","more":"<p>Смотрел трансляцию конференции Highload++. Один из докладчиков был из Zalando - один из крупнейших в Европе онлайн-продавцов одежды и обуви (представьте себе нашу Lamoda, только в 50 раз крупнее). Он сказал, что у них микросервисная архитектура, и каджый сервис должен соответствовать OpenAPI (бывшая Swagger API Specification). Сохраняю ссылку себе, т.к. использование OAI - best practice в проектировании API.</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"civzlxo7p0000gkurvzn52p7n","tag_id":"civzlxo7y0003gkur8p1j38b5","_id":"civzlxo8n000fgkurli8nvwr6"},{"post_id":"civzlxo7p0000gkurvzn52p7n","tag_id":"civzlxo8c0007gkurjxrbsqj4","_id":"civzlxo8p000hgkurjh67wr7f"},{"post_id":"civzlxo7p0000gkurvzn52p7n","tag_id":"civzlxo8i000agkurjkpyrpmy","_id":"civzlxo8r000kgkursvmebd2f"},{"post_id":"civzlxo7v0002gkur0oprp9va","tag_id":"civzlxo8l000dgkur0zctggi7","_id":"civzlxo8s000mgkur4do0e9m9"},{"post_id":"civzlxo8o000ggkurfbvmlx7n","tag_id":"civzlxo8c0007gkurjxrbsqj4","_id":"civzlxo8w000pgkurkdsbzskc"},{"post_id":"civzlxo8t000ngkurbjvm8t7f","tag_id":"civzlxo8l000dgkur0zctggi7","_id":"civzlxo90000rgkurshm1z47p"},{"post_id":"civzlxo800004gkurbagjbksp","tag_id":"civzlxo8q000igkurcaxyu8uz","_id":"civzlxo95000vgkurxa351q6a"},{"post_id":"civzlxo800004gkurbagjbksp","tag_id":"civzlxo8w000ogkur9atb9eu5","_id":"civzlxo96000xgkurofgzq9rb"},{"post_id":"civzlxo850005gkurjn0m667e","tag_id":"civzlxo92000tgkur2qwqytmz","_id":"civzlxo9c0013gkurebsfp9s5"},{"post_id":"civzlxo850005gkurjn0m667e","tag_id":"civzlxo97000ygkur73huvyrf","_id":"civzlxo9d0015gkurix8chu7h"},{"post_id":"civzlxo8b0006gkurgxg2f7sc","tag_id":"civzlxo92000tgkur2qwqytmz","_id":"civzlxo9g0018gkurf1zh4wi3"},{"post_id":"civzlxo9e0017gkur1gm7aagl","tag_id":"civzlxo8c0007gkurjxrbsqj4","_id":"civzlxo9k001agkurdym633qi"},{"post_id":"civzlxo9m001dgkurkfhjmfdn","tag_id":"civzlxo9k001bgkurgum9irsw","_id":"civzlxo9q001ggkurp69nj4na"},{"post_id":"civzlxo8d0008gkur8s8w9vjv","tag_id":"civzlxo8l000dgkur0zctggi7","_id":"civzlxo9r001igkurif6tajkz"},{"post_id":"civzlxo8d0008gkur8s8w9vjv","tag_id":"civzlxo9k001bgkurgum9irsw","_id":"civzlxo9t001lgkur1qzdmqqd"},{"post_id":"civzlxo9q001hgkur68af91xl","tag_id":"civzlxo9k001bgkurgum9irsw","_id":"civzlxo9t001ngkurlwrg1g8m"},{"post_id":"civzlxo8h0009gkura6k9qq5f","tag_id":"civzlxo9p001fgkurjvh3u968","_id":"civzlxo9x001qgkur4n269vo8"},{"post_id":"civzlxo8j000bgkurvmdffjkh","tag_id":"civzlxo9p001fgkurjvh3u968","_id":"civzlxoa4001vgkur7nh8d2dk"},{"post_id":"civzlxo8j000bgkurvmdffjkh","tag_id":"civzlxo9x001pgkursqz5bxnf","_id":"civzlxoa5001xgkurmv7cazly"},{"post_id":"civzlxo8k000cgkur8aq66jfn","tag_id":"civzlxo9z001tgkur4pxsjaw2","_id":"civzlxoa60020gkurlzd4vrmz"},{"post_id":"civzlxo8k000cgkur8aq66jfn","tag_id":"civzlxo9x001pgkursqz5bxnf","_id":"civzlxoa60021gkurcd0g4atb"},{"post_id":"civzlxo8m000egkur2sthvnfl","tag_id":"civzlxo92000tgkur2qwqytmz","_id":"civzlxoa60023gkur7hhmawt9"},{"post_id":"civzlxo8q000jgkur62kg4fls","tag_id":"civzlxo9x001pgkursqz5bxnf","_id":"civzlxoa80025gkurm8an0t70"},{"post_id":"civzlxo8r000lgkur4eca66wa","tag_id":"civzlxoa70024gkurhkdpxzka","_id":"civzlxoa90028gkur21zpgf3p"},{"post_id":"civzlxo8r000lgkur4eca66wa","tag_id":"civzlxoa80026gkurut1z8m2m","_id":"civzlxoa90029gkurx9hufldh"},{"post_id":"civzlxo8x000qgkurfleendd9","tag_id":"civzlxoa80027gkur5fhdm22x","_id":"civzlxoab002bgkurymszeb5l"},{"post_id":"civzlxo91000sgkurh4h4cfha","tag_id":"civzlxo8q000igkurcaxyu8uz","_id":"civzlxoac002dgkur6o1td3n4"},{"post_id":"civzlxo91000sgkurh4h4cfha","tag_id":"civzlxo9x001pgkursqz5bxnf","_id":"civzlxoac002egkur34tvdgaf"},{"post_id":"civzlxo91000sgkurh4h4cfha","tag_id":"civzlxo8w000ogkur9atb9eu5","_id":"civzlxoac002ggkurqnw8czr2"},{"post_id":"civzlxo94000ugkur9tmn2a6e","tag_id":"civzlxo7y0003gkur8p1j38b5","_id":"civzlxoac002hgkurd5asghiv"},{"post_id":"civzlxo94000ugkur9tmn2a6e","tag_id":"civzlxo9x001pgkursqz5bxnf","_id":"civzlxoad002jgkurvc8gj406"},{"post_id":"civzlxo96000wgkurbls1gdbn","tag_id":"civzlxoac002fgkur5ewb3ay6","_id":"civzlxoae002lgkure974m68g"},{"post_id":"civzlxo96000wgkurbls1gdbn","tag_id":"civzlxoad002igkurgwokwd60","_id":"civzlxoae002mgkur86ze6zt5"},{"post_id":"civzlxo96000wgkurbls1gdbn","tag_id":"civzlxo8w000ogkur9atb9eu5","_id":"civzlxoaf002ogkur1vbvf3l0"},{"post_id":"civzlxo97000zgkurjd0g273i","tag_id":"civzlxo9z001tgkur4pxsjaw2","_id":"civzlxoaf002qgkur4ray58r7"},{"post_id":"civzlxo97000zgkurjd0g273i","tag_id":"civzlxo9x001pgkursqz5bxnf","_id":"civzlxoag002rgkurcrqhiqzh"},{"post_id":"civzlxo980010gkurq3j4bzd2","tag_id":"civzlxo9p001fgkurjvh3u968","_id":"civzlxoag002tgkur66ew6xa7"},{"post_id":"civzlxo9a0012gkurcn2sdnsv","tag_id":"civzlxo9p001fgkurjvh3u968","_id":"civzlxoah002wgkurqiesn3nu"},{"post_id":"civzlxo9a0012gkurcn2sdnsv","tag_id":"civzlxoag002ugkurxwgf0uuq","_id":"civzlxoah002xgkur7w6dy2hk"},{"post_id":"civzlxo9c0014gkurhr3meh8u","tag_id":"civzlxo9z001tgkur4pxsjaw2","_id":"civzlxoai0030gkurqvufo74u"},{"post_id":"civzlxo9c0014gkurhr3meh8u","tag_id":"civzlxo9x001pgkursqz5bxnf","_id":"civzlxoai0031gkur8147ekoy"},{"post_id":"civzlxo9g0019gkur0adelw4m","tag_id":"civzlxoai002zgkurugwgh5c6","_id":"civzlxoan0034gkur7fc6ky3k"},{"post_id":"civzlxo9g0019gkur0adelw4m","tag_id":"civzlxoag002ugkurxwgf0uuq","_id":"civzlxoan0035gkurfr75ykuc"},{"post_id":"civzlxo9l001cgkurlen2untg","tag_id":"civzlxo9p001fgkurjvh3u968","_id":"civzlxoao0038gkurmzxkcozo"},{"post_id":"civzlxo9l001cgkurlen2untg","tag_id":"civzlxoag002ugkurxwgf0uuq","_id":"civzlxoao0039gkursp9sjwym"},{"post_id":"civzlxo9o001egkurskpimuek","tag_id":"civzlxoa80027gkur5fhdm22x","_id":"civzlxoap003bgkurw1krr0dd"},{"post_id":"civzlxo9r001jgkur19ah1r72","tag_id":"civzlxo9k001bgkurgum9irsw","_id":"civzlxoaq003dgkurcup8556e"},{"post_id":"civzlxo9r001jgkur19ah1r72","tag_id":"civzlxoag002ugkurxwgf0uuq","_id":"civzlxoaq003egkurqwfaqou3"},{"post_id":"civzlxo9t001mgkurfgkldcf9","tag_id":"civzlxoa80026gkurut1z8m2m","_id":"civzlxoaq003ggkura7n4z4qt"},{"post_id":"civzlxo9u001ogkurb8st6rga","tag_id":"civzlxoaq003fgkurzmn3nk0u","_id":"civzlxoas003igkursp8a74uw"},{"post_id":"civzlxo9x001rgkurxpgnhwma","tag_id":"civzlxoaq003fgkurzmn3nk0u","_id":"civzlxoau003kgkurjxjk7utw"},{"post_id":"civzlxo9y001sgkurinkvg42r","tag_id":"civzlxoaq003fgkurzmn3nk0u","_id":"civzlxoav003mgkurotmbp0xx"},{"post_id":"civzlxoa4001wgkurbw01f4y1","tag_id":"civzlxoau003lgkur9uuqyik4","_id":"civzlxoaw003ogkural7r4nbk"},{"post_id":"civzlxoa4001wgkurbw01f4y1","tag_id":"civzlxoaw003ngkurgngmg63o","_id":"civzlxoax003pgkur4tjs8331"}],"Tag":[{"name":"nginx","_id":"civzlxo7y0003gkur8p1j38b5"},{"name":"python","_id":"civzlxo8c0007gkurjxrbsqj4"},{"name":"uwsgi","_id":"civzlxo8i000agkurjkpyrpmy"},{"name":"hardware","_id":"civzlxo8l000dgkur0zctggi7"},{"name":"php","_id":"civzlxo8q000igkurcaxyu8uz"},{"name":"apache","_id":"civzlxo8w000ogkur9atb9eu5"},{"name":"dns","_id":"civzlxo92000tgkur2qwqytmz"},{"name":"dhcp","_id":"civzlxo97000ygkur73huvyrf"},{"name":"storage","_id":"civzlxo9k001bgkurgum9irsw"},{"name":"mysql","_id":"civzlxo9p001fgkurjvh3u968"},{"name":"troubleshooting","_id":"civzlxo9x001pgkursqz5bxnf"},{"name":"puppet","_id":"civzlxo9z001tgkur4pxsjaw2"},{"name":"vpn","_id":"civzlxoa70024gkurhkdpxzka"},{"name":"environment","_id":"civzlxoa80026gkurut1z8m2m"},{"name":"network","_id":"civzlxoa80027gkur5fhdm22x"},{"name":"logs","_id":"civzlxoac002fgkur5ewb3ay6"},{"name":"elk","_id":"civzlxoad002igkurgwokwd60"},{"name":"performance","_id":"civzlxoag002ugkurxwgf0uuq"},{"name":"tool","_id":"civzlxoai002zgkurugwgh5c6"},{"name":"book","_id":"civzlxoaq003fgkurzmn3nk0u"},{"name":"development","_id":"civzlxoau003lgkur9uuqyik4"},{"name":"api","_id":"civzlxoaw003ngkurgngmg63o"}]}}